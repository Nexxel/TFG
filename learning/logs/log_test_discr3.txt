=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.079213
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 4
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 9
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.00142583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00139732
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 14
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 15
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.5665e-05
New value of Value function: 2.5665e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 19
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00142583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 39
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 46
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 47
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 48
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 49
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 50
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0014256
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00072
New value of Value function: 0.0792
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 53
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 54
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 55
----------
State: 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 56
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 57
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0014256
New value of Value function: 0.0014256
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0776417
New value of Value function: 0.0776417
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 59
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.56608e-05
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.08084e-05
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.56608e-05
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000745148
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00145024
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0407056
New value of Value function: 0.0407056
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 69
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 1.296e-05
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 70
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210315
New value of Value function: 0.00210315
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00210315
New value of Value function: 0.0776417
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 74
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.78567e-05
New value of Value function: 0.0776417
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 75
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00345864
New value of Value function: 0.00345864
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0774864
New value of Value function: 0.0774864
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 77
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210035
New value of Value function: 0.0774864
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 78
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0034531
New value of Value function: 0.0774864
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 79
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0773314
New value of Value function: 0.0773314
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 80
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0771767
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 81
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.9355e-05
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 82
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00477865
New value of Value function: 0.00477865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00345027
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 84
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00477044
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 85
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00477322
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 86
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00606694
New value of Value function: 0.0771767
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 87
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.115633
New value of Value function: 0.115633
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 88
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 97
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 98
----------
State: 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 99
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 100
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 1.296e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014256
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 104
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.296e-05
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 105
----------
State: 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 141
	Distance: 0
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 106
----------
State: 141
	Distance: 0
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 1.296e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.03992
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 109
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 110
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0398402
New value of Value function: 0.03992
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 111
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0407058
New value of Value function: 0.0407058
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 112
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.83616e-05
New value of Value function: 3.83616e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.83616e-05
New value of Value function: 0.0014256
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00212979
New value of Value function: 0.00212979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 309
	Distance: 0
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.041203
New value of Value function: 0.041203
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 116
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.114053
New value of Value function: 0.114053
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 117
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00215394
New value of Value function: 0.0407056
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 118
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0392
New value of Value function: 0.0407056
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 119
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 124
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0400257
New value of Value function: 0.0400257
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 126
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00142583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 129
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0027952
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142583
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00282315
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00419252
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00282315
New value of Value function: 0.079213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0790545
New value of Value function: 0.0790545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00553165
New value of Value function: 0.0790545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0788964
New value of Value function: 0.0788964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00415944
New value of Value function: 0.0788964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00549638
New value of Value function: 0.0788964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00680659
New value of Value function: 0.0788964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.117331
New value of Value function: 0.117331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00073944
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 145
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.04108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 146
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 147
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.00072
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 148
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.60156e-05
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 149
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.87164e-05
New value of Value function: 0.00477865
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00673603
New value of Value function: 0.00673603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000743936
New value of Value function: 0.114053
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 152
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.83363e-05
New value of Value function: 0.00212979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 153
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.59058e-05
New value of Value function: 0.00212979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00205296
New value of Value function: 0.00212979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 155
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.113825
New value of Value function: 0.113825
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 156
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00799445
New value of Value function: 0.113825
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 157
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.0478346
New value of Value function: 0.113825
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 158
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000732701
New value of Value function: 0.000732701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 159
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0414103
New value of Value function: 0.0414103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 160
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.83363e-05
New value of Value function: 0.000732701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0401
New value of Value function: 0.0401
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 162
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00344594
New value of Value function: 0.00344594
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0401103
New value of Value function: 0.113825
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 164
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 165
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 166
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.296e-05
New value of Value function: 0.00072
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 167
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014256
New value of Value function: 0.0014256
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 168
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00073944
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 170
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0400257
New value of Value function: 0.04108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 172
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 173
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000752141
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 174
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0400973
New value of Value function: 0.04108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000752141
New value of Value function: 0.000752141
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0399394
New value of Value function: 0.04108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 589
	Distance: 0
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0802584
New value of Value function: 0.0802584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00073944
New value of Value function: 0.00073944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 179
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000121249
New value of Value function: 0.04108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 180
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000133949
New value of Value function: 0.00673603
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 181
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0401315
New value of Value function: 0.0401315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 182
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600257
New value of Value function: 0.0600257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108406
New value of Value function: 0.00142583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00350928
New value of Value function: 0.00350928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00487865
New value of Value function: 0.117331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00211197
New value of Value function: 0.117331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00689305
New value of Value function: 0.117331
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.117097
New value of Value function: 0.117097
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.116863
New value of Value function: 0.116863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00877399
New value of Value function: 0.116863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00417325
New value of Value function: 0.116863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00931851
New value of Value function: 0.116863
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 194
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0792194
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 195
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600005
New value of Value function: 0.0600005
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 196
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00210353
New value of Value function: 0.00210353
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.154563
New value of Value function: 0.154563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 198
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108001
New value of Value function: 0.00210353
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0598805
New value of Value function: 0.0598805
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 200
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0597607
New value of Value function: 0.0597607
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 201
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.0597607
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 202
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000720462
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 204
----------
State: 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0792883
New value of Value function: 0.0792883
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 205
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00248559
New value of Value function: 0.00350928
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 206
----------
State: 701
	Distance: 0
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04108
New value of Value function: 0.0792883
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 207
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0602259
New value of Value function: 0.0602259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 208
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00142595
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 209
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00417945
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.152898
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00275216
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0105581
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00684803
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00950735
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0120694
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0130991
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00684195
New value of Value function: 0.152898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.152592
New value of Value function: 0.152592
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0145746
New value of Value function: 0.152592
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.152287
New value of Value function: 0.152287
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.151982
New value of Value function: 0.151982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00944079
New value of Value function: 0.151982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0170188
New value of Value function: 0.151982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.151678
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0155673
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0194087
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00815123
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0179862
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0203567
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0119822
New value of Value function: 0.151678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.151375
New value of Value function: 0.151375
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0144673
New value of Value function: 0.151375
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 0.189423
New value of Value function: 0.189423
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 234
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118603
New value of Value function: 0.118603
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 235
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00319327
New value of Value function: 0.00319327
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 236
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.118366
New value of Value function: 0.118366
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 237
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00340962
New value of Value function: 0.118366
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 0.227765
New value of Value function: 0.227765
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 239
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.118129
New value of Value function: 0.118129
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 240
----------
State: 10165
	Distance: 12
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600575
New value of Value function: 0.118129
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 241
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.74788e-05
New value of Value function: 0.00319327
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 242
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00616123
New value of Value function: 0.00616123
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0240493
New value of Value function: 0.227765
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.012088
New value of Value function: 0.227765
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.015946
New value of Value function: 0.227765
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0197269
New value of Value function: 0.227765
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.224636
New value of Value function: 0.224636
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 248
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0410841
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 249
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00214247
New value of Value function: 0.0602259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 250
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.0602259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 251
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 252
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000722367
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 253
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0400512
New value of Value function: 0.0400512
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 254
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 255
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 256
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00247493
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 257
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000758491
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 258
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0813362
New value of Value function: 0.0813362
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000762761
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 260
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0610778
New value of Value function: 0.0610778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 261
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0010994
New value of Value function: 0.0010994
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 262
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0609341
New value of Value function: 0.0609341
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 263
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118696
New value of Value function: 0.118696
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 264
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00073944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 265
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108046
New value of Value function: 0.00108046
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 266
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0598805
New value of Value function: 0.0600257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 267
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108046
New value of Value function: 0.0600257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 268
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118696
New value of Value function: 0.118696
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 269
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.31671e-05
New value of Value function: 0.00073944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 270
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00748254
New value of Value function: 0.00748254
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0182214
New value of Value function: 0.224636
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 0.260278
New value of Value function: 0.260278
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 273
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00214645
New value of Value function: 0.00748254
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 274
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601347
New value of Value function: 0.0602259
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 275
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213653
New value of Value function: 0.00748254
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 276
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.11896
New value of Value function: 0.11896
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 277
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0120179
New value of Value function: 0.0120179
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 0.295289
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 279
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00231984
New value of Value function: 0.0120179
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 280
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00248977
New value of Value function: 0.0120179
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 281
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000216322
New value of Value function: 0.0120179
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 282
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.060225
New value of Value function: 0.060225
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 283
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213155
New value of Value function: 0.00213155
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 284
----------
State: 757
	Distance: 0
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0120263
New value of Value function: 0.0792194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0288835
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.033621
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0231722
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0382638
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0428137
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0472727
New value of Value function: 0.295289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 0.330467
New value of Value function: 0.330467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00423508
New value of Value function: 0.060225
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 293
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.118464
New value of Value function: 0.11896
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 294
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176581
New value of Value function: 0.176581
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00594841
New value of Value function: 0.00594841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0249689
New value of Value function: 0.330467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.329806
New value of Value function: 0.329806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0522637
New value of Value function: 0.329806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0286452
New value of Value function: 0.329806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 0.364294
New value of Value function: 0.364294
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 301
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0591314
New value of Value function: 0.0591314
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 302
----------
State: 8597
	Distance: 10
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0125953
New value of Value function: 0.0125953
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0577757
New value of Value function: 0.364294
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 0.398092
New value of Value function: 0.398092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 305
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.063164
New value of Value function: 0.063164
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 306
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0590131
New value of Value function: 0.0590131
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 307
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00350221
New value of Value function: 0.0590131
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 308
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0044944
New value of Value function: 0.0590131
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 309
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0588951
New value of Value function: 0.0588951
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 310
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0189432
New value of Value function: 0.0588951
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0316352
New value of Value function: 0.398092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.397296
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0352237
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0416705
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0637716
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0479884
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0264836
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0696474
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0381538
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.044542
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.05418
New value of Value function: 0.397296
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.396501
New value of Value function: 0.396501
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.395708
New value of Value function: 0.395708
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 0.428854
New value of Value function: 0.428854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 325
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0262837
New value of Value function: 0.0588951
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 0.461414
New value of Value function: 0.461414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 327
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0673269
New value of Value function: 0.0673269
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 0.493398
New value of Value function: 0.493398
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 329
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00179784
New value of Value function: 0.0673269
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 330
----------
State: 645
	Distance: 0
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0412119
New value of Value function: 0.0412119
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 331
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00191794
New value of Value function: 0.0673269
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 332
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00309146
New value of Value function: 0.0673269
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 333
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0748615
New value of Value function: 0.0748615
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 0.524877
New value of Value function: 0.524877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 335
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0828121
New value of Value function: 0.0828121
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 0.55587
New value of Value function: 0.55587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 337
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0911615
New value of Value function: 0.0911615
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 0.586394
New value of Value function: 0.586394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 339
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0998934
New value of Value function: 0.0998934
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 0.616464
New value of Value function: 0.616464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 341
----------
State: 10109
	Distance: 12
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00389841
New value of Value function: 0.0998934
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00221156
New value of Value function: 0.118696
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 343
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.121846
New value of Value function: 0.121846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00436056
New value of Value function: 0.118696
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 345
----------
State: 533
	Distance: 0
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0073467
New value of Value function: 0.121846
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 346
----------
State: 477
	Distance: 0
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0426309
New value of Value function: 0.0426309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 347
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.151562
New value of Value function: 0.151562
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 348
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.35385e-05
New value of Value function: 0.000752141
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 349
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00343372
New value of Value function: 0.00343372
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 350
----------
State: 421
	Distance: 0
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00145086
New value of Value function: 0.151562
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 351
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000721801
New value of Value function: 0.0401
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 352
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0400198
New value of Value function: 0.0400198
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 353
----------
State: 365
	Distance: 0
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0421002
New value of Value function: 0.0421002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00072
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 355
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 356
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 357
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 358
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 359
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04108
New value of Value function: 0.04108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 360
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 361
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118702
New value of Value function: 0.118702
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 362
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010584
New value of Value function: 0.0010584
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 363
----------
State: 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 364
----------
State: 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 365
----------
State: 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 366
----------
State: 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 367
----------
State: 7981
	Distance: 10
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213663
New value of Value function: 0.00213663
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 368
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00319503
New value of Value function: 0.118702
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 369
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00144504
New value of Value function: 0.118702
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 370
----------
State: 253
	Distance: 0
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.082395
New value of Value function: 0.082395
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 371
----------
State: 9605
	Distance: 12
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00314409
New value of Value function: 0.118702
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 372
----------
State: 197
	Distance: 0
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 373
----------
State: 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9493
	Distance: 12
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 374
----------
State: 9493
	Distance: 12
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 375
----------
State: 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 376
----------
State: 7925
	Distance: 10
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0110964
New value of Value function: 0.0110964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0370503
New value of Value function: 0.616464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0474057
New value of Value function: 0.616464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0793509
New value of Value function: 0.616464
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.615231
New value of Value function: 0.615231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0641705
New value of Value function: 0.615231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0575317
New value of Value function: 0.615231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.088838
New value of Value function: 0.615231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0981354
New value of Value function: 0.615231
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.614001
New value of Value function: 0.614001
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0739392
New value of Value function: 0.614001
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0547032
New value of Value function: 0.614001
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0646612
New value of Value function: 0.614001
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.612773
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.067411
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0770927
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0743979
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0865807
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0834903
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0839398
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0961727
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 397
----------
State: 85
	Distance: 0
	Angle: 1
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0110299
New value of Value function: 0.0110299
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.095879
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.105279
New value of Value function: 0.612773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.611547
New value of Value function: 0.611547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0928283
New value of Value function: 0.611547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.10198
New value of Value function: 0.611547
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.610324
New value of Value function: 0.610324
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.609103
New value of Value function: 0.609103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.114137
New value of Value function: 0.609103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.104925
New value of Value function: 0.609103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.607885
New value of Value function: 0.607885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.606669
New value of Value function: 0.606669
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.605456
New value of Value function: 0.605456
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.110838
New value of Value function: 0.605456
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.122753
New value of Value function: 0.605456
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.604245
New value of Value function: 0.604245
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.119498
New value of Value function: 0.604245
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0931374
New value of Value function: 0.604245
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.131174
New value of Value function: 0.604245
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.603037
New value of Value function: 0.603037
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.601831
New value of Value function: 0.601831
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.11366
New value of Value function: 0.601831
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.600627
New value of Value function: 0.600627
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.139362
New value of Value function: 0.600627
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.599426
New value of Value function: 0.599426
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.122176
New value of Value function: 0.599426
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.598227
New value of Value function: 0.598227
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.130501
New value of Value function: 0.598227
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.59703
New value of Value function: 0.59703
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.595836
New value of Value function: 0.595836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.594645
New value of Value function: 0.594645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.147278
New value of Value function: 0.594645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.138594
New value of Value function: 0.594645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.593455
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.101957
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.155015
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.146505
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.12779
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.154257
New value of Value function: 0.593455
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.592268
New value of Value function: 0.592268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.110579
New value of Value function: 0.592268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.119028
New value of Value function: 0.592268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.162576
New value of Value function: 0.592268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.169985
New value of Value function: 0.592268
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.591084
New value of Value function: 0.591084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.135874
New value of Value function: 0.591084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.161811
New value of Value function: 0.591084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.589902
New value of Value function: 0.589902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.127266
New value of Value function: 0.589902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.143775
New value of Value function: 0.589902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.177203
New value of Value function: 0.589902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.135338
New value of Value function: 0.589902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.588722
New value of Value function: 0.588722
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.151496
New value of Value function: 0.588722
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.587545
New value of Value function: 0.587545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.169151
New value of Value function: 0.587545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.143207
New value of Value function: 0.587545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.150919
New value of Value function: 0.587545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.586369
New value of Value function: 0.586369
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.585197
New value of Value function: 0.585197
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.584026
New value of Value function: 0.584026
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.582858
New value of Value function: 0.582858
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.158392
New value of Value function: 0.582858
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.581693
New value of Value function: 0.581693
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.580529
New value of Value function: 0.580529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.158916
New value of Value function: 0.580529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.579368
New value of Value function: 0.579368
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.165653
New value of Value function: 0.579368
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.184088
New value of Value function: 0.579368
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.578209
New value of Value function: 0.578209
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.577053
New value of Value function: 0.577053
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.575899
New value of Value function: 0.575899
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.574747
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.166083
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.190752
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.197282
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.173107
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.176113
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.203682
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.209954
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.2161
New value of Value function: 0.574747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.573598
New value of Value function: 0.573598
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.182916
New value of Value function: 0.573598
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.222103
New value of Value function: 0.573598
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.57245
New value of Value function: 0.57245
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.571305
New value of Value function: 0.571305
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.570163
New value of Value function: 0.570163
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.569023
New value of Value function: 0.569023
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.1895
New value of Value function: 0.569023
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.172582
New value of Value function: 0.569023
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.567884
New value of Value function: 0.567884
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.566749
New value of Value function: 0.566749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.195911
New value of Value function: 0.566749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.179332
New value of Value function: 0.566749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.179846
New value of Value function: 0.566749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.565615
New value of Value function: 0.565615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.564484
New value of Value function: 0.564484
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.563355
New value of Value function: 0.563355
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.562228
New value of Value function: 0.562228
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.186369
New value of Value function: 0.562228
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.185866
New value of Value function: 0.562228
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.192762
New value of Value function: 0.562228
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.561104
New value of Value function: 0.561104
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.559982
New value of Value function: 0.559982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.198986
New value of Value function: 0.559982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.202073
New value of Value function: 0.559982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.192228
New value of Value function: 0.559982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.558862
New value of Value function: 0.558862
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.557744
New value of Value function: 0.557744
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.556628
New value of Value function: 0.556628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.205026
New value of Value function: 0.556628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.210945
New value of Value function: 0.556628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.555515
New value of Value function: 0.555515
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.216725
New value of Value function: 0.555515
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.22766
New value of Value function: 0.555515
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.208031
New value of Value function: 0.555515
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.554404
New value of Value function: 0.554404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.213849
New value of Value function: 0.554404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.198363
New value of Value function: 0.554404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.204375
New value of Value function: 0.554404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.553295
New value of Value function: 0.553295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.219532
New value of Value function: 0.553295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.210247
New value of Value function: 0.553295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.233066
New value of Value function: 0.553295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.552189
New value of Value function: 0.552189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.22508
New value of Value function: 0.552189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.22233
New value of Value function: 0.552189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.551084
New value of Value function: 0.551084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.215961
New value of Value function: 0.551084
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.549982
New value of Value function: 0.549982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.221542
New value of Value function: 0.549982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.22701
New value of Value function: 0.549982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.227783
New value of Value function: 0.549982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.23237
New value of Value function: 0.549982
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.548882
New value of Value function: 0.548882
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.233107
New value of Value function: 0.548882
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.547785
New value of Value function: 0.547785
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.238265
New value of Value function: 0.547785
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.546689
New value of Value function: 0.546689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.238286
New value of Value function: 0.546689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.237563
New value of Value function: 0.546689
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.545596
New value of Value function: 0.545596
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.230399
New value of Value function: 0.545596
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.544504
New value of Value function: 0.544504
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.243301
New value of Value function: 0.544504
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.248236
New value of Value function: 0.544504
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.543415
New value of Value function: 0.543415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.243301
New value of Value function: 0.543415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.253053
New value of Value function: 0.543415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.542329
New value of Value function: 0.542329
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.242574
New value of Value function: 0.542329
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.541244
New value of Value function: 0.541244
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.540161
New value of Value function: 0.540161
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.539081
New value of Value function: 0.539081
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.248139
New value of Value function: 0.539081
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.538003
New value of Value function: 0.538003
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.536927
New value of Value function: 0.536927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.252841
New value of Value function: 0.536927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.257448
New value of Value function: 0.536927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 103
New value of Q matrix: 0.566227
New value of Value function: 0.566227
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 557
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00106011
New value of Value function: 0.00213155
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 558
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.117756
New value of Value function: 0.117756
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 559
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.83679e-05
New value of Value function: 0.00213155
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 560
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.012281
New value of Value function: 0.012281
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 0.595123
New value of Value function: 0.595123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 562
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 563
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0021196
New value of Value function: 0.0021196
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 564
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00416369
New value of Value function: 0.117756
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 565
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.33099e-05
New value of Value function: 0.00073944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 566
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0607247
New value of Value function: 0.0607247
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 567
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021196
New value of Value function: 0.0021196
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 568
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.17648
New value of Value function: 0.17648
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 569
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 570
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00109304
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 571
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00110609
New value of Value function: 0.0607247
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 572
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109304
New value of Value function: 0.0607247
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 573
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.119548
New value of Value function: 0.119548
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 574
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00215187
New value of Value function: 0.00215187
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 575
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00323584
New value of Value function: 0.119548
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 576
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.119309
New value of Value function: 0.119309
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 577
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.119071
New value of Value function: 0.119071
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 578
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.119868
New value of Value function: 0.119868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 579
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.236226
New value of Value function: 0.236226
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 580
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.176127
New value of Value function: 0.176127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 581
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0635137
New value of Value function: 0.176127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 582
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0227476
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.248434
New value of Value function: 0.595123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.593933
New value of Value function: 0.593933
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.26299
New value of Value function: 0.593933
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.268421
New value of Value function: 0.593933
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 106
New value of Q matrix: 0.625225
New value of Value function: 0.625225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 588
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.233683
New value of Value function: 0.233683
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 589
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0597602
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 590
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0032288
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 591
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00532874
New value of Value function: 0.119868
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 592
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.119628
New value of Value function: 0.119628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 593
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00322449
New value of Value function: 0.119628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 594
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0631987
New value of Value function: 0.119628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 595
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00218428
New value of Value function: 0.00218428
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 596
----------
State: 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107568
New value of Value function: 0.00594841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 597
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0335467
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.259246
New value of Value function: 0.625225
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 107
New value of Q matrix: 0.653796
New value of Value function: 0.653796
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 600
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00211459
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 601
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00424389
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 602
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00623371
New value of Value function: 0.233683
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 603
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00109681
New value of Value function: 0.119628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 604
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00110952
New value of Value function: 0.0609341
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 605
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.121869
New value of Value function: 0.121869
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00326852
New value of Value function: 0.119628
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 607
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.181585
New value of Value function: 0.181585
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.117255
New value of Value function: 0.117255
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 609
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0610757
New value of Value function: 0.0610757
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 610
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00627859
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 611
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0664497
New value of Value function: 0.233683
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 612
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.126196
New value of Value function: 0.233683
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 613
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0627713
New value of Value function: 0.0627713
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 614
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.290139
New value of Value function: 0.290139
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 615
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0626458
New value of Value function: 0.0626458
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 616
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.121431
New value of Value function: 0.121431
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 617
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0117683
New value of Value function: 0.0117683
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 108
New value of Q matrix: 0.680932
New value of Value function: 0.680932
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 619
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0117683
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 620
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.9317e-05
New value of Value function: 3.9317e-05
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 621
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7025
	Distance: 8
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0621406
New value of Value function: 0.0621406
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 622
----------
State: 7025
	Distance: 8
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 623
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7025
	Distance: 8
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 624
----------
State: 7025
	Distance: 8
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00218576
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 625
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0451325
New value of Value function: 0.121431
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 109
New value of Q matrix: 0.709499
New value of Value function: 0.709499
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.119109
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 628
----------
State: 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0186004
New value of Value function: 0.0186004
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 110
New value of Q matrix: 0.735309
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 630
----------
State: 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7029
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 631
----------
State: 7029
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.07706e-07
New value of Value function: 7.07706e-07
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 632
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00211059
New value of Value function: 0.00211059
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 633
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.0663407
New value of Value function: 0.117255
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 634
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0630418
New value of Value function: 0.0630418
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 635
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0574654
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.256701
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.267296
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.276288
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.264803
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.275186
New value of Value function: 0.735309
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.733838
New value of Value function: 0.733838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.282891
New value of Value function: 0.733838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.272716
New value of Value function: 0.733838
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.732371
New value of Value function: 0.732371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.280444
New value of Value function: 0.732371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.283945
New value of Value function: 0.732371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.730906
New value of Value function: 0.730906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.238948
New value of Value function: 0.730906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.729444
New value of Value function: 0.729444
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 115
New value of Q matrix: 0.756999
New value of Value function: 0.756999
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 651
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0113755
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 652
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.025758
New value of Value function: 0.290139
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 653
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0403348
New value of Value function: 0.0403348
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 654
----------
State: 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00138898
New value of Value function: 0.0186004
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 655
----------
State: 7813
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7029
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 656
----------
State: 7029
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.013626
New value of Value function: 0.013626
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 116
New value of Q matrix: 0.782071
New value of Value function: 0.782071
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 658
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00214397
New value of Value function: 0.0117683
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 659
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00630298
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 660
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00530075
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 661
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.177421
New value of Value function: 0.177421
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 662
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0650767
New value of Value function: 0.0650767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 663
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.34648
New value of Value function: 0.34648
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 664
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0703934
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 117
New value of Q matrix: 0.808574
New value of Value function: 0.808574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 666
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00832089
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 667
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0173847
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 668
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.401695
New value of Value function: 0.401695
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 669
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0191809
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 670
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0209413
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 671
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.015385
New value of Value function: 0.119109
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 672
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.185816
New value of Value function: 0.401695
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 673
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.118871
New value of Value function: 0.118871
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 674
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0226621
New value of Value function: 0.118871
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 675
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0835399
New value of Value function: 0.118871
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 118
New value of Q matrix: 0.834542
New value of Value function: 0.834542
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 677
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00632948
New value of Value function: 0.118871
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 678
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94483e-05
New value of Value function: 0.0630418
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 679
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94483e-05
New value of Value function: 0.00108046
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 680
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00316945
New value of Value function: 0.00316945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 681
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.116081
New value of Value function: 0.116081
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 682
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00222978
New value of Value function: 0.0650767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 683
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.0650767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 684
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00208947
New value of Value function: 0.00208947
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 685
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.12307
New value of Value function: 0.12307
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 686
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.61094e-05
New value of Value function: 0.0630418
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 687
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.705e-05
New value of Value function: 0.00316945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 688
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.18069e-05
New value of Value function: 0.00316945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 689
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.063365
New value of Value function: 0.063365
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 690
----------
State: 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 691
----------
State: 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 692
----------
State: 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.31886e-05
New value of Value function: 1.31886e-05
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 693
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0600376
New value of Value function: 0.0600376
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 694
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 695
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 696
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 697
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 698
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 699
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 700
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 701
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 702
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 703
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 704
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 705
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 706
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 707
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 708
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.00109944
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 709
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 710
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 711
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 712
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 713
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 714
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.944e-05
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 715
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 716
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610584
New value of Value function: 0.0610584
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 717
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 718
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0150218
New value of Value function: 0.0150218
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.249191
New value of Value function: 0.834542
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.293288
New value of Value function: 0.834542
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.832873
New value of Value function: 0.832873
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.831207
New value of Value function: 0.831207
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.829544
New value of Value function: 0.829544
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.289767
New value of Value function: 0.829544
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.827885
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.298874
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.292135
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.302324
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.307798
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.301195
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.31118
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 49
New value of Q matrix: 0.341642
New value of Value function: 0.827885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 733
----------
State: 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000270392
New value of Value function: 0.000270392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 734
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109905
New value of Value function: 0.0150218
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 735
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6353
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0598372
New value of Value function: 0.0598372
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 736
----------
State: 6353
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600049
New value of Value function: 0.0600049
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 737
----------
State: 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9489
	Distance: 12
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.000270392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 738
----------
State: 9489
	Distance: 12
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06108
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 739
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9489
	Distance: 12
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109944
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 740
----------
State: 9489
	Distance: 12
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600049
New value of Value function: 0.06108
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 741
----------
State: 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6353
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108009
New value of Value function: 0.00108009
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 742
----------
State: 6353
	Distance: 8
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 743
----------
State: 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0149019
New value of Value function: 0.0149019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.82623
New value of Value function: 0.82623
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.824577
New value of Value function: 0.824577
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.822928
New value of Value function: 0.822928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.309983
New value of Value function: 0.822928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.319769
New value of Value function: 0.822928
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.821282
New value of Value function: 0.821282
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.81964
New value of Value function: 0.81964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.818
New value of Value function: 0.818
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.816364
New value of Value function: 0.816364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.349504
New value of Value function: 0.816364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.318478
New value of Value function: 0.816364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.328068
New value of Value function: 0.816364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.814732
New value of Value function: 0.814732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.258872
New value of Value function: 0.814732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.813102
New value of Value function: 0.813102
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.26833
New value of Value function: 0.813102
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.326745
New value of Value function: 0.813102
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.811476
New value of Value function: 0.811476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.336113
New value of Value function: 0.811476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.334816
New value of Value function: 0.811476
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.809853
New value of Value function: 0.809853
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.808233
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.277512
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.342668
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.28651
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.357062
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.364469
New value of Value function: 0.808233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.806617
New value of Value function: 0.806617
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 772
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.805004
New value of Value function: 0.805004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.343881
New value of Value function: 0.805004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.350305
New value of Value function: 0.805004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.351494
New value of Value function: 0.805004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.357789
New value of Value function: 0.805004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.803394
New value of Value function: 0.803394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.801787
New value of Value function: 0.801787
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.365065
New value of Value function: 0.801787
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.800183
New value of Value function: 0.800183
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.358867
New value of Value function: 0.800183
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.798583
New value of Value function: 0.798583
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.796986
New value of Value function: 0.796986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.371525
New value of Value function: 0.796986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.37211
New value of Value function: 0.796986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.366035
New value of Value function: 0.796986
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.795392
New value of Value function: 0.795392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.373032
New value of Value function: 0.795392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.295097
New value of Value function: 0.795392
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.793801
New value of Value function: 0.793801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.378956
New value of Value function: 0.793801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.792213
New value of Value function: 0.792213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.379831
New value of Value function: 0.792213
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.790629
New value of Value function: 0.790629
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.789048
New value of Value function: 0.789048
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.38558
New value of Value function: 0.789048
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.392071
New value of Value function: 0.789048
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.78747
New value of Value function: 0.78747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.303369
New value of Value function: 0.78747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.785895
New value of Value function: 0.785895
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.784323
New value of Value function: 0.784323
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.386352
New value of Value function: 0.784323
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.782754
New value of Value function: 0.782754
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.781189
New value of Value function: 0.781189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.779626
New value of Value function: 0.779626
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.778067
New value of Value function: 0.778067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.398235
New value of Value function: 0.778067
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.776511
New value of Value function: 0.776511
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.774958
New value of Value function: 0.774958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.392574
New value of Value function: 0.774958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.404219
New value of Value function: 0.774958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.410084
New value of Value function: 0.774958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.773408
New value of Value function: 0.773408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.398644
New value of Value function: 0.773408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.311223
New value of Value function: 0.773408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0.771861
New value of Value function: 0.771861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.404565
New value of Value function: 0.771861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.377988
New value of Value function: 0.771861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.770317
New value of Value function: 0.770317
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.768777
New value of Value function: 0.768777
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.767239
New value of Value function: 0.767239
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0.765705
New value of Value function: 0.765705
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.410256
New value of Value function: 0.765705
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.415665
New value of Value function: 0.765705
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0.764173
New value of Value function: 0.764173
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.318754
New value of Value function: 0.764173
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0.762645
New value of Value function: 0.762645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.384156
New value of Value function: 0.762645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.421079
New value of Value function: 0.762645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0.76112
New value of Value function: 0.76112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.415751
New value of Value function: 0.76112
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.759597
New value of Value function: 0.759597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.758078
New value of Value function: 0.758078
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.756562
New value of Value function: 0.756562
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.755049
New value of Value function: 0.755049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0.753539
New value of Value function: 0.753539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.426221
New value of Value function: 0.753539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.431261
New value of Value function: 0.753539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.752032
New value of Value function: 0.752032
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 171
New value of Q matrix: 0.777011
New value of Value function: 0.777011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 841
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010584
New value of Value function: 0.0010584
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 842
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0139862
New value of Value function: 0.0139862
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.421422
New value of Value function: 0.777011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.390459
New value of Value function: 0.777011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.396636
New value of Value function: 0.777011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 846
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.326365
New value of Value function: 0.777011
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.775457
New value of Value function: 0.775457
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.436594
New value of Value function: 0.775457
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.773906
New value of Value function: 0.773906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 174
New value of Q matrix: 0.798447
New value of Value function: 0.798447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 851
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90512e-05
New value of Value function: 0.0010584
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 852
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.014372
New value of Value function: 0.014372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.427366
New value of Value function: 0.798447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.403076
New value of Value function: 0.798447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.442234
New value of Value function: 0.798447
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.79685
New value of Value function: 0.79685
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 176
New value of Q matrix: 0.821164
New value of Value function: 0.821164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 858
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0139862
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 859
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 860
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 861
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 862
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 863
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 864
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 865
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 866
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 867
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 868
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 869
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 870
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 871
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118819
New value of Value function: 0.118819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 872
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 873
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 874
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0602518
New value of Value function: 0.0602518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 875
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0139862
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 876
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0602518
New value of Value function: 0.0602518
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 877
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0284874
New value of Value function: 0.0284874
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.334619
New value of Value function: 0.821164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 177
New value of Q matrix: 0.845254
New value of Value function: 0.845254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 880
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0284874
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 881
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108453
New value of Value function: 0.00108453
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 882
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600195
New value of Value function: 0.0602518
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 883
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.95216e-05
New value of Value function: 0.00108453
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 884
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108453
New value of Value function: 0.00108453
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 885
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.119305
New value of Value function: 0.119305
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 886
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00155001
New value of Value function: 0.014372
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 887
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021475
New value of Value function: 0.0284874
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 888
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021475
New value of Value function: 0.119305
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 889
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.177432
New value of Value function: 0.177432
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 890
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0431323
New value of Value function: 0.0431323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.410229
New value of Value function: 0.845254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0.843563
New value of Value function: 0.843563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.417208
New value of Value function: 0.843563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.34311
New value of Value function: 0.843563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.841876
New value of Value function: 0.841876
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 180
New value of Q matrix: 0.865297
New value of Value function: 0.865297
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 897
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600187
New value of Value function: 0.0600187
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 898
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.95216e-05
New value of Value function: 1.95216e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 899
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00108236
New value of Value function: 0.00108453
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 900
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108236
New value of Value function: 0.00108236
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 901
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108034
New value of Value function: 0.00108236
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 902
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0598986
New value of Value function: 0.0598986
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 903
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94825e-05
New value of Value function: 0.0598986
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 904
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0010802
New value of Value function: 0.00108236
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 905
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0010802
New value of Value function: 0.00108034
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 906
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.85772e-05
New value of Value function: 0.00108034
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 907
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021369
New value of Value function: 0.0021369
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 908
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118701
New value of Value function: 0.118701
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 909
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.51388e-07
New value of Value function: 1.95216e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 910
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 1.95216e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 911
----------
State: 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0155754
New value of Value function: 0.0155754
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 181
New value of Q matrix: 0.887992
New value of Value function: 0.887992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 913
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0159838
New value of Value function: 0.0159838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 182
New value of Q matrix: 0.910519
New value of Value function: 0.910519
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 915
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000287709
New value of Value function: 0.0159838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 916
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000287709
New value of Value function: 0.0159838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 917
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000287709
New value of Value function: 0.0159838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 918
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0320535
New value of Value function: 0.0320535
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 183
New value of Q matrix: 0.932886
New value of Value function: 0.932886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 920
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000858918
New value of Value function: 0.0320535
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 921
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0482044
New value of Value function: 0.0482044
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.35304
New value of Value function: 0.932886
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 184
New value of Q matrix: 0.954229
New value of Value function: 0.954229
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 924
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 925
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 926
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 927
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 928
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 929
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 930
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 931
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 932
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 933
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 934
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 935
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 936
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 937
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610584
New value of Value function: 0.0610584
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 938
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 939
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.4992e-07
New value of Value function: 3.4992e-07
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 940
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.90575e-05
New value of Value function: 1.90575e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 941
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3.4992e-07
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 942
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 943
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 944
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 945
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 946
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 947
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109905
New value of Value function: 0.00109905
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 948
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.119837
New value of Value function: 0.119837
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 949
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.85957e-07
New value of Value function: 6.85957e-07
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 950
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.84643e-05
New value of Value function: 3.84643e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 951
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0629618
New value of Value function: 0.0629618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 952
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00170942
New value of Value function: 0.0482044
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 953
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00105834
New value of Value function: 0.0482044
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 954
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00323786
New value of Value function: 0.0431323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 955
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.12257
New value of Value function: 0.12257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 956
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0479663
New value of Value function: 0.0479663
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 957
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0806081
New value of Value function: 0.0806081
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 958
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213662
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 959
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.177407
New value of Value function: 0.177407
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 960
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0602509
New value of Value function: 0.0602509
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 961
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0171761
New value of Value function: 0.0806081
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.936595
New value of Value function: 0.936595
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 963
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0168587
New value of Value function: 0.0806081
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 964
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 186
New value of Q matrix: 0.958726
New value of Value function: 0.958726
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 965
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0642641
New value of Value function: 0.0642641
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 187
New value of Q matrix: 0.980709
New value of Value function: 0.980709
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 967
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0806316
New value of Value function: 0.0806316
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.426517
New value of Value function: 0.980709
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0.978747
New value of Value function: 0.978747
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 189
New value of Q matrix: 1.00062
New value of Value function: 1.00062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 971
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0970302
New value of Value function: 0.0970302
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 78
New value of Q matrix: 0.47367
New value of Value function: 1.00062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 973
----------
State: 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0617465
New value of Value function: 0.0617465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 974
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.096201
New value of Value function: 0.096201
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 975
----------
State: 8593
	Distance: 10
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0610845
New value of Value function: 0.0617465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 976
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00528721
New value of Value function: 0.0602509
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 977
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00319333
New value of Value function: 0.177407
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 978
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0320958
New value of Value function: 0.177407
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 190
New value of Q matrix: 1.0238
New value of Value function: 1.0238
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 980
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.234943
New value of Value function: 0.234943
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 981
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0601259
New value of Value function: 0.0601259
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 982
----------
State: 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0184285
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 191
New value of Q matrix: 1.04506
New value of Value function: 1.04506
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 984
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.113088
New value of Value function: 0.113088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 192
New value of Q matrix: 1.06619
New value of Value function: 1.06619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 986
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00371082
New value of Value function: 0.113088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 987
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00567218
New value of Value function: 0.113088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 988
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00220627
New value of Value function: 0.113088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 989
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0610586
New value of Value function: 0.12257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 990
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.92357e-07
New value of Value function: 6.92357e-07
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 991
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.92357e-07
New value of Value function: 3.84643e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 992
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600377
New value of Value function: 0.0600377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 993
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00203558
New value of Value function: 0.00203558
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 994
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.130018
New value of Value function: 0.130018
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.437178
New value of Value function: 1.06619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.43801
New value of Value function: 1.06619
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 1.06406
New value of Value function: 1.06406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.448403
New value of Value function: 1.06406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.447587
New value of Value function: 1.06406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 1.06193
New value of Value function: 1.06193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1001
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.365094
New value of Value function: 1.06193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1002
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.457751
New value of Value function: 1.06193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.376907
New value of Value function: 1.06193
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1004
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 1.05981
New value of Value function: 1.05981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1005
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 196
New value of Q matrix: 1.07861
New value of Value function: 1.07861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1006
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1007
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.66405e-05
New value of Value function: 3.66405e-05
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1008
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.66405e-05
New value of Value function: 0.00203558
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1009
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600359
New value of Value function: 0.0600359
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1010
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1011
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1012
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1013
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1014
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1015
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1016
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.23472e-08
New value of Value function: 1.23472e-08
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1017
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.23472e-08
New value of Value function: 6.85957e-07
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1018
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0600007
New value of Value function: 0.0600007
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1019
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108002
New value of Value function: 0.00108002
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1020
----------
State: 5961
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.11882
New value of Value function: 0.11882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1021
----------
State: 5233
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00108068
New value of Value function: 0.00108068
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1022
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108136
New value of Value function: 0.0600377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1023
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108068
New value of Value function: 0.0600377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1024
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108068
New value of Value function: 0.0600377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1025
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.84593e-05
New value of Value function: 0.0600377
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1026
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215775
New value of Value function: 0.00215775
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1027
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118837
New value of Value function: 0.118837
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1028
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1029
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213907
New value of Value function: 0.00213907
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1030
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.11646
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1031
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600385
New value of Value function: 0.0600385
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1032
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00419257
New value of Value function: 0.00419257
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1033
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00315535
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1034
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.65296e-05
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1035
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00421088
New value of Value function: 0.00421088
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1036
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00315601
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1037
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00518853
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1038
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00315535
New value of Value function: 0.11646
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1039
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.115212
New value of Value function: 0.115212
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1040
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00108069
New value of Value function: 0.0600385
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1041
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215707
New value of Value function: 0.0600385
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1042
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.119598
New value of Value function: 0.119598
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1043
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0610807
New value of Value function: 0.119598
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1044
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00213977
New value of Value function: 0.0600385
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1045
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0599184
New value of Value function: 0.0599184
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1046
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107853
New value of Value function: 0.0599184
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1047
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0597986
New value of Value function: 0.0597986
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1048
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.059679
New value of Value function: 0.059679
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1049
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0595596
New value of Value function: 0.0595596
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1050
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0594405
New value of Value function: 0.0594405
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1051
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0593216
New value of Value function: 0.0593216
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1052
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.059203
New value of Value function: 0.059203
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1053
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00426669
New value of Value function: 0.059203
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1054
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.119598
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1055
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1056
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1057
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1058
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1059
----------
State: 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1060
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215276
New value of Value function: 0.00215276
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1061
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.119358
New value of Value function: 0.119358
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1062
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00214845
New value of Value function: 0.119358
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1063
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00425393
New value of Value function: 0.119358
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1064
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0063173
New value of Value function: 0.119358
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1065
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.11912
New value of Value function: 0.11912
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1066
----------
State: 6745
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6749
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.116737
New value of Value function: 0.116737
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1067
----------
State: 6749
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1068
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1069
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1070
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1071
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1072
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1073
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1074
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.37395e-07
New value of Value function: 2.37395e-07
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1075
----------
State: 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.31622e-05
New value of Value function: 1.31622e-05
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1076
----------
State: 8261
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1077
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1078
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1079
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1080
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.76104e-05
New value of Value function: 3.76104e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1081
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.76104e-05
New value of Value function: 0.00208947
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1082
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.060038
New value of Value function: 0.060038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1083
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00323231
New value of Value function: 0.00323231
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1084
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.174968
New value of Value function: 0.174968
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1085
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00314942
New value of Value function: 0.0602518
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1086
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.172553
New value of Value function: 0.172553
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1087
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.064229
New value of Value function: 0.064229
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1088
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.234473
New value of Value function: 0.234473
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1089
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00222536
New value of Value function: 0.234473
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1090
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0620437
New value of Value function: 0.12257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1091
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.12257
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1092
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0010584
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1093
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1094
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1095
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1096
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1097
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1098
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1099
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1100
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1101
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1102
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108068
New value of Value function: 0.00108068
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1103
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00111754
New value of Value function: 0.060038
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1104
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0631277
New value of Value function: 0.0631277
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1105
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00105668
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1106
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00108068
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1107
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600387
New value of Value function: 0.0600387
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1108
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021097
New value of Value function: 0.0021097
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1109
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1110
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.060038
New value of Value function: 0.060038
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1111
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0641413
New value of Value function: 0.0641413
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1112
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00122954
New value of Value function: 0.115212
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1113
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108068
New value of Value function: 0.0641413
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1114
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.119992
New value of Value function: 0.119992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1115
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0628779
New value of Value function: 0.0628779
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1116
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1117
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00321825
New value of Value function: 0.00321825
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1118
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0609599
New value of Value function: 0.119992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1119
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0010807
New value of Value function: 0.119992
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1120
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0600387
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1121
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1122
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1123
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1124
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1125
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1126
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1127
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1128
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107707
New value of Value function: 0.00107707
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1129
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118911
New value of Value function: 0.118911
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1130
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0341364
New value of Value function: 0.0341364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.45885
New value of Value function: 1.07861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.388784
New value of Value function: 1.07861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 1.07646
New value of Value function: 1.07646
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 1.0743
New value of Value function: 1.0743
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 1.07216
New value of Value function: 1.07216
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 1.07001
New value of Value function: 1.07001
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 1.06787
New value of Value function: 1.06787
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.40023
New value of Value function: 1.06787
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 1.06574
New value of Value function: 1.06574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 1.0636
New value of Value function: 1.0636
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.483341
New value of Value function: 1.0636
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 1.06148
New value of Value function: 1.06148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.492781
New value of Value function: 1.06148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.46878
New value of Value function: 1.06148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.478511
New value of Value function: 1.06148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 1.05935
New value of Value function: 1.05935
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 1.05723
New value of Value function: 1.05723
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 1.05512
New value of Value function: 1.05512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.487933
New value of Value function: 1.05512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.411218
New value of Value function: 1.05512
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 1.05301
New value of Value function: 1.05301
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 1.0509
New value of Value function: 1.0509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 1.0488
New value of Value function: 1.0488
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 1.0467
New value of Value function: 1.0467
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 1.04461
New value of Value function: 1.04461
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 1.04252
New value of Value function: 1.04252
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 1.04044
New value of Value function: 1.04044
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 1.03836
New value of Value function: 1.03836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 1.03628
New value of Value function: 1.03628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 1.03421
New value of Value function: 1.03421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 1.03214
New value of Value function: 1.03214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 1.03007
New value of Value function: 1.03007
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.467137
New value of Value function: 1.03007
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 1.02801
New value of Value function: 1.02801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.476298
New value of Value function: 1.02801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 1.02596
New value of Value function: 1.02596
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.48524
New value of Value function: 1.02596
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 1.02391
New value of Value function: 1.02391
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 1.02186
New value of Value function: 1.02186
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 1.01981
New value of Value function: 1.01981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 1.01777
New value of Value function: 1.01777
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.501245
New value of Value function: 1.01777
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 1.01574
New value of Value function: 1.01574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 1.01371
New value of Value function: 1.01371
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 1.01168
New value of Value function: 1.01168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 1.00966
New value of Value function: 1.00966
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.493709
New value of Value function: 1.00966
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 1.00764
New value of Value function: 1.00764
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.496311
New value of Value function: 1.00764
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 1.00562
New value of Value function: 1.00562
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 1.00361
New value of Value function: 1.00361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.50445
New value of Value function: 1.00361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 1.0016
New value of Value function: 1.0016
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.421022
New value of Value function: 1.0016
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.509249
New value of Value function: 1.0016
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.999601
New value of Value function: 0.999601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.512354
New value of Value function: 0.999601
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.997602
New value of Value function: 0.997602
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.995606
New value of Value function: 0.995606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.430523
New value of Value function: 0.995606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.439833
New value of Value function: 0.995606
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.993615
New value of Value function: 0.993615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.991628
New value of Value function: 0.991628
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.989645
New value of Value function: 0.989645
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0.987665
New value of Value function: 0.987665
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.519885
New value of Value function: 0.987665
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0.98569
New value of Value function: 0.98569
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.983719
New value of Value function: 0.983719
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.965495
New value of Value function: 0.965495
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1200
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.123216
New value of Value function: 0.123216
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1201
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00734998
New value of Value function: 0.234473
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1202
----------
State: 6241
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.232002
New value of Value function: 0.232002
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1203
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.0407764
New value of Value function: 0.123216
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1204
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000776381
New value of Value function: 0.0431323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1205
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0596485
New value of Value function: 0.0596485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 244
New value of Q matrix: 0.987259
New value of Value function: 0.987259
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1207
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0762262
New value of Value function: 0.0762262
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 245
New value of Q matrix: 1.00985
New value of Value function: 1.00985
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1209
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.145595
New value of Value function: 0.145595
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 246
New value of Q matrix: 1.03103
New value of Value function: 1.03103
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1211
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0932602
New value of Value function: 0.0932602
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 247
New value of Q matrix: 1.05303
New value of Value function: 1.05303
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1213
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00723742
New value of Value function: 0.145595
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1214
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.11035
New value of Value function: 0.11035
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 248
New value of Q matrix: 1.07459
New value of Value function: 1.07459
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1216
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.162026
New value of Value function: 0.162026
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.450379
New value of Value function: 1.07459
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.518407
New value of Value function: 1.07459
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 249
New value of Q matrix: 1.09508
New value of Value function: 1.09508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1220
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.127854
New value of Value function: 0.127854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.529199
New value of Value function: 1.09508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.461083
New value of Value function: 1.09508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.471573
New value of Value function: 1.09508
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 250
New value of Q matrix: 1.11426
New value of Value function: 1.11426
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1225
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0600057
New value of Value function: 0.0600057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1226
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0200568
New value of Value function: 0.0600057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 251
New value of Q matrix: 1.13198
New value of Value function: 1.13198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1228
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010801
New value of Value function: 0.0010801
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1229
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00626157
New value of Value function: 0.0600057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1230
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.118825
New value of Value function: 0.118825
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1231
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94418e-05
New value of Value function: 0.0010801
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1232
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00107794
New value of Value function: 0.00107794
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1233
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00107579
New value of Value function: 0.00107579
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1234
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00107363
New value of Value function: 0.00107363
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1235
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00107149
New value of Value function: 0.00107149
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1236
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00106934
New value of Value function: 0.00106934
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1237
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213885
New value of Value function: 0.00213885
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1238
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00109978
New value of Value function: 0.118825
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1239
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0599158
New value of Value function: 0.0599158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1240
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00413372
New value of Value function: 0.0599158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1241
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.176487
New value of Value function: 0.176487
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1242
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00527284
New value of Value function: 0.00527284
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1243
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00215627
New value of Value function: 0.176487
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1244
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107849
New value of Value function: 0.0599158
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1245
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.061634
New value of Value function: 0.061634
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1246
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.21888
New value of Value function: 0.21888
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1247
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00114287
New value of Value function: 0.00527284
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1248
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00526229
New value of Value function: 0.00526229
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1249
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00909689
New value of Value function: 0.00909689
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1250
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.234878
New value of Value function: 0.234878
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 252
New value of Q matrix: 1.15357
New value of Value function: 1.15357
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1252
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.250945
New value of Value function: 0.250945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 253
New value of Q matrix: 1.17501
New value of Value function: 1.17501
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1254
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00327155
New value of Value function: 0.250945
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1255
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0615107
New value of Value function: 0.0615107
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1256
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0613877
New value of Value function: 0.0613877
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1257
----------
State: 5345
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.12016
New value of Value function: 0.12016
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1258
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1259
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1260
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000163744
New value of Value function: 0.000163744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1261
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.88551e-05
New value of Value function: 0.00909689
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1262
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000324213
New value of Value function: 0.000324213
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1263
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00907869
New value of Value function: 0.00907869
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1264
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000182469
New value of Value function: 0.00907869
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1265
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0211502
New value of Value function: 0.0211502
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 254
New value of Q matrix: 1.19189
New value of Value function: 1.19189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1267
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00927782
New value of Value function: 0.0211502
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1268
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0421813
New value of Value function: 0.0421813
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.540069
New value of Value function: 1.19189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.529493
New value of Value function: 1.19189
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 255
New value of Q matrix: 1.20806
New value of Value function: 1.20806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1272
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0220628
New value of Value function: 0.0220628
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.521121
New value of Value function: 1.20806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1274
----------
State: 753
	Distance: 0
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.161511
New value of Value function: 0.161511
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1275
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0630828
New value of Value function: 0.0630828
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 256
New value of Q matrix: 1.22504
New value of Value function: 1.22504
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1277
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00125882
New value of Value function: 0.0630828
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1278
----------
State: 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0603971
New value of Value function: 0.0603971
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1279
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.004517
New value of Value function: 0.0220628
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1280
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.247013
New value of Value function: 0.247013
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1281
----------
State: 7809
	Distance: 9
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0631768
New value of Value function: 0.0631768
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 1282
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00655937
New value of Value function: 0.176487
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1283
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.303208
New value of Value function: 0.303208
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1284
----------
State: 4673
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00441041
New value of Value function: 0.0630828
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1285
----------
State: 5457
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0118859
New value of Value function: 0.176487
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 1286
----------
State: 5401
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00328159
New value of Value function: 0.303208
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1287
----------
State: 5289
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00618253
New value of Value function: 0.00618253
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 1288
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00516605
New value of Value function: 0.115212
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1289
----------
State: 6017
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.113973
New value of Value function: 0.113973
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 1290
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00316263
New value of Value function: 0.059203
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 1291
----------
State: 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6073
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0590846
New value of Value function: 0.0590846
New value of Policy matrix: 4

