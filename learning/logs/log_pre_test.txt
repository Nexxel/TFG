=======================================
Episode: 1
Iteration: 1
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 9
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 10
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 11
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118819
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 12
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213875
New value of Value function: 0.00213875
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 13
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213875
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 14
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00423472
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 15
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 16
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 17
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118819
New value of Value function: 0.118819
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 18
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 19
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 20
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 21
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 22
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 23
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 24
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 25
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 26
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 27
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 28
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 29
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 30
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 31
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 32
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 33
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 1.944e-05
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 34
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 35
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 36
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021384
New value of Value function: 0.0021384
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 37
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.1188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 38
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0031968
New value of Value function: 0.0031968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 39
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.176462
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 40
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.84912e-05
New value of Value function: 0.0021384
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 41
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.62126e-05
New value of Value function: 0.0021384
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 42
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00527196
New value of Value function: 0.00527196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 43
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00317632
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 44
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0631131
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 45
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.48952e-05
New value of Value function: 9.48952e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 46
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00317632
New value of Value function: 0.00527196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 47
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600949
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 48
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000169584
New value of Value function: 0.00527196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 49
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000261087
New value of Value function: 0.00527196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 50
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00628912
New value of Value function: 0.00628912
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 51
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.121853
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 52
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000206202
New value of Value function: 0.000206202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 53
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00627654
New value of Value function: 0.00627654
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 54
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00834284
New value of Value function: 0.00834284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 55
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.122592
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 56
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00317632
New value of Value function: 0.176462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 57
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.233083
New value of Value function: 0.233083
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 58
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00615101
New value of Value function: 0.00834284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 59
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 60
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601502
New value of Value function: 0.0601502
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 61
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0123715
New value of Value function: 0.0123715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.288644
New value of Value function: 0.288644
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 63
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010827
New value of Value function: 0.0123715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 64
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.0601502
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 65
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000222687
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 66
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000222687
New value of Value function: 0.0123715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 67
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00625068
New value of Value function: 0.0123715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 68
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0123467
New value of Value function: 0.0123467
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 69
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000440474
New value of Value function: 0.0123467
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 70
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00128329
New value of Value function: 0.0123467
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00634791
New value of Value function: 0.0123467
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 72
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0123221
New value of Value function: 0.0123221
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 73
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00147942
New value of Value function: 0.0123221
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 74
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0122974
New value of Value function: 0.0122974
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 75
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0172471
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 76
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.343182
New value of Value function: 0.343182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 77
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00176028
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 78
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000742112
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 79
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000566312
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 80
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00172908
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 81
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.00836e-06
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 82
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.040004
New value of Value function: 0.040004
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 84
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.00836e-06
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 85
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.00836e-06
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 86
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.93656e-06
New value of Value function: 0.000222687
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 87
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00072785
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.039924
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718632
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718632
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142289
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142289
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211307
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000718632
New value of Value function: 0.039924
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0398442
New value of Value function: 0.0398442
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000717195
New value of Value function: 0.0398442
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211163
New value of Value function: 0.0398442
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0397645
New value of Value function: 0.0397645
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142002
New value of Value function: 0.0397645
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0396849
New value of Value function: 0.0396849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00278372
New value of Value function: 0.0396849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00141718
New value of Value function: 0.0396849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00210595
New value of Value function: 0.0396849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.0789043
New value of Value function: 0.0789043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 105
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.70295e-05
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 106
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.31013e-05
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 107
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000323286
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 108
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0017076
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 109
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000231334
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 110
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000627268
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 111
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00103772
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 112
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.000865433
New value of Value function: 0.0172471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 113
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0230794
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 114
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.119308
New value of Value function: 0.343182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 115
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00126355
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 116
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00208888
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 117
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00663638
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 118
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00143239
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 119
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00691908
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 120
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00181917
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 121
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00165371
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 122
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0020602
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 123
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.97902e-05
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 124
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.22957e-05
New value of Value function: 0.00072785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 125
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0600414
New value of Value function: 0.0600414
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 126
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 127
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000415429
New value of Value function: 0.000415429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 128
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00203607
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 129
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00309975
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 130
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00103015
New value of Value function: 0.0600414
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 131
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00241077
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 132
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0041185
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 133
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0607208
New value of Value function: 0.0607208
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 134
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.000415429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 135
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 136
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 137
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00142028
New value of Value function: 0.00142028
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00349108
New value of Value function: 0.0789043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0787465
New value of Value function: 0.0787465
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00280627
New value of Value function: 0.0787465
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0048387
New value of Value function: 0.0787465
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00348127
New value of Value function: 0.0787465
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.078589
New value of Value function: 0.078589
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.117025
New value of Value function: 0.117025
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 145
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.47772e-06
New value of Value function: 0.000415429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 146
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.48059e-05
New value of Value function: 0.000415429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 147
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.47772e-06
New value of Value function: 0.000415429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 148
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00210645
New value of Value function: 0.00210645
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.154722
New value of Value function: 0.154722
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.7916e-05
New value of Value function: 0.00210645
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 151
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000445037
New value of Value function: 0.00210645
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 152
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000851565
New value of Value function: 0.00210645
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 153
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00277799
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 154
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00313786
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 155
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00719613
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 156
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00746763
New value of Value function: 0.0230794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 157
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0287951
New value of Value function: 0.0287951
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 158
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.180144
New value of Value function: 0.343182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 159
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.71163e-06
New value of Value function: 0.000206202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 160
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000720389
New value of Value function: 0.000720389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 161
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0343965
New value of Value function: 0.0343965
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 162
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118832
New value of Value function: 0.343182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 163
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.66044e-05
New value of Value function: 0.000720389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 164
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.2967e-05
New value of Value function: 0.000720389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 165
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.2967e-05
New value of Value function: 0.000720389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 166
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.56747e-05
New value of Value function: 0.000720389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 167
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00620244
New value of Value function: 0.00620244
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 168
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.39643
New value of Value function: 0.39643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 169
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00715479
New value of Value function: 0.00715479
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 170
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176513
New value of Value function: 0.39643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 171
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00111594
New value of Value function: 0.0031968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 172
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213875
New value of Value function: 0.0031968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 173
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600575
New value of Value function: 0.118819
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 174
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.75424e-05
New value of Value function: 0.0031968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 175
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000113934
New value of Value function: 0.0031968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 176
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00423472
New value of Value function: 0.00423472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 177
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00319715
New value of Value function: 0.118819
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 178
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.118582
New value of Value function: 0.118582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 179
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0609909
New value of Value function: 0.118582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 180
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0632094
New value of Value function: 0.118582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 181
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0062845
New value of Value function: 0.0062845
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 182
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00319287
New value of Value function: 0.118582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 183
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0619055
New value of Value function: 0.118582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 184
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.123346
New value of Value function: 0.123346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 185
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.175203
New value of Value function: 0.39643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 186
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0641655
New value of Value function: 0.123346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 187
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213875
New value of Value function: 0.123346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 188
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00327863
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 189
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0628876
New value of Value function: 0.123346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 190
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00423472
New value of Value function: 0.123346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 191
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610969
New value of Value function: 0.118819
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 192
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0043162
New value of Value function: 0.0043162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 193
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.181008
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 194
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0102698
New value of Value function: 0.0102698
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 195
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00638715
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 196
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0661403
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 197
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00951755
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 198
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0642632
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 199
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000113121
New value of Value function: 0.0062845
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 200
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00324599
New value of Value function: 0.0062845
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 201
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00941695
New value of Value function: 0.00941695
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 202
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0125853
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 203
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.064888
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 204
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0668484
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 205
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0155918
New value of Value function: 0.181008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 206
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.237557
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 207
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0135046
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 208
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0672539
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 209
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0690935
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 210
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0697875
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 211
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0726677
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 212
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0719877
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 213
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0680476
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 214
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.118582
New value of Value function: 0.118582
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 215
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.118345
New value of Value function: 0.118345
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 216
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0021302
New value of Value function: 0.118345
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 217
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0620052
New value of Value function: 0.118345
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 218
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00534326
New value of Value function: 0.118345
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 219
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.118108
New value of Value function: 0.118108
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 220
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.120843
New value of Value function: 0.120843
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 221
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00850591
New value of Value function: 0.00850591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 222
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.131457
New value of Value function: 0.237557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 223
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00326879
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 224
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.117921
New value of Value function: 0.120843
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 225
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.117738
New value of Value function: 0.120843
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 226
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.178579
New value of Value function: 0.178579
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 227
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000153106
New value of Value function: 0.00850591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 228
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00321442
New value of Value function: 0.00850591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 229
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00530202
New value of Value function: 0.178579
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 230
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.178222
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 231
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.118591
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 232
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00735802
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 233
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00519598
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 234
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00320799
New value of Value function: 0.00320799
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 235
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00844439
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 236
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0104189
New value of Value function: 0.178222
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 237
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.177865
New value of Value function: 0.177865
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 238
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.17751
New value of Value function: 0.17751
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 239
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.119414
New value of Value function: 0.17751
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 240
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.234113
New value of Value function: 0.234113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 241
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0126118
New value of Value function: 0.0126118
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 242
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.293049
New value of Value function: 0.293049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 243
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000354739
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 244
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0034465
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 245
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000353942
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 246
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00845595
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 247
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.347373
New value of Value function: 0.347373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 248
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0163172
New value of Value function: 0.0163172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 249
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.400719
New value of Value function: 0.400719
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 250
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0063721
New value of Value function: 0.0163172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 251
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00653836
New value of Value function: 0.0163172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 252
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00099969
New value of Value function: 0.0163172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 253
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0162845
New value of Value function: 0.0162845
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 254
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0231718
New value of Value function: 0.0231718
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 255
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.453122
New value of Value function: 0.453122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 256
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0308645
New value of Value function: 0.0308645
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 257
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0748428
New value of Value function: 0.453122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 258
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.133573
New value of Value function: 0.453122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 259
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00421403
New value of Value function: 0.0126118
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 260
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.12124
New value of Value function: 0.234113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 261
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00930609
New value of Value function: 0.234113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 262
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.289657
New value of Value function: 0.289657
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 263
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000377057
New value of Value function: 0.0126118
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 264
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0125866
New value of Value function: 0.0125866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 265
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00128496
New value of Value function: 0.0125866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 266
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00125926
New value of Value function: 0.0125866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 267
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 268
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000226559
New value of Value function: 0.000226559
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 269
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000596074
New value of Value function: 0.0125866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 270
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000810712
New value of Value function: 0.0125866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 271
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0125614
New value of Value function: 0.0125614
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 272
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0125533
New value of Value function: 0.0125533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 273
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00360353
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 274
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0043557
New value of Value function: 0.0125533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 275
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0125453
New value of Value function: 0.0125453
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 276
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00375727
New value of Value function: 0.0135046
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 277
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0125375
New value of Value function: 0.0125375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 278
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0134776
New value of Value function: 0.0134776
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 279
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0039078
New value of Value function: 0.0134776
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 280
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00449427
New value of Value function: 0.0125375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 281
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0125293
New value of Value function: 0.0125293
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 282
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00405517
New value of Value function: 0.0134776
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 283
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0125213
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 284
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00852943
New value of Value function: 0.0134776
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 285
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0134507
New value of Value function: 0.0134507
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 286
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000589756
New value of Value function: 0.0134507
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 287
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000588976
New value of Value function: 0.0134507
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 288
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000820073
New value of Value function: 0.0134507
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 289
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00421618
New value of Value function: 0.0134507
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 290
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0605772
New value of Value function: 0.0605772
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 291
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00109039
New value of Value function: 0.00109039
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 292
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0142721
New value of Value function: 0.0605772
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 293
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.060456
New value of Value function: 0.060456
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 294
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00944705
New value of Value function: 0.060456
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 295
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0150748
New value of Value function: 0.060456
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 296
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00522007
New value of Value function: 0.060456
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 297
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0603351
New value of Value function: 0.0603351
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 298
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0018897
New value of Value function: 0.0603351
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 299
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0602145
New value of Value function: 0.0602145
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 300
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.060094
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 301
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.015855
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 302
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00534105
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 303
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00101988
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 304
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00122487
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 305
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00145946
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 306
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00337552
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 307
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00462976
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 308
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00142575
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 309
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00476255
New value of Value function: 0.0125213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 310
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0124963
New value of Value function: 0.0124963
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 311
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.0613972
New value of Value function: 0.0613972
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 312
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00110515
New value of Value function: 0.00110515
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 313
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00253542
New value of Value function: 0.0613972
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 314
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0612744
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 315
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00248879
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 316
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 317
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 318
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 319
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 320
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 321
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 322
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 323
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00107784
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 324
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00107572
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 325
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213875
New value of Value function: 0.00213875
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 326
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108035
New value of Value function: 0.0600194
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 327
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118858
New value of Value function: 0.118858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 328
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213944
New value of Value function: 0.00213944
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 329
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00132497
New value of Value function: 0.118858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 330
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00441095
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 331
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0133493
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 332
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.014164
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 333
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0166196
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 334
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00633717
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 335
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00354195
New value of Value function: 0.0612744
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 336
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0611519
New value of Value function: 0.0611519
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 337
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00576804
New value of Value function: 0.0611519
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 338
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00675341
New value of Value function: 0.0611519
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 339
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0610296
New value of Value function: 0.0610296
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 340
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0149793
New value of Value function: 0.0610296
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 341
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0609075
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 342
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00541906
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 343
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00771468
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 344
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0157614
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 345
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0173689
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 346
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0181032
New value of Value function: 0.060094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 347
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0599738
New value of Value function: 0.0599738
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 348
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00730676
New value of Value function: 0.0599738
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 349
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00456745
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 350
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00865672
New value of Value function: 0.0609075
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 351
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0607857
New value of Value function: 0.0607857
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 352
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0606641
New value of Value function: 0.0606641
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 353
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0605428
New value of Value function: 0.0605428
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 354
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00661554
New value of Value function: 0.0605428
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 355
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00238824
New value of Value function: 0.118858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 356
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0604217
New value of Value function: 0.0604217
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 357
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00957118
New value of Value function: 0.0604217
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 358
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0603009
New value of Value function: 0.0603009
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 359
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.0693996
New value of Value function: 0.0693996
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 360
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00124919
New value of Value function: 0.00124919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 361
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.0665057
New value of Value function: 0.0693996
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 362
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00213944
New value of Value function: 0.00213944
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 363
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600385
New value of Value function: 0.118858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 364
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.85098e-05
New value of Value function: 0.00213944
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 365
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213516
New value of Value function: 0.00213875
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 366
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0024734
New value of Value function: 0.0024734
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 367
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00655988
New value of Value function: 0.0693996
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 368
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.128056
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 369
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00214117
New value of Value function: 0.0024734
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 370
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.45213e-05
New value of Value function: 0.0024734
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 371
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00246846
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 372
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00112748
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 373
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.80631e-05
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 374
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00209835
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 375
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.44322e-05
New value of Value function: 4.44322e-05
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 376
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.44322e-05
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 377
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00114936
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 378
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.79758e-05
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 379
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00209488
New value of Value function: 0.00246846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 380
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00423541
New value of Value function: 0.00423541
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 381
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00464549
New value of Value function: 0.118858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 382
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.067315
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 383
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118914
New value of Value function: 0.118914
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 384
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00113045
New value of Value function: 0.00423541
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 385
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.62374e-05
New value of Value function: 0.00423541
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 386
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00422694
New value of Value function: 0.00422694
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 387
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00421849
New value of Value function: 0.00421849
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 388
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00627457
New value of Value function: 0.00627457
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 389
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.176593
New value of Value function: 0.176593
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 390
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00527113
New value of Value function: 0.00627457
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 391
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.17624
New value of Value function: 0.17624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 392
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.232828
New value of Value function: 0.232828
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 393
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00626202
New value of Value function: 0.00626202
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 394
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00624949
New value of Value function: 0.00624949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 395
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000187204
New value of Value function: 0.00624949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 396
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00529875
New value of Value function: 0.00624949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 397
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.288284
New value of Value function: 0.288284
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 398
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.77396e-05
New value of Value function: 0.00624949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 399
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 400
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000112491
New value of Value function: 0.000112491
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 401
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.006237
New value of Value function: 0.006237
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 402
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000149251
New value of Value function: 0.006237
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 403
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00527798
New value of Value function: 0.006237
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 404
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000258532
New value of Value function: 0.006237
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 405
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00622452
New value of Value function: 0.00622452
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 406
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00621207
New value of Value function: 0.00621207
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 407
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00747743
New value of Value function: 0.00747743
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 408
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.0664731
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 409
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00724209
New value of Value function: 0.00724209
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 410
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.121725
New value of Value function: 0.288284
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 411
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.287708
New value of Value function: 0.287708
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 412
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0639787
New value of Value function: 0.287708
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 413
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00973131
New value of Value function: 0.287708
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 414
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0611933
New value of Value function: 0.287708
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 415
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00963289
New value of Value function: 0.00963289
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 416
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0711475
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 417
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.287132
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 418
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0118417
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 419
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.0755765
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 420
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00343139
New value of Value function: 0.00724209
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 421
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0720295
New value of Value function: 0.128056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 422
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.1278
New value of Value function: 0.1278
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 423
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.127544
New value of Value function: 0.127544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 424
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0674394
New value of Value function: 0.127544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 425
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.185124
New value of Value function: 0.185124
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 426
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00727064
New value of Value function: 0.00727064
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 427
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00957111
New value of Value function: 0.00957111
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 428
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00349363
New value of Value function: 0.00727064
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 429
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00675599
New value of Value function: 0.00727064
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 430
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0757573
New value of Value function: 0.185124
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 431
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0678675
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 432
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0167732
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 433
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0651379
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 434
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.124459
New value of Value function: 0.287132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 435
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.286558
New value of Value function: 0.286558
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 436
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.127128
New value of Value function: 0.286558
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 437
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.285985
New value of Value function: 0.285985
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 438
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.01977
New value of Value function: 0.285985
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 439
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0773972
New value of Value function: 0.185124
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 440
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0694229
New value of Value function: 0.185124
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 441
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.184754
New value of Value function: 0.184754
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 442
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.241189
New value of Value function: 0.241189
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 443
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0072561
New value of Value function: 0.0072561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 444
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0025497
New value of Value function: 0.0072561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 445
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00724159
New value of Value function: 0.00724159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 446
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00726904
New value of Value function: 0.00726904
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 447
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000425641
New value of Value function: 0.00957111
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 448
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00951053
New value of Value function: 0.00951053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 449
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0024995
New value of Value function: 0.00726904
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 450
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000130843
New value of Value function: 0.000130843
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 451
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0072545
New value of Value function: 0.0072545
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 452
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0072806
New value of Value function: 0.0072806
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 453
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00536396
New value of Value function: 0.00951053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 454
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00945137
New value of Value function: 0.00945137
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 455
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0122827
New value of Value function: 0.0122827
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 456
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0689828
New value of Value function: 0.285985
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 457
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.340435
New value of Value function: 0.340435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 458
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0136037
New value of Value function: 0.0136037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 459
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.119316
New value of Value function: 0.241189
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 460
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0122819
New value of Value function: 0.0122819
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 461
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0135527
New value of Value function: 0.0135527
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 462
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0122802
New value of Value function: 0.0122802
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 463
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00550063
New value of Value function: 0.0135527
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 464
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000427409
New value of Value function: 0.0135527
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 465
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000420886
New value of Value function: 0.0135527
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 466
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000354191
New value of Value function: 0.000354191
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 467
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0135256
New value of Value function: 0.0135256
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 468
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0175965
New value of Value function: 0.0175965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 469
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.296368
New value of Value function: 0.296368
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 470
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.58987e-05
New value of Value function: 0.000130843
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 471
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000221044
New value of Value function: 0.000221044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 472
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0120386
New value of Value function: 0.0120386
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 473
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.89596e-05
New value of Value function: 0.000221044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 474
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000344921
New value of Value function: 0.000344921
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 475
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000302997
New value of Value function: 0.0120386
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 476
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000303145
New value of Value function: 0.0120386
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 477
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.41889e-05
New value of Value function: 0.000344921
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 478
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.000344921
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 479
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 480
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 481
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 482
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 483
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 484
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 485
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 486
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.05988
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 487
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 488
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 489
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.05988
New value of Value function: 0.05988
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 490
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107784
New value of Value function: 0.05988
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 491
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107784
New value of Value function: 0.05988
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 492
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00107784
New value of Value function: 0.05988
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 493
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 494
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 495
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 496
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.84912e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 497
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.84912e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 498
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.71614e-05
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 499
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010584
New value of Value function: 0.0010584
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 500
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 501
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 502
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 503
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 504
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 505
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 506
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 507
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 508
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90512e-05
New value of Value function: 1.90512e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 509
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00103757
New value of Value function: 0.00103757
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 510
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.90131e-05
New value of Value function: 1.90131e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 511
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.89751e-05
New value of Value function: 1.89751e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 512
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.41551e-07
New value of Value function: 1.89751e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 513
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.76272e-07
New value of Value function: 1.89751e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 514
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.89371e-05
New value of Value function: 1.89371e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 515
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 1.89371e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 516
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 517
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 518
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 519
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 520
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.002785
New value of Value function: 0.002785
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00551305
New value of Value function: 0.154722
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.0447921
New value of Value function: 0.154722
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 523
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.013e-05
New value of Value function: 0.002785
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 524
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00277943
New value of Value function: 0.00277943
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 525
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00277387
New value of Value function: 0.00277387
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 526
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00276832
New value of Value function: 0.00276832
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 527
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00276279
New value of Value function: 0.00276279
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 528
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.97301e-05
New value of Value function: 0.00276279
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 529
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.97301e-05
New value of Value function: 0.00276279
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 530
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00283373
New value of Value function: 0.00283373
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.0839472
New value of Value function: 0.154722
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 532
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000100135
New value of Value function: 0.00283373
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 533
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.97428e-05
New value of Value function: 0.00283373
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 534
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0627771
New value of Value function: 0.0627771
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 535
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 536
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00112999
New value of Value function: 0.00112999
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 537
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0626515
New value of Value function: 0.0626515
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 538
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0641835
New value of Value function: 0.0641835
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.154413
New value of Value function: 0.154413
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.154104
New value of Value function: 0.154104
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.153796
New value of Value function: 0.153796
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.153488
New value of Value function: 0.153488
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.153181
New value of Value function: 0.153181
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.152875
New value of Value function: 0.152875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00815453
New value of Value function: 0.152875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0107432
New value of Value function: 0.152875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.152569
New value of Value function: 0.152569
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0132746
New value of Value function: 0.152569
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.152264
New value of Value function: 0.152264
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.151959
New value of Value function: 0.151959
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0850035
New value of Value function: 0.151959
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.151655
New value of Value function: 0.151655
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.151352
New value of Value function: 0.151352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.151049
New value of Value function: 0.151049
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.150747
New value of Value function: 0.150747
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0054636
New value of Value function: 0.150747
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.150446
New value of Value function: 0.150446
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00611967
New value of Value function: 0.150446
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0157171
New value of Value function: 0.150446
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.150145
New value of Value function: 0.150145
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.149845
New value of Value function: 0.149845
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.149545
New value of Value function: 0.149545
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.149246
New value of Value function: 0.149246
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.148947
New value of Value function: 0.148947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.148649
New value of Value function: 0.148649
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0180784
New value of Value function: 0.148649
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00803002
New value of Value function: 0.148649
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.148352
New value of Value function: 0.148352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0859738
New value of Value function: 0.148352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.148055
New value of Value function: 0.148055
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.147759
New value of Value function: 0.147759
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00865694
New value of Value function: 0.147759
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0105291
New value of Value function: 0.147759
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0111435
New value of Value function: 0.147759
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.147464
New value of Value function: 0.147464
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0129729
New value of Value function: 0.147464
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.147169
New value of Value function: 0.147169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0869034
New value of Value function: 0.147169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0153624
New value of Value function: 0.147169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0203659
New value of Value function: 0.147169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0135696
New value of Value function: 0.147169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.146875
New value of Value function: 0.146875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0176989
New value of Value function: 0.146875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0878091
New value of Value function: 0.146875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.146581
New value of Value function: 0.146581
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.146288
New value of Value function: 0.146288
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.145995
New value of Value function: 0.145995
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.145703
New value of Value function: 0.145703
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.145412
New value of Value function: 0.145412
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0159157
New value of Value function: 0.145412
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.145121
New value of Value function: 0.145121
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0199571
New value of Value function: 0.145121
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.088665
New value of Value function: 0.145121
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.144831
New value of Value function: 0.144831
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0221649
New value of Value function: 0.144831
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0225656
New value of Value function: 0.144831
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.144541
New value of Value function: 0.144541
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.144252
New value of Value function: 0.144252
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.143963
New value of Value function: 0.143963
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0894831
New value of Value function: 0.143963
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.143675
New value of Value function: 0.143675
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0247004
New value of Value function: 0.143675
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.143388
New value of Value function: 0.143388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0243026
New value of Value function: 0.143388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0263976
New value of Value function: 0.143388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0284506
New value of Value function: 0.143388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.143101
New value of Value function: 0.143101
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.142815
New value of Value function: 0.142815
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.018168
New value of Value function: 0.142815
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.142529
New value of Value function: 0.142529
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.142244
New value of Value function: 0.142244
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0902538
New value of Value function: 0.142244
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.14196
New value of Value function: 0.14196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0304369
New value of Value function: 0.14196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0267617
New value of Value function: 0.14196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.141676
New value of Value function: 0.141676
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.141393
New value of Value function: 0.141393
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0203497
New value of Value function: 0.141393
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.14111
New value of Value function: 0.14111
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0323681
New value of Value function: 0.14111
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0287664
New value of Value function: 0.14111
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0307311
New value of Value function: 0.14111
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.140828
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0342556
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0909836
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0224776
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0361054
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0379182
New value of Value function: 0.140828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.140546
New value of Value function: 0.140546
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0916938
New value of Value function: 0.140546
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0923898
New value of Value function: 0.140546
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.140265
New value of Value function: 0.140265
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0396846
New value of Value function: 0.140265
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0245528
New value of Value function: 0.140265
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0930667
New value of Value function: 0.140265
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.139984
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0414106
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0326362
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0937251
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0265815
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0431021
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0943703
New value of Value function: 0.139984
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.139704
New value of Value function: 0.139704
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.139425
New value of Value function: 0.139425
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0344931
New value of Value function: 0.139425
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0285595
New value of Value function: 0.139425
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.139146
New value of Value function: 0.139146
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.138868
New value of Value function: 0.138868
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.13859
New value of Value function: 0.13859
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.138313
New value of Value function: 0.138313
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.138036
New value of Value function: 0.138036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.13776
New value of Value function: 0.13776
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.030468
New value of Value function: 0.13776
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.137485
New value of Value function: 0.137485
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0447148
New value of Value function: 0.137485
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.13721
New value of Value function: 0.13721
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 657
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.036273
New value of Value function: 0.13721
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.136935
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0323235
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0462854
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0478245
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0949478
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0341419
New value of Value function: 0.136935
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.136661
New value of Value function: 0.136661
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.136388
New value of Value function: 0.136388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.049323
New value of Value function: 0.136388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0955038
New value of Value function: 0.136388
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.136115
New value of Value function: 0.136115
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0507866
New value of Value function: 0.136115
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.135843
New value of Value function: 0.135843
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.135571
New value of Value function: 0.135571
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.1353
New value of Value function: 0.1353
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0379829
New value of Value function: 0.1353
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.13503
New value of Value function: 0.13503
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.13476
New value of Value function: 0.13476
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0521965
New value of Value function: 0.13476
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0960194
New value of Value function: 0.13476
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.13449
New value of Value function: 0.13449
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.134221
New value of Value function: 0.134221
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.096515
New value of Value function: 0.134221
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.133953
New value of Value function: 0.133953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0535638
New value of Value function: 0.133953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0358702
New value of Value function: 0.133953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0375639
New value of Value function: 0.133953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0549036
New value of Value function: 0.133953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.133685
New value of Value function: 0.133685
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.096991
New value of Value function: 0.133685
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.039219
New value of Value function: 0.133685
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.133417
New value of Value function: 0.133417
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0396248
New value of Value function: 0.133417
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0562071
New value of Value function: 0.133417
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.133151
New value of Value function: 0.133151
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.041229
New value of Value function: 0.133151
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.132884
New value of Value function: 0.132884
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 695
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.132619
New value of Value function: 0.132619
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.132353
New value of Value function: 0.132353
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.132089
New value of Value function: 0.132089
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0574605
New value of Value function: 0.132089
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.131824
New value of Value function: 0.131824
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.131561
New value of Value function: 0.131561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0586794
New value of Value function: 0.131561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0427725
New value of Value function: 0.131561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0598739
New value of Value function: 0.131561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0974193
New value of Value function: 0.131561
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.131298
New value of Value function: 0.131298
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.131035
New value of Value function: 0.131035
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.130773
New value of Value function: 0.130773
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.044271
New value of Value function: 0.130773
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.130511
New value of Value function: 0.130511
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.13025
New value of Value function: 0.13025
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.12999
New value of Value function: 0.12999
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.12973
New value of Value function: 0.12973
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.12947
New value of Value function: 0.12947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.129212
New value of Value function: 0.129212
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0457114
New value of Value function: 0.129212
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0407604
New value of Value function: 0.129212
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.128953
New value of Value function: 0.128953
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.128695
New value of Value function: 0.128695
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0471137
New value of Value function: 0.128695
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0422617
New value of Value function: 0.128695
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.128438
New value of Value function: 0.128438
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.128181
New value of Value function: 0.128181
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.127925
New value of Value function: 0.127925
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.048474
New value of Value function: 0.127925
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0609791
New value of Value function: 0.127925
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0498072
New value of Value function: 0.127925
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.127669
New value of Value function: 0.127669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0511091
New value of Value function: 0.127669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0437145
New value of Value function: 0.127669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0523849
New value of Value function: 0.127669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.127413
New value of Value function: 0.127413
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0451337
New value of Value function: 0.127413
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0620529
New value of Value function: 0.127413
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.127159
New value of Value function: 0.127159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0536261
New value of Value function: 0.127159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0977597
New value of Value function: 0.127159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.126904
New value of Value function: 0.126904
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.12665
New value of Value function: 0.12665
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.126397
New value of Value function: 0.126397
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.126144
New value of Value function: 0.126144
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0630825
New value of Value function: 0.126144
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.125892
New value of Value function: 0.125892
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.12564
New value of Value function: 0.12564
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.125389
New value of Value function: 0.125389
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0640778
New value of Value function: 0.125389
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 746
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.125138
New value of Value function: 0.125138
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.098057
New value of Value function: 0.125138
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.124888
New value of Value function: 0.124888
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 118
New value of Q matrix: 0.16239
New value of Value function: 0.16239
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 750
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 751
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 752
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.7916e-05
New value of Value function: 3.7916e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 753
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00087245
New value of Value function: 0.00210645
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 754
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00206432
New value of Value function: 0.00206432
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 755
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.71577e-05
New value of Value function: 3.71577e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 756
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.28932e-05
New value of Value function: 0.00206432
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 757
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.71577e-05
New value of Value function: 0.00142028
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 758
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00206019
New value of Value function: 0.00206019
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 759
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00205607
New value of Value function: 0.00205607
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 760
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00205196
New value of Value function: 0.00205196
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 761
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00147414
New value of Value function: 0.00205196
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 762
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0342641
New value of Value function: 0.0342641
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 763
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00159645
New value of Value function: 0.0308645
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 764
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.0640731
New value of Value function: 0.0640731
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 765
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.1445e-05
New value of Value function: 0.00205196
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 766
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00204785
New value of Value function: 0.00204785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 767
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.4019e-05
New value of Value function: 0.00204785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 768
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.90966e-05
New value of Value function: 0.00204785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 769
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.72774e-05
New value of Value function: 0.00204785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 770
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00204376
New value of Value function: 0.00204376
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 771
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00203967
New value of Value function: 0.00203967
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 772
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00203559
New value of Value function: 0.00203559
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 773
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00308785
New value of Value function: 0.00308785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 774
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.119562
New value of Value function: 0.119562
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 775
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000123296
New value of Value function: 0.00308785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 776
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00594912
New value of Value function: 0.00594912
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 119
New value of Q matrix: 0.199249
New value of Value function: 0.199249
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 778
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00798225
New value of Value function: 0.00798225
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 779
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.119323
New value of Value function: 0.119323
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 780
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00359042
New value of Value function: 0.119323
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 120
New value of Q matrix: 0.235408
New value of Value function: 0.235408
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 782
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00997041
New value of Value function: 0.00997041
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 783
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00237452
New value of Value function: 0.119323
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 784
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.119084
New value of Value function: 0.119084
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 785
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.118866
New value of Value function: 0.119084
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 786
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00139187
New value of Value function: 0.00139187
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 787
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0601795
New value of Value function: 0.0601795
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 788
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00222905
New value of Value function: 0.00997041
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 789
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.118846
New value of Value function: 0.118866
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 790
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00775596
New value of Value function: 0.118866
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 121
New value of Q matrix: 0.27284
New value of Value function: 0.27284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 792
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.118628
New value of Value function: 0.118846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 793
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.118608
New value of Value function: 0.118628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 794
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00723814
New value of Value function: 0.118628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0677074
New value of Value function: 0.27284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0574647
New value of Value function: 0.27284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.101007
New value of Value function: 0.27284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.272294
New value of Value function: 0.272294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0612167
New value of Value function: 0.272294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.103888
New value of Value function: 0.272294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0491323
New value of Value function: 0.272294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0712545
New value of Value function: 0.272294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.271749
New value of Value function: 0.271749
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0648838
New value of Value function: 0.271749
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0747209
New value of Value function: 0.271749
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 124
New value of Q matrix: 0.306494
New value of Value function: 0.306494
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 807
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0119063
New value of Value function: 0.0119063
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 808
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0612239
New value of Value function: 0.118628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 809
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00259797
New value of Value function: 0.0119063
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 810
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0649269
New value of Value function: 0.0649269
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 811
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.0673077
New value of Value function: 0.118628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 812
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000286852
New value of Value function: 0.0119063
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 813
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0128369
New value of Value function: 0.0128369
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 814
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0347475
New value of Value function: 0.0649269
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 815
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00424378
New value of Value function: 0.0649269
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 816
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0647971
New value of Value function: 0.0647971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 817
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.123732
New value of Value function: 0.123732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 818
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0147155
New value of Value function: 0.0147155
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 819
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0680968
New value of Value function: 0.118628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 820
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.176521
New value of Value function: 0.176521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 821
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0175985
New value of Value function: 0.0175985
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 822
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0622266
New value of Value function: 0.176521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 823
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00638609
New value of Value function: 0.123732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 824
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.124435
New value of Value function: 0.124435
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 825
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.176168
New value of Value function: 0.176168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 826
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0632219
New value of Value function: 0.176168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 827
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.0617835
New value of Value function: 0.124435
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 828
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00320743
New value of Value function: 0.00320743
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 829
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.119407
New value of Value function: 0.176168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 830
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.178161
New value of Value function: 0.178161
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.107327
New value of Value function: 0.306494
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.305881
New value of Value function: 0.305881
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 126
New value of Q matrix: 0.34297
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 834
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.234915
New value of Value function: 0.234915
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 835
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0175633
New value of Value function: 0.0175633
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 836
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0175282
New value of Value function: 0.0175282
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 837
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0174931
New value of Value function: 0.0174931
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 838
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0213717
New value of Value function: 0.0213717
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 839
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.234445
New value of Value function: 0.234445
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 840
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0641973
New value of Value function: 0.234445
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 841
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00849819
New value of Value function: 0.124435
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 842
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.126166
New value of Value function: 0.126166
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 843
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.290141
New value of Value function: 0.290141
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 844
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00550365
New value of Value function: 0.0213717
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 845
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.344723
New value of Value function: 0.344723
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 846
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0029307
New value of Value function: 0.0213717
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 847
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00514308
New value of Value function: 0.0213717
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 848
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.184028
New value of Value function: 0.184028
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 849
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0271493
New value of Value function: 0.0271493
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 850
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0138058
New value of Value function: 0.344723
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 851
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.123224
New value of Value function: 0.344723
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 852
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.126965
New value of Value function: 0.344723
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 853
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.344002
New value of Value function: 0.344002
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.111354
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0543231
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0794
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0697596
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0745379
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0839854
New value of Value function: 0.34297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.342284
New value of Value function: 0.342284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0792082
New value of Value function: 0.342284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0884668
New value of Value function: 0.342284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0928586
New value of Value function: 0.342284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0593977
New value of Value function: 0.342284
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.3416
New value of Value function: 0.3416
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0971502
New value of Value function: 0.3416
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0837729
New value of Value function: 0.3416
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.115276
New value of Value function: 0.3416
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.340916
New value of Value function: 0.340916
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 130
New value of Q matrix: 0.374587
New value of Value function: 0.374587
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 871
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.027095
New value of Value function: 0.027095
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 872
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00267218
New value of Value function: 0.027095
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 873
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00060854
New value of Value function: 0.027095
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 874
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00733893
New value of Value function: 0.027095
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.373838
New value of Value function: 0.373838
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0888265
New value of Value function: 0.373838
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 0.406849
New value of Value function: 0.406849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 878
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0270408
New value of Value function: 0.0270408
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 879
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00310547
New value of Value function: 0.0270408
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 880
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00767889
New value of Value function: 0.0270408
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 881
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0338233
New value of Value function: 0.0338233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 133
New value of Q matrix: 0.43932
New value of Value function: 0.43932
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 883
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00365218
New value of Value function: 0.0338233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 884
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0060024
New value of Value function: 0.0338233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 885
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0337556
New value of Value function: 0.0337556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 886
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00418674
New value of Value function: 0.0337556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 887
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0392726
New value of Value function: 0.0392726
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 888
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.397829
New value of Value function: 0.397829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 889
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.045648
New value of Value function: 0.045648
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 890
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0700742
New value of Value function: 0.397829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 891
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.450694
New value of Value function: 0.450694
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 892
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00492466
New value of Value function: 0.045648
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 893
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0528475
New value of Value function: 0.0528475
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 894
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.502631
New value of Value function: 0.502631
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 895
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00577743
New value of Value function: 0.0528475
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 896
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0068336
New value of Value function: 0.0528475
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 897
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00847656
New value of Value function: 0.0528475
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 898
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0518156
New value of Value function: 0.0518156
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 899
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000969096
New value of Value function: 0.00139187
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 900
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00659456
New value of Value function: 0.0518156
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 901
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.051712
New value of Value function: 0.051712
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 902
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0516086
New value of Value function: 0.0516086
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 903
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0596238
New value of Value function: 0.0596238
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 904
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.501626
New value of Value function: 0.501626
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 905
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0757642
New value of Value function: 0.501626
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 906
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0719852
New value of Value function: 0.501626
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 907
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.189376
New value of Value function: 0.189376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 908
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.022559
New value of Value function: 0.501626
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 909
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.552666
New value of Value function: 0.552666
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 910
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0683793
New value of Value function: 0.0683793
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 911
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.602844
New value of Value function: 0.602844
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 912
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0682425
New value of Value function: 0.0682425
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 913
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0777289
New value of Value function: 0.0777289
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 914
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.135276
New value of Value function: 0.602844
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 915
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.143422
New value of Value function: 0.602844
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 916
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.598695
New value of Value function: 0.598695
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 0.471933
New value of Value function: 0.471933
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 918
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00970615
New value of Value function: 0.0777289
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 919
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00643934
New value of Value function: 0.0777289
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 920
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0775734
New value of Value function: 0.0775734
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 921
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0867985
New value of Value function: 0.0867985
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 922
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0739543
New value of Value function: 0.598695
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 923
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0713243
New value of Value function: 0.189376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 924
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0328843
New value of Value function: 0.598695
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 925
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.134307
New value of Value function: 0.598695
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 926
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00156237
New value of Value function: 0.00320743
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 927
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0174734
New value of Value function: 0.0867985
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 928
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0430031
New value of Value function: 0.598695
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 929
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.648283
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 930
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0866249
New value of Value function: 0.0866249
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 931
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0965615
New value of Value function: 0.0965615
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 932
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0538122
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 933
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.191678
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 934
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0132002
New value of Value function: 0.0132002
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 935
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.075884
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 936
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.197258
New value of Value function: 0.197258
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 937
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.064405
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 938
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.248082
New value of Value function: 0.648283
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 939
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0148124
New value of Value function: 0.0148124
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 940
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.697056
New value of Value function: 0.697056
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 941
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0188621
New value of Value function: 0.0965615
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 942
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.107177
New value of Value function: 0.107177
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 943
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.695662
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 944
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.255643
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 945
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0756388
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 946
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.263052
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 947
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.141637
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 948
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0125219
New value of Value function: 0.0601795
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 949
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.151326
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 950
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.266285
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 135
New value of Q matrix: 0.515016
New value of Value function: 0.515016
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 952
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0868882
New value of Value function: 0.695662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 953
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.69427
New value of Value function: 0.69427
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 954
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.273457
New value of Value function: 0.69427
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 955
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.692882
New value of Value function: 0.692882
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 956
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.691496
New value of Value function: 0.691496
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 957
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.690113
New value of Value function: 0.690113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 958
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.280409
New value of Value function: 0.690113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 959
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.73824
New value of Value function: 0.73824
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 960
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.118322
New value of Value function: 0.118322
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 961
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0887011
New value of Value function: 0.73824
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 962
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.206601
New value of Value function: 0.206601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 963
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.736763
New value of Value function: 0.736763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 964
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0906459
New value of Value function: 0.736763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 965
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0831596
New value of Value function: 0.206601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 966
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.161561
New value of Value function: 0.736763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 967
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.288063
New value of Value function: 0.736763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 968
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.295563
New value of Value function: 0.736763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 969
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.73529
New value of Value function: 0.73529
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 970
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.782714
New value of Value function: 0.782714
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 971
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.118085
New value of Value function: 0.118085
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 972
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0116376
New value of Value function: 0.118085
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 973
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.116807
New value of Value function: 0.116807
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 974
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0263603
New value of Value function: 0.0601795
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 975
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.768143
New value of Value function: 0.768143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 976
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108323
New value of Value function: 0.0601795
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 977
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108323
New value of Value function: 0.0601795
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 978
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0600591
New value of Value function: 0.0600591
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 979
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0396597
New value of Value function: 0.0600591
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 980
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 0.812805
New value of Value function: 0.812805
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 981
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0024451
New value of Value function: 0.0024451
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 982
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0734884
New value of Value function: 0.0734884
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 983
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.858652
New value of Value function: 0.858652
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 984
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.129926
New value of Value function: 0.129926
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 985
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0895818
New value of Value function: 0.858652
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 986
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 0.903817
New value of Value function: 0.903817
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 987
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.129667
New value of Value function: 0.129667
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 988
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.143342
New value of Value function: 0.143342
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 989
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.104059
New value of Value function: 0.903817
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 990
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.90201
New value of Value function: 0.90201
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 991
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.900206
New value of Value function: 0.900206
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 992
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.352232
New value of Value function: 0.900206
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 993
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.021065
New value of Value function: 0.143342
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 994
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0226664
New value of Value function: 0.143342
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 995
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.174534
New value of Value function: 0.900206
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 996
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.111248
New value of Value function: 0.900206
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.122241
New value of Value function: 0.515016
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0674801
New value of Value function: 0.515016
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.104478
New value of Value function: 0.515016
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.513986
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1001
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.129048
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1002
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.135718
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.142256
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1004
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0753822
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1005
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.11164
New value of Value function: 0.513986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1006
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.512958
New value of Value function: 0.512958
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0962832
New value of Value function: 0.512958
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.511932
New value of Value function: 0.511932
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1009
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.118622
New value of Value function: 0.511932
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1010
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.510909
New value of Value function: 0.510909
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1011
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.125446
New value of Value function: 0.510909
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1012
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0830709
New value of Value function: 0.510909
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1013
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 140
New value of Q matrix: 0.556894
New value of Value function: 0.556894
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1014
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.898405
New value of Value function: 0.898405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1015
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.187214
New value of Value function: 0.898405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1016
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.105004
New value of Value function: 0.898405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1017
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.119075
New value of Value function: 0.898405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1018
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 0.943017
New value of Value function: 0.943017
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1019
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.157449
New value of Value function: 0.157449
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1020
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.246304
New value of Value function: 0.943017
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1021
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0142389
New value of Value function: 0.157449
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1022
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0322371
New value of Value function: 0.157449
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1023
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.132961
New value of Value function: 0.556894
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1024
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.55578
New value of Value function: 0.55578
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1025
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 142
New value of Q matrix: 0.587499
New value of Value function: 0.587499
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1026
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.171275
New value of Value function: 0.171275
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1027
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 0.98724
New value of Value function: 0.98724
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1028
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0170371
New value of Value function: 0.171275
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1029
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.178424
New value of Value function: 0.178424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1030
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.149986
New value of Value function: 0.587499
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1031
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.586324
New value of Value function: 0.586324
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1032
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.15754
New value of Value function: 0.586324
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1033
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0919633
New value of Value function: 0.586324
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1034
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.100678
New value of Value function: 0.586324
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1035
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 144
New value of Q matrix: 0.617809
New value of Value function: 0.617809
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1036
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.034804
New value of Value function: 0.178424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1037
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0238553
New value of Value function: 0.178424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1038
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.192626
New value of Value function: 0.192626
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1039
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.985265
New value of Value function: 0.985265
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1040
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.0256
New value of Value function: 1.0256
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1041
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00346727
New value of Value function: 0.00346727
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1042
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.192241
New value of Value function: 0.192241
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1043
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0247714
New value of Value function: 0.192241
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1044
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.120413
New value of Value function: 1.0256
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1045
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0852152
New value of Value function: 0.206601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1046
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.22093
New value of Value function: 0.22093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1047
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.02355
New value of Value function: 1.02355
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1048
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.06654
New value of Value function: 1.06654
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1049
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0201567
New value of Value function: 0.192241
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1050
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.188458
New value of Value function: 0.188458
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1051
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0225957
New value of Value function: 0.0225957
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1052
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.364385
New value of Value function: 1.06654
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1053
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 1.1086
New value of Value function: 1.1086
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1054
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.188082
New value of Value function: 0.188082
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1055
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.187705
New value of Value function: 0.187705
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1056
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.203906
New value of Value function: 0.203906
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1057
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.261333
New value of Value function: 1.1086
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1058
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.09755
New value of Value function: 1.09755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1059
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 145
New value of Q matrix: 0.649123
New value of Value function: 0.649123
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1060
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.219584
New value of Value function: 0.219584
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1061
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.09536
New value of Value function: 1.09536
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1062
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.376814
New value of Value function: 1.09536
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1063
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.128739
New value of Value function: 1.09536
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1064
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.145881
New value of Value function: 1.09536
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1065
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.275823
New value of Value function: 1.09536
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1066
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.08513
New value of Value function: 1.08513
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 146
New value of Q matrix: 0.695673
New value of Value function: 0.695673
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1068
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.38881
New value of Value function: 1.08513
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1069
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.121981
New value of Value function: 1.08513
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1070
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.236044
New value of Value function: 0.236044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1071
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.12379
New value of Value function: 1.08513
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1072
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0115671
New value of Value function: 0.236044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1073
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0383013
New value of Value function: 0.236044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1074
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.235572
New value of Value function: 0.235572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1075
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0124184
New value of Value function: 0.235572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1076
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0642403
New value of Value function: 0.0642403
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1077
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.232017
New value of Value function: 0.232017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1078
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0641763
New value of Value function: 0.0642403
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1079
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0386916
New value of Value function: 0.232017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1080
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.122976
New value of Value function: 0.122976
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1081
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0163464
New value of Value function: 0.232017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1082
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0401314
New value of Value function: 0.232017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1083
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.184693
New value of Value function: 0.184693
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1084
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0125045
New value of Value function: 0.232017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1085
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.246909
New value of Value function: 0.246909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1086
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 1.08296
New value of Value function: 1.08296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1087
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 1.0808
New value of Value function: 1.0808
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1088
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.400488
New value of Value function: 1.0808
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1089
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.125759
New value of Value function: 1.0808
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1090
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0166988
New value of Value function: 0.246909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1091
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0879552
New value of Value function: 0.246909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1092
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.261425
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1093
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 1.12313
New value of Value function: 1.12313
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1094
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.235409
New value of Value function: 0.235409
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1095
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.12089
New value of Value function: 1.12089
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1096
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.14342
New value of Value function: 1.12089
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1097
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.11865
New value of Value function: 1.11865
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1098
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.11641
New value of Value function: 1.11641
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1099
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 1.11418
New value of Value function: 1.11418
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1100
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.330713
New value of Value function: 1.11418
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1101
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0263811
New value of Value function: 0.0263811
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1102
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.250756
New value of Value function: 0.250756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1103
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.205065
New value of Value function: 1.11418
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1104
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0434334
New value of Value function: 0.250756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1105
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.11195
New value of Value function: 1.11195
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1106
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 1.15422
New value of Value function: 1.15422
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1107
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.266517
New value of Value function: 0.266517
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1108
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 1.15191
New value of Value function: 1.15191
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1109
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.384574
New value of Value function: 1.15191
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1110
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0216842
New value of Value function: 0.0263811
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1111
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 1.19367
New value of Value function: 1.19367
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1112
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.047362
New value of Value function: 0.266517
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1113
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.282672
New value of Value function: 0.282672
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1114
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.457567
New value of Value function: 1.19367
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1115
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.298505
New value of Value function: 0.298505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1116
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 1.23517
New value of Value function: 1.23517
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1117
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0289816
New value of Value function: 0.298505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1118
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0440344
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1119
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0210705
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1120
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0909018
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1121
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0253547
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1122
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0937894
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1123
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0295533
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1124
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0966192
New value of Value function: 0.261425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1125
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.278429
New value of Value function: 0.278429
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1126
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 1.27584
New value of Value function: 1.27584
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1127
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0251266
New value of Value function: 0.298505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1128
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0337751
New value of Value function: 0.298505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1129
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.297908
New value of Value function: 0.297908
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1130
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.292216
New value of Value function: 0.292216
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1131
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0181961
New value of Value function: 0.0181961
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1132
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0393678
New value of Value function: 0.292216
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1133
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.309337
New value of Value function: 0.309337
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1134
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 1.31589
New value of Value function: 1.31589
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1135
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.326837
New value of Value function: 0.326837
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1136
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 1.35546
New value of Value function: 1.35546
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1137
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0522978
New value of Value function: 0.326837
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1138
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0334271
New value of Value function: 0.326837
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1139
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0181597
New value of Value function: 0.0181597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1140
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0203992
New value of Value function: 0.0203992
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1141
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.326183
New value of Value function: 0.326183
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1142
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.325531
New value of Value function: 0.325531
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1143
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0571114
New value of Value function: 0.325531
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1144
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.32488
New value of Value function: 0.32488
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1145
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.061817
New value of Value function: 0.32488
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1146
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0490223
New value of Value function: 0.32488
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1147
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.514263
New value of Value function: 1.35546
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1148
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.34278
New value of Value function: 0.34278
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1149
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 1.39452
New value of Value function: 1.39452
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.361026
New value of Value function: 0.361026
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1151
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.529079
New value of Value function: 1.39452
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1152
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 1.43313
New value of Value function: 1.43313
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1153
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0670792
New value of Value function: 0.361026
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1154
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.045079
New value of Value function: 0.361026
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1155
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.379602
New value of Value function: 0.379602
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1156
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 1.4713
New value of Value function: 1.4713
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1157
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.398493
New value of Value function: 0.398493
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1158
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.544981
New value of Value function: 1.4713
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1159
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 1.46836
New value of Value function: 1.46836
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1160
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.169394
New value of Value function: 1.46836
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1161
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.205975
New value of Value function: 1.46836
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1162
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.299291
New value of Value function: 0.299291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1163
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 1.50616
New value of Value function: 1.50616
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1164
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.417634
New value of Value function: 0.417634
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1165
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 1.50315
New value of Value function: 1.50315
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1166
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.193063
New value of Value function: 1.50315
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1167
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.228913
New value of Value function: 1.50315
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1168
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 1.5406
New value of Value function: 1.5406
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1169
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.437012
New value of Value function: 0.437012
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1170
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.404613
New value of Value function: 1.5406
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1171
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 1.57766
New value of Value function: 1.57766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1172
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0611564
New value of Value function: 0.437012
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1173
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 1.5745
New value of Value function: 1.5745
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1174
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.229722
New value of Value function: 1.5745
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1175
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.155054
New value of Value function: 0.299291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1176
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000367186
New value of Value function: 0.0203992
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1177
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0461376
New value of Value function: 0.0461376
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1178
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 75
New value of Q matrix: 1.61088
New value of Value function: 1.61088
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1179
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.436138
New value of Value function: 0.436138
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1180
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.428246
New value of Value function: 0.428246
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1181
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0742106
New value of Value function: 0.0742106
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1182
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.464229
New value of Value function: 1.61088
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1183
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.427389
New value of Value function: 0.427389
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1184
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.447837
New value of Value function: 0.447837
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1185
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.515419
New value of Value function: 1.61088
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1186
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00047486
New value of Value function: 0.0263811
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1187
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0383756
New value of Value function: 0.0383756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.10688
New value of Value function: 0.695673
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 147
New value of Q matrix: 0.729821
New value of Value function: 0.729821
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1190
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.467877
New value of Value function: 0.467877
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1191
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 1.60766
New value of Value function: 1.60766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1192
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.534049
New value of Value function: 1.60766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1193
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 1.58864
New value of Value function: 1.58864
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 148
New value of Q matrix: 0.755915
New value of Value function: 0.755915
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1195
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000690761
New value of Value function: 0.0383756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1196
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0160027
New value of Value function: 0.0383756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.118349
New value of Value function: 0.755915
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.129588
New value of Value function: 0.755915
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 149
New value of Q matrix: 0.789218
New value of Value function: 0.789218
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1200
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.487115
New value of Value function: 0.487115
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1201
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 1.62564
New value of Value function: 1.62564
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1202
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0529454
New value of Value function: 0.487115
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1203
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.48614
New value of Value function: 0.48614
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1204
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.485168
New value of Value function: 0.485168
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1205
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0653205
New value of Value function: 0.485168
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1206
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.362038
New value of Value function: 0.362038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1207
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0705308
New value of Value function: 0.485168
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1208
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 0.423531
New value of Value function: 0.423531
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1209
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0487327
New value of Value function: 0.485168
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1210
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0463411
New value of Value function: 0.0463411
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1211
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.484198
New value of Value function: 0.484198
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1212
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0744531
New value of Value function: 0.484198
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1213
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.483229
New value of Value function: 0.483229
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1214
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.502826
New value of Value function: 0.502826
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1215
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.62238
New value of Value function: 1.62238
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1216
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.218404
New value of Value function: 1.62238
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1217
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 1.61914
New value of Value function: 1.61914
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1218
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 1.65581
New value of Value function: 1.65581
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1219
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0989247
New value of Value function: 0.502826
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1220
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 1.6525
New value of Value function: 1.6525
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1221
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 1.6885
New value of Value function: 1.6885
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1222
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.523163
New value of Value function: 0.523163
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1223
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 84
New value of Q matrix: 1.72414
New value of Value function: 1.72414
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1224
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0571749
New value of Value function: 0.523163
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1225
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.106363
New value of Value function: 0.523163
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1226
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.522116
New value of Value function: 0.522116
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1227
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.521072
New value of Value function: 0.521072
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1228
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0573542
New value of Value function: 0.521072
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1229
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.141398
New value of Value function: 0.141398
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1230
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.105572
New value of Value function: 0.521072
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1231
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00798339
New value of Value function: 0.0742106
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1232
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.484439
New value of Value function: 0.484439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1233
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.52003
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1234
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.11218
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1235
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.505785
New value of Value function: 0.505785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1236
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.592728
New value of Value function: 1.72414
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1237
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0527207
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1238
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0547748
New value of Value function: 0.0547748
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1239
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0823246
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1240
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0655677
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1241
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0658722
New value of Value function: 0.52003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 150
New value of Q matrix: 0.81442
New value of Value function: 0.81442
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1243
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0630399
New value of Value function: 0.0630399
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1244
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.540664
New value of Value function: 0.540664
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1245
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 1.7207
New value of Value function: 1.7207
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1246
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 1.74742
New value of Value function: 1.74742
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1247
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.071511
New value of Value function: 0.071511
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1248
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.561304
New value of Value function: 0.561304
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1249
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 87
New value of Q matrix: 1.78257
New value of Value function: 1.78257
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1250
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.582164
New value of Value function: 0.582164
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1251
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 1.77901
New value of Value function: 1.77901
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1252
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.257149
New value of Value function: 1.77901
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1253
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 89
New value of Q matrix: 1.81391
New value of Value function: 1.81391
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1254
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.603171
New value of Value function: 0.603171
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1255
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.246687
New value of Value function: 1.81391
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1256
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 1.81028
New value of Value function: 1.81028
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1257
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 1.80666
New value of Value function: 1.80666
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1258
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 92
New value of Q matrix: 1.84138
New value of Value function: 1.84138
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1259
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0751134
New value of Value function: 0.603171
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1260
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.120794
New value of Value function: 0.603171
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1261
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.601965
New value of Value function: 0.601965
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1262
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.600761
New value of Value function: 0.600761
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1263
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.127482
New value of Value function: 0.600761
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1264
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0380663
New value of Value function: 0.505785
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1265
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.528814
New value of Value function: 0.528814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1266
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.583419
New value of Value function: 1.84138
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1267
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00360673
New value of Value function: 0.141398
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1268
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.141115
New value of Value function: 0.141115
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1269
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.171438
New value of Value function: 0.171438
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1270
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 93
New value of Q matrix: 1.87537
New value of Value function: 1.87537
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1271
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.622502
New value of Value function: 0.622502
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1272
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 1.87162
New value of Value function: 1.87162
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1273
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 1.90539
New value of Value function: 1.90539
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1274
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.621257
New value of Value function: 0.621257
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1275
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.620015
New value of Value function: 0.620015
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1276
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.641912
New value of Value function: 0.641912
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1277
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.27605
New value of Value function: 1.90539
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1278
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 96
New value of Q matrix: 1.93884
New value of Value function: 1.93884
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1279
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0748983
New value of Value function: 0.641912
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1280
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0816352
New value of Value function: 0.0816352
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1281
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0849548
New value of Value function: 0.641912
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1282
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.643733
New value of Value function: 0.643733
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 151
New value of Q matrix: 0.849719
New value of Value function: 0.849719
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1284
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.665757
New value of Value function: 0.665757
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1285
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 97
New value of Q matrix: 1.97204
New value of Value function: 1.97204
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1286
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0952393
New value of Value function: 0.665757
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1287
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.667737
New value of Value function: 0.667737
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 152
New value of Q matrix: 0.908221
New value of Value function: 0.908221
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1289
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 2.00462
New value of Value function: 2.00462
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1290
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.690465
New value of Value function: 0.690465
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1291
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 2.00061
New value of Value function: 2.00061
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1292
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.324435
New value of Value function: 2.00061
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1293
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.116689
New value of Value function: 0.690465
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1294
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 1.99661
New value of Value function: 1.99661
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1295
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 2.02911
New value of Value function: 2.02911
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1296
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.094804
New value of Value function: 0.690465
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1297
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0924309
New value of Value function: 0.0924309
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1298
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0662185
New value of Value function: 0.690465
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1299
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0577744
New value of Value function: 0.0924309
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1300
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.327465
New value of Value function: 2.02911
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1301
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.161472
New value of Value function: 0.528814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1302
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.0986408
New value of Value function: 0.528814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1303
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00951866
New value of Value function: 0.0742106
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1304
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0437093
New value of Value function: 0.528814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1305
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0308028
New value of Value function: 0.0308028
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1306
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0383429
New value of Value function: 0.0383429
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1307
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.50475
New value of Value function: 0.50475
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1308
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0466616
New value of Value function: 0.0466616
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1309
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.555495
New value of Value function: 0.555495
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1310
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0468079
New value of Value function: 0.0468079
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1311
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0687733
New value of Value function: 0.0687733
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1312
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.605227
New value of Value function: 0.605227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1313
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0567658
New value of Value function: 0.0567658
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1314
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0765179
New value of Value function: 0.605227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1315
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0782919
New value of Value function: 0.0782919
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1316
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.654144
New value of Value function: 0.654144
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1317
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00742938
New value of Value function: 0.0567658
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1318
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0674051
New value of Value function: 0.0674051
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1319
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.702275
New value of Value function: 0.702275
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1320
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0786979
New value of Value function: 0.0786979
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1321
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.749646
New value of Value function: 0.749646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1322
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00869736
New value of Value function: 0.0786979
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1323
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0785332
New value of Value function: 0.0785332
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1324
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0781353
New value of Value function: 0.0781353
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1325
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00325835
New value of Value function: 0.0781353
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1326
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.077979
New value of Value function: 0.077979
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1327
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0778331
New value of Value function: 0.0778331
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1328
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0783636
New value of Value function: 0.0783636
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1329
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0106687
New value of Value function: 0.0778331
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1330
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0781973
New value of Value function: 0.0781973
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1331
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0776774
New value of Value function: 0.0776774
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1332
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.136143
New value of Value function: 0.136143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1333
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108821
New value of Value function: 0.00108821
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 1334
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00140755
New value of Value function: 0.00140755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1335
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.136659
New value of Value function: 0.136659
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1336
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00245058
New value of Value function: 0.00245058
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1337
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00564376
New value of Value function: 0.136143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1338
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.0704553
New value of Value function: 0.136143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1339
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00245058
New value of Value function: 0.00245058
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1340
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.193421
New value of Value function: 0.193421
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1341
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1342
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.41105e-05
New value of Value function: 4.41105e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1343
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00245986
New value of Value function: 0.00245986
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1344
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.19397
New value of Value function: 0.19397
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1345
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00487085
New value of Value function: 0.00487085
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1346
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.250178
New value of Value function: 0.250178
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1347
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00348157
New value of Value function: 0.00487085
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1348
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.24964
New value of Value function: 0.24964
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1349
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00927664
New value of Value function: 0.00927664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1350
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.249668
New value of Value function: 0.249668
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1351
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0222347
New value of Value function: 0.24964
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1352
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.249141
New value of Value function: 0.249141
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1353
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.248642
New value of Value function: 0.248642
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1354
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.12909
New value of Value function: 0.248642
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1355
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00687713
New value of Value function: 0.00687713
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1356
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.303669
New value of Value function: 0.303669
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1357
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1358
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.93989e-07
New value of Value function: 7.93989e-07
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1359
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.93989e-07
New value of Value function: 4.41105e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1360
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.42918e-08
New value of Value function: 4.41105e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1361
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.5721e-06
New value of Value function: 1.5721e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1362
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 4.41105e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1363
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1364
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1365
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1366
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1367
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1368
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600194
New value of Value function: 0.0600194
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1369
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.82488e-07
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1370
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.78402e-05
New value of Value function: 3.78402e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1371
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.81123e-07
New value of Value function: 3.78402e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1372
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.70834e-05
New value of Value function: 3.70834e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1373
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600007
New value of Value function: 0.0600007
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1374
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.335e-06
New value of Value function: 3.70834e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1375
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.70092e-05
New value of Value function: 3.70092e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1376
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.66166e-07
New value of Value function: 3.70092e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1377
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3.70092e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1378
----------
State: 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1379
----------
State: 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.66166e-07
New value of Value function: 6.66166e-07
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1380
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00111628
New value of Value function: 0.00111628
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1381
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118821
New value of Value function: 0.118821
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1382
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00323273
New value of Value function: 0.00323273
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1383
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600582
New value of Value function: 0.118821
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1384
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00322626
New value of Value function: 0.00322626
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1385
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00530051
New value of Value function: 0.00530051
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1386
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.118583
New value of Value function: 0.118583
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1387
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.176307
New value of Value function: 0.176307
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1388
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.54092e-05
New value of Value function: 0.00530051
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1389
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0215425
New value of Value function: 0.0215425
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 153
New value of Q matrix: 0.93323
New value of Value function: 0.93323
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1391
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00317352
New value of Value function: 0.176307
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1392
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00317352
New value of Value function: 0.176307
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1393
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.233168
New value of Value function: 0.233168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1394
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0253087
New value of Value function: 0.0253087
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1395
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.288961
New value of Value function: 0.288961
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1396
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000549057
New value of Value function: 0.0253087
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1397
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0300038
New value of Value function: 0.0300038
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1398
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0605401
New value of Value function: 0.288961
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1399
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0418321
New value of Value function: 0.0418321
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1400
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.689085
New value of Value function: 0.689085
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1401
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.687706
New value of Value function: 0.687706
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1402
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.675288
New value of Value function: 0.675288
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1403
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0848816
New value of Value function: 0.0848816
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1404
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.105063
New value of Value function: 0.675288
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1405
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.673937
New value of Value function: 0.673937
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1406
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.67259
New value of Value function: 0.67259
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1407
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.671244
New value of Value function: 0.671244
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1408
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.669902
New value of Value function: 0.669902
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1409
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.658032
New value of Value function: 0.658032
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1410
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00935159
New value of Value function: 0.0848816
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1411
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0188469
New value of Value function: 0.0848816
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1412
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 0.579766
New value of Value function: 0.579766
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1413
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0950285
New value of Value function: 0.0950285
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1414
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.655307
New value of Value function: 0.655307
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1415
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.639966
New value of Value function: 0.639966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1416
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.653996
New value of Value function: 0.653996
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1417
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0766661
New value of Value function: 0.653996
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1418
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.126127
New value of Value function: 0.653996
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1419
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.67744
New value of Value function: 0.67744
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1420
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 102
New value of Q matrix: 2.06072
New value of Value function: 2.06072
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1421
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.135799
New value of Value function: 0.67744
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1422
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.700984
New value of Value function: 0.700984
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1423
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 103
New value of Q matrix: 2.09212
New value of Value function: 2.09212
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1424
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.104626
New value of Value function: 0.700984
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1425
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.12824
New value of Value function: 0.12824
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1426
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 104
New value of Q matrix: 2.11259
New value of Value function: 2.11259
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1427
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.138293
New value of Value function: 0.138293
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1428
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.699582
New value of Value function: 0.699582
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1429
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.723617
New value of Value function: 0.723617
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1430
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 2.10836
New value of Value function: 2.10836
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1431
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 2.10415
New value of Value function: 2.10415
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1432
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 2.12455
New value of Value function: 2.12455
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1433
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00316623
New value of Value function: 0.138293
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1434
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.019901
New value of Value function: 0.138293
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.1471
New value of Value function: 0.93323
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 154
New value of Q matrix: 0.957055
New value of Value function: 0.957055
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1437
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.148553
New value of Value function: 0.148553
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1438
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.72217
New value of Value function: 0.72217
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1439
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.115532
New value of Value function: 0.72217
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1440
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.130448
New value of Value function: 0.72217
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.955141
New value of Value function: 0.955141
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 156
New value of Q matrix: 0.989037
New value of Value function: 0.989037
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1443
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.140839
New value of Value function: 0.72217
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1444
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.710401
New value of Value function: 0.710401
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1445
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0183566
New value of Value function: 0.148553
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1446
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.158369
New value of Value function: 0.158369
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1447
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.14587
New value of Value function: 0.710401
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1448
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.70898
New value of Value function: 0.70898
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1449
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.707562
New value of Value function: 0.707562
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1450
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.731653
New value of Value function: 0.731653
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1451
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 2.1203
New value of Value function: 2.1203
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1452
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 109
New value of Q matrix: 2.15107
New value of Value function: 2.15107
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1453
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.156122
New value of Value function: 0.731653
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1454
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.730189
New value of Value function: 0.730189
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1455
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.754305
New value of Value function: 0.754305
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1456
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.309248
New value of Value function: 2.15107
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1457
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 2.14676
New value of Value function: 2.14676
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1458
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.572723
New value of Value function: 2.14676
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1459
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.332435
New value of Value function: 2.14676
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1460
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.665809
New value of Value function: 0.665809
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1461
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.599911
New value of Value function: 2.14676
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1462
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 2.14247
New value of Value function: 2.14247
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1463
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 2.13819
New value of Value function: 2.13819
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1464
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 2.13391
New value of Value function: 2.13391
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1465
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 114
New value of Q matrix: 2.16481
New value of Value function: 2.16481
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1466
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.752796
New value of Value function: 0.752796
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1467
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.163899
New value of Value function: 0.752796
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1468
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 2.16048
New value of Value function: 2.16048
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1469
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 116
New value of Q matrix: 2.19082
New value of Value function: 2.19082
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1470
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.777175
New value of Value function: 0.777175
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1471
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.627347
New value of Value function: 2.19082
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1472
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 2.18644
New value of Value function: 2.18644
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1473
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 2.2167
New value of Value function: 2.2167
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1474
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.162331
New value of Value function: 0.777175
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1475
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.105113
New value of Value function: 0.105113
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1476
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.692393
New value of Value function: 0.692393
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1477
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.688789
New value of Value function: 2.2167
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1478
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.166989
New value of Value function: 0.777175
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1479
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.801532
New value of Value function: 0.801532
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1480
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 2.21227
New value of Value function: 2.21227
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1481
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 2.20784
New value of Value function: 2.20784
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1482
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 121
New value of Q matrix: 2.23811
New value of Value function: 2.23811
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1483
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.799929
New value of Value function: 0.799929
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1484
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.140872
New value of Value function: 0.799929
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1485
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.195487
New value of Value function: 0.195487
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1486
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 2.25687
New value of Value function: 2.25687
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1487
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.205976
New value of Value function: 0.205976
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1488
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.824554
New value of Value function: 0.824554
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1489
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 123
New value of Q matrix: 2.28657
New value of Value function: 2.28657
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1490
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.152897
New value of Value function: 0.824554
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1491
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.825866
New value of Value function: 0.825866
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 157
New value of Q matrix: 1.02412
New value of Value function: 1.02412
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1493
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.164705
New value of Value function: 0.825866
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1494
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.827782
New value of Value function: 0.827782
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 158
New value of Q matrix: 1.0848
New value of Value function: 1.0848
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1496
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.338249
New value of Value function: 2.28657
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1497
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0284825
New value of Value function: 0.692393
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1498
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.109131
New value of Value function: 0.692393
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1499
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.719703
New value of Value function: 0.719703
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1500
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 2.282
New value of Value function: 2.282
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1501
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 2.27744
New value of Value function: 2.27744
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1502
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 126
New value of Q matrix: 2.30679
New value of Value function: 2.30679
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1503
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.176311
New value of Value function: 0.827782
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1504
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.830753
New value of Value function: 0.830753
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 159
New value of Q matrix: 1.11806
New value of Value function: 1.11806
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1506
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.85566
New value of Value function: 0.85566
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1507
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.344585
New value of Value function: 2.30679
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1508
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 2.30217
New value of Value function: 2.30217
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1509
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 128
New value of Q matrix: 2.33153
New value of Value function: 2.33153
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1510
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.853949
New value of Value function: 0.853949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1511
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.878838
New value of Value function: 0.878838
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1512
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 2.32687
New value of Value function: 2.32687
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1513
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 130
New value of Q matrix: 2.35615
New value of Value function: 2.35615
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1514
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.179468
New value of Value function: 0.878838
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1515
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.903672
New value of Value function: 0.903672
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1516
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 2.35144
New value of Value function: 2.35144
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1517
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.614077
New value of Value function: 2.35144
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1518
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.695139
New value of Value function: 2.35144
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 160
New value of Q matrix: 1.15196
New value of Value function: 1.15196
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1520
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.927924
New value of Value function: 0.927924
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1521
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 132
New value of Q matrix: 2.38111
New value of Value function: 2.38111
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1522
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.952226
New value of Value function: 0.952226
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1523
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 133
New value of Q matrix: 2.41063
New value of Value function: 2.41063
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1524
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.193019
New value of Value function: 0.952226
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1525
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.118524
New value of Value function: 0.952226
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1526
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.381085
New value of Value function: 2.41063
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1527
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 2.43956
New value of Value function: 2.43956
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1528
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.950321
New value of Value function: 0.950321
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1529
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.94842
New value of Value function: 0.94842
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1530
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.973364
New value of Value function: 0.973364
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1531
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 135
New value of Q matrix: 2.46829
New value of Value function: 2.46829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1532
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.998326
New value of Value function: 0.998326
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1533
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.604881
New value of Value function: 2.46829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1534
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.212438
New value of Value function: 0.212438
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1535
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.725665
New value of Value function: 2.46829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1536
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 2.49689
New value of Value function: 2.49689
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1537
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 1.0233
New value of Value function: 1.0233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1538
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 2.4919
New value of Value function: 2.4919
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1539
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 138
New value of Q matrix: 2.52048
New value of Value function: 2.52048
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1540
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.207578
New value of Value function: 1.0233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1541
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.191204
New value of Value function: 1.0233
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1542
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 1.00666
New value of Value function: 1.00666
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1543
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.253558
New value of Value function: 0.253558
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1544
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 139
New value of Q matrix: 2.54819
New value of Value function: 2.54819
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1545
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 1.0324
New value of Value function: 1.0324
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1546
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.597347
New value of Value function: 2.54819
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1547
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0847339
New value of Value function: 0.253558
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1548
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.419331
New value of Value function: 2.54819
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1549
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 140
New value of Q matrix: 2.56093
New value of Value function: 2.56093
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1550
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.102716
New value of Value function: 0.205976
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1551
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.457041
New value of Value function: 2.56093
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1552
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 2.5883
New value of Value function: 2.5883
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1553
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.162743
New value of Value function: 1.0324
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1554
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.63199
New value of Value function: 2.5883
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1555
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 0.410067
New value of Value function: 2.5883
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1556
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 1.03033
New value of Value function: 1.03033
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1557
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.191944
New value of Value function: 1.03033
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1558
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.161585
New value of Value function: 0.253558
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1559
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 1.05631
New value of Value function: 1.05631
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1560
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 2.58312
New value of Value function: 2.58312
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1561
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 2.53602
New value of Value function: 2.53602
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1562
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.294135
New value of Value function: 0.294135
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1563
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 144
New value of Q matrix: 2.56432
New value of Value function: 2.56432
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1564
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 1.0542
New value of Value function: 1.0542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1565
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.172039
New value of Value function: 1.0542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1566
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 0.784285
New value of Value function: 0.784285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1567
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 1.07927
New value of Value function: 1.07927
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1568
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 2.59246
New value of Value function: 2.59246
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1569
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 1.07712
New value of Value function: 1.07712
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1570
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 1.10224
New value of Value function: 1.10224
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1571
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.415983
New value of Value function: 2.59246
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1572
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.172359
New value of Value function: 0.784285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1573
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.230804
New value of Value function: 0.784285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1574
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.104902
New value of Value function: 0.104902
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1575
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.122645
New value of Value function: 0.122645
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1576
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.234769
New value of Value function: 1.10224
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1577
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.487504
New value of Value function: 2.59246
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1578
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.223267
New value of Value function: 1.10224
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1579
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 1.09431
New value of Value function: 1.09431
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1580
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0569522
New value of Value function: 0.784285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1581
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 0.830807
New value of Value function: 0.830807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1582
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0113722
New value of Value function: 0.122645
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1583
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.166856
New value of Value function: 0.166856
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1584
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 2.6203
New value of Value function: 2.6203
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1585
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 1.11959
New value of Value function: 1.11959
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1586
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 2.64805
New value of Value function: 2.64805
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1587
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 1.14486
New value of Value function: 1.14486
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1588
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 2.64275
New value of Value function: 2.64275
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1589
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.495469
New value of Value function: 2.64275
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1590
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 149
New value of Q matrix: 2.67051
New value of Value function: 2.67051
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1591
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 1.17003
New value of Value function: 1.17003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1592
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 2.69816
New value of Value function: 2.69816
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1593
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 1.1952
New value of Value function: 1.1952
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1594
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 2.72571
New value of Value function: 2.72571
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1595
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.240315
New value of Value function: 1.1952
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1596
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.181002
New value of Value function: 1.1952
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1597
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 1.19281
New value of Value function: 1.19281
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1598
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.251544
New value of Value function: 1.19281
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1599
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 1.19042
New value of Value function: 1.19042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1600
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.256936
New value of Value function: 1.19042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1601
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.267941
New value of Value function: 1.19042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1602
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 1.18735
New value of Value function: 1.18735
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 161
New value of Q matrix: 1.19029
New value of Value function: 1.19029
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1604
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 1.18498
New value of Value function: 1.18498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1605
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 1.21034
New value of Value function: 1.21034
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1606
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 2.75298
New value of Value function: 2.75298
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1607
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.273584
New value of Value function: 1.21034
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1608
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 1.23569
New value of Value function: 1.23569
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1609
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 2.78016
New value of Value function: 2.78016
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1610
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 1.26102
New value of Value function: 1.26102
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1611
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.492708
New value of Value function: 2.78016
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1612
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.864234
New value of Value function: 0.864234
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1613
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.702048
New value of Value function: 2.78016
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1614
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 1.28584
New value of Value function: 1.28584
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1615
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.535603
New value of Value function: 2.78016
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1616
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 154
New value of Q matrix: 2.8077
New value of Value function: 2.8077
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1617
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 1.31066
New value of Value function: 1.31066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1618
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.794744
New value of Value function: 2.8077
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1619
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.200974
New value of Value function: 1.31066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1620
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.291704
New value of Value function: 1.31066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1621
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 1.33499
New value of Value function: 1.33499
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1622
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 155
New value of Q matrix: 2.83558
New value of Value function: 2.83558
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1623
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 1.35933
New value of Value function: 1.35933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1624
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 2.82991
New value of Value function: 2.82991
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1625
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 157
New value of Q matrix: 2.85778
New value of Value function: 2.85778
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1626
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 1.38358
New value of Value function: 1.38358
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1627
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 158
New value of Q matrix: 2.88553
New value of Value function: 2.88553
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1628
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 1.38081
New value of Value function: 1.38081
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1629
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 1.40514
New value of Value function: 1.40514
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1630
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 2.91311
New value of Value function: 2.91311
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1631
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 1.42947
New value of Value function: 1.42947
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1632
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 2.90728
New value of Value function: 2.90728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1633
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.535185
New value of Value function: 2.90728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1634
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 161
New value of Q matrix: 2.93487
New value of Value function: 2.93487
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1635
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 1.45371
New value of Value function: 1.45371
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1636
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 2.929
New value of Value function: 2.929
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1637
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 163
New value of Q matrix: 2.95659
New value of Value function: 2.95659
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1638
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 1.47785
New value of Value function: 1.47785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1639
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.57811
New value of Value function: 2.95659
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1640
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.741226
New value of Value function: 2.95659
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1641
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 164
New value of Q matrix: 2.98405
New value of Value function: 2.98405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1642
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 1.4749
New value of Value function: 1.4749
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1643
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.312418
New value of Value function: 1.4749
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1644
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 1.49911
New value of Value function: 1.49911
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1645
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 165
New value of Q matrix: 3.01136
New value of Value function: 3.01136
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1646
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 1.49611
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1647
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.289512
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1648
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.222803
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1649
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 3.03806
New value of Value function: 3.03806
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1650
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.310652
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1651
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.245277
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1652
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.295057
New value of Value function: 1.49611
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1653
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.03198
New value of Value function: 3.03198
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1654
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 168
New value of Q matrix: 3.05827
New value of Value function: 3.05827
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1655
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 1.52124
New value of Value function: 1.52124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1656
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.05216
New value of Value function: 3.05216
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1657
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 0.790109
New value of Value function: 3.05216
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1658
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.229239
New value of Value function: 0.229239
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1659
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.224336
New value of Value function: 1.52124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1660
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.331821
New value of Value function: 1.52124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1661
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 1.51224
New value of Value function: 1.51224
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.148422
New value of Value function: 1.19029
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.165583
New value of Value function: 1.19029
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 162
New value of Q matrix: 1.23371
New value of Value function: 1.23371
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1665
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.33339
New value of Value function: 1.51224
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1666
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 1.50922
New value of Value function: 1.50922
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1667
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.352351
New value of Value function: 1.50922
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1668
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 1.50124
New value of Value function: 1.50124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 163
New value of Q matrix: 1.30397
New value of Value function: 1.30397
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1670
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 170
New value of Q matrix: 3.07814
New value of Value function: 3.07814
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1671
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.382129
New value of Value function: 1.50124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1672
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 171
New value of Q matrix: 3.1036
New value of Value function: 3.1036
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1673
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.34502
New value of Value function: 1.50124
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1674
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 0.587485
New value of Value function: 3.1036
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1675
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.179075
New value of Value function: 0.179075
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1676
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 0.933971
New value of Value function: 0.933971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1677
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 1.49824
New value of Value function: 1.49824
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1678
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.246818
New value of Value function: 1.49824
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1679
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 1.49524
New value of Value function: 1.49524
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1680
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 1.49225
New value of Value function: 1.49225
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1681
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 1.47922
New value of Value function: 1.47922
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1682
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.971157
New value of Value function: 0.971157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1683
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.834713
New value of Value function: 3.1036
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1684
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 172
New value of Q matrix: 3.12815
New value of Value function: 3.12815
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1685
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 1.50594
New value of Value function: 1.50594
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1686
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.12189
New value of Value function: 3.12189
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1687
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.593216
New value of Value function: 3.12189
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1688
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.00793
New value of Value function: 1.00793
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1689
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.830501
New value of Value function: 3.12189
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1690
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.08293
New value of Value function: 3.08293
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 164
New value of Q matrix: 1.37339
New value of Value function: 1.37339
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1692
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 0.905126
New value of Value function: 3.08293
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1693
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 1.53131
New value of Value function: 1.53131
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1694
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.07676
New value of Value function: 3.07676
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1695
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 176
New value of Q matrix: 3.10279
New value of Value function: 3.10279
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1696
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.269445
New value of Value function: 1.53131
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1697
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 1.52825
New value of Value function: 1.52825
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1698
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 1.52519
New value of Value function: 1.52519
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1699
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 1.55054
New value of Value function: 1.55054
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1700
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.622398
New value of Value function: 3.10279
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1701
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 0.878017
New value of Value function: 3.10279
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1702
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.280505
New value of Value function: 0.280505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1703
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 177
New value of Q matrix: 3.10578
New value of Value function: 3.10578
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1704
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.330799
New value of Value function: 0.330799
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1705
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.04896
New value of Value function: 3.04896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1706
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.376162
New value of Value function: 0.376162
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1707
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.352075
New value of Value function: 1.55054
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1708
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.213235
New value of Value function: 0.376162
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1709
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 179
New value of Q matrix: 3.07589
New value of Value function: 3.07589
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1710
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 1.57489
New value of Value function: 1.57489
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1711
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 180
New value of Q matrix: 3.10272
New value of Value function: 3.10272
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1712
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.402834
New value of Value function: 1.57489
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1713
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.373381
New value of Value function: 1.57489
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1714
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 1.56812
New value of Value function: 1.56812
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1715
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 165
New value of Q matrix: 1.41414
New value of Value function: 1.41414
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1716
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.39414
New value of Value function: 1.56812
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1717
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.289511
New value of Value function: 1.56812
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.170908
New value of Value function: 1.41414
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 166
New value of Q matrix: 1.48171
New value of Value function: 1.48171
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1720
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 181
New value of Q matrix: 3.10662
New value of Value function: 3.10662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1721
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.380102
New value of Value function: 0.380102
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1722
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 182
New value of Q matrix: 3.11133
New value of Value function: 3.11133
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1723
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.428504
New value of Value function: 0.428504
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1724
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 183
New value of Q matrix: 3.11682
New value of Value function: 3.11682
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1725
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.156764
New value of Value function: 0.428504
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1726
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 184
New value of Q matrix: 3.14271
New value of Value function: 3.14271
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1727
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 1.59332
New value of Value function: 1.59332
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1728
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 185
New value of Q matrix: 3.16853
New value of Value function: 3.16853
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1729
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 1.61849
New value of Value function: 1.61849
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1730
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.1622
New value of Value function: 3.1622
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1731
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 187
New value of Q matrix: 3.18809
New value of Value function: 3.18809
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1732
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 1.64351
New value of Value function: 1.64351
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1733
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 188
New value of Q matrix: 3.21391
New value of Value function: 3.21391
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1734
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 1.64022
New value of Value function: 1.64022
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1735
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 1.63694
New value of Value function: 1.63694
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1736
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 1.66205
New value of Value function: 1.66205
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1737
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.20748
New value of Value function: 3.20748
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1738
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.599494
New value of Value function: 3.20748
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1739
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 1.0455
New value of Value function: 1.0455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1740
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 190
New value of Q matrix: 3.23325
New value of Value function: 3.23325
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1741
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.341919
New value of Value function: 1.66205
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1742
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 191
New value of Q matrix: 3.2585
New value of Value function: 3.2585
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1743
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 1.65873
New value of Value function: 1.65873
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1744
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 1.65541
New value of Value function: 1.65541
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1745
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 1.68095
New value of Value function: 1.68095
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1746
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.606323
New value of Value function: 3.2585
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1747
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0746322
New value of Value function: 1.0455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1748
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.04341
New value of Value function: 1.04341
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1749
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.0812
New value of Value function: 1.0812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1750
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.25198
New value of Value function: 3.25198
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1751
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.24548
New value of Value function: 3.24548
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1752
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 3.27083
New value of Value function: 3.27083
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1753
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 1.67759
New value of Value function: 1.67759
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1754
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.416454
New value of Value function: 1.67759
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1755
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 1.65175
New value of Value function: 1.65175
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1756
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0272161
New value of Value function: 0.428504
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1757
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0533426
New value of Value function: 0.428504
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 167
New value of Q matrix: 1.52181
New value of Value function: 1.52181
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1759
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 1.67759
New value of Value function: 1.67759
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1760
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.919332
New value of Value function: 3.27083
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1761
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.2328
New value of Value function: 3.2328
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 168
New value of Q matrix: 1.56157
New value of Value function: 1.56157
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1763
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 1.67424
New value of Value function: 1.67424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1764
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.424914
New value of Value function: 1.67424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1765
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 1.69894
New value of Value function: 1.69894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1766
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 196
New value of Q matrix: 3.25873
New value of Value function: 3.25873
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1767
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.365662
New value of Value function: 1.69894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1768
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.438706
New value of Value function: 1.69894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1769
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.368701
New value of Value function: 1.69894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1770
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 1.72362
New value of Value function: 1.72362
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1771
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.613658
New value of Value function: 3.25873
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1772
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.170172
New value of Value function: 1.0812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1773
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0786483
New value of Value function: 0.179075
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1774
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 197
New value of Q matrix: 3.28458
New value of Value function: 3.28458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1775
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.392352
New value of Value function: 1.72362
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1776
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 1.70861
New value of Value function: 1.70861
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1777
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 1.15033
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1778
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 1.73356
New value of Value function: 1.73356
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1779
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.946146
New value of Value function: 3.28458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1780
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.622091
New value of Value function: 3.28458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1781
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0938455
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1782
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.246894
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1783
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.187474
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1784
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.262662
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1785
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.278115
New value of Value function: 1.15033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1786
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 1.21853
New value of Value function: 1.21853
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1787
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 1.72082
New value of Value function: 1.72082
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1788
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 1.28513
New value of Value function: 1.28513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1789
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 1.71738
New value of Value function: 1.71738
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1790
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 1.74216
New value of Value function: 1.74216
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1791
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 0.992304
New value of Value function: 3.28458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1792
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 1.73867
New value of Value function: 1.73867
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1793
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 1.76302
New value of Value function: 1.76302
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1794
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 198
New value of Q matrix: 3.31062
New value of Value function: 3.31062
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1795
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.476007
New value of Value function: 1.76302
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1796
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.304
New value of Value function: 3.304
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1797
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 200
New value of Q matrix: 3.32965
New value of Value function: 3.32965
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1798
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.461666
New value of Value function: 1.76302
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1799
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.416239
New value of Value function: 1.76302
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1800
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 1.78769
New value of Value function: 1.78769
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1801
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 201
New value of Q matrix: 3.35524
New value of Value function: 3.35524
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1802
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 1.78412
New value of Value function: 1.78412
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1803
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 1.78055
New value of Value function: 1.78055
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1804
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.431047
New value of Value function: 1.78055
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1805
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 1.35148
New value of Value function: 1.35148
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1806
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 1.80533
New value of Value function: 1.80533
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1807
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.34853
New value of Value function: 3.34853
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1808
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.987496
New value of Value function: 3.34853
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1809
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.34183
New value of Value function: 3.34183
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1810
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 1.03261
New value of Value function: 3.34183
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1811
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.04007
New value of Value function: 3.34183
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 1.55845
New value of Value function: 1.55845
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 170
New value of Q matrix: 1.62743
New value of Value function: 1.62743
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1814
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.670103
New value of Value function: 3.34183
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1815
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.33515
New value of Value function: 3.33515
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1816
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 205
New value of Q matrix: 3.36094
New value of Value function: 3.36094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1817
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.498983
New value of Value function: 1.80533
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1818
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.521499
New value of Value function: 1.80533
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1819
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 1.82972
New value of Value function: 1.82972
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1820
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 206
New value of Q matrix: 3.38666
New value of Value function: 3.38666
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1821
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 1.85409
New value of Value function: 1.85409
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1822
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 207
New value of Q matrix: 3.4123
New value of Value function: 3.4123
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1823
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 1.87843
New value of Value function: 1.87843
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1824
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 208
New value of Q matrix: 3.43786
New value of Value function: 3.43786
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1825
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 1.90274
New value of Value function: 1.90274
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1826
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.75095
New value of Value function: 3.43786
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1827
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.484307
New value of Value function: 1.90274
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1828
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.633976
New value of Value function: 3.43786
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1829
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.38633
New value of Value function: 1.38633
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1830
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.43099
New value of Value function: 3.43099
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1831
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 210
New value of Q matrix: 3.45662
New value of Value function: 3.45662
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1832
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.499575
New value of Value function: 1.90274
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1833
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.297506
New value of Value function: 1.38633
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1834
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.208679
New value of Value function: 1.38633
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1835
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.35478
New value of Value function: 1.38633
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1836
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.209743
New value of Value function: 0.209743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1837
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.545318
New value of Value function: 1.90274
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1838
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.568661
New value of Value function: 1.90274
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1839
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 1.86846
New value of Value function: 1.86846
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1840
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.110708
New value of Value function: 0.209743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1841
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 1.86473
New value of Value function: 1.86473
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1842
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 1.861
New value of Value function: 1.861
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1843
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 1.886
New value of Value function: 1.886
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1844
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 211
New value of Q matrix: 3.48143
New value of Value function: 3.48143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1845
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 1.91094
New value of Value function: 1.91094
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1846
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.9927
New value of Value function: 3.48143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1847
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 1.453
New value of Value function: 1.453
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1848
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 1.93539
New value of Value function: 1.93539
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1849
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 0.685072
New value of Value function: 3.48143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1850
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.231702
New value of Value function: 0.231702
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1851
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.48661
New value of Value function: 1.48661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1852
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 1.03551
New value of Value function: 3.48143
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1853
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 212
New value of Q matrix: 3.50664
New value of Value function: 3.50664
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1854
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.393185
New value of Value function: 1.93539
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1855
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 1.9598
New value of Value function: 1.9598
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1856
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.08238
New value of Value function: 3.50664
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1857
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 1.02157
New value of Value function: 3.50664
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1858
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00677092
New value of Value function: 0.376162
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1859
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.431758
New value of Value function: 0.431758
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1860
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.49963
New value of Value function: 3.49963
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1861
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 214
New value of Q matrix: 3.52491
New value of Value function: 3.52491
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1862
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 1.95588
New value of Value function: 1.95588
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1863
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.592494
New value of Value function: 1.95588
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1864
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.553032
New value of Value function: 1.95588
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1865
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.698129
New value of Value function: 3.52491
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1866
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0991043
New value of Value function: 1.48661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1867
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.181416
New value of Value function: 0.39643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1868
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.249169
New value of Value function: 0.249169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1869
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.249651
New value of Value function: 0.249651
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1870
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.303062
New value of Value function: 0.303062
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1871
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.302456
New value of Value function: 0.302456
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1872
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.300901
New value of Value function: 0.300901
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1873
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.250074
New value of Value function: 0.250074
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1874
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.300299
New value of Value function: 0.300299
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1875
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.299698
New value of Value function: 0.299698
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1876
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.299099
New value of Value function: 0.299099
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1877
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0109147
New value of Value function: 0.299099
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1878
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0160801
New value of Value function: 0.299099
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1879
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.353284
New value of Value function: 0.353284
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1880
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00921489
New value of Value function: 0.00921489
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1881
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000123788
New value of Value function: 0.00687713
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1882
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000122107
New value of Value function: 0.00687713
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1883
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000167017
New value of Value function: 0.000167017
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1884
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000123788
New value of Value function: 0.00687713
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1885
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00686338
New value of Value function: 0.00686338
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1886
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0130852
New value of Value function: 0.0130852
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1887
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.352577
New value of Value function: 0.352577
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1888
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.013507
New value of Value function: 0.352577
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1889
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 0.405526
New value of Value function: 0.405526
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1890
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.82978e-08
New value of Value function: 1.5721e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1891
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.60296e-08
New value of Value function: 1.5721e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1892
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.82978e-08
New value of Value function: 1.5721e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1893
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.82978e-08
New value of Value function: 1.5721e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1894
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.23631e-06
New value of Value function: 6.23631e-06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1895
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.20858e-06
New value of Value function: 0.000344921
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1896
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000344231
New value of Value function: 0.000344231
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1897
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000343543
New value of Value function: 0.000343543
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1898
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000342856
New value of Value function: 0.000342856
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1899
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.1714e-06
New value of Value function: 0.000342856
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1900
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00567062
New value of Value function: 0.00567062
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1901
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.350543
New value of Value function: 0.350543
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1902
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00577391
New value of Value function: 0.00577391
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1903
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00683756
New value of Value function: 0.0120386
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1904
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0179257
New value of Value function: 0.0179257
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1905
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.072638
New value of Value function: 0.340435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1906
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.130713
New value of Value function: 0.340435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1907
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0255024
New value of Value function: 0.340435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1908
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.393943
New value of Value function: 0.393943
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1909
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0235544
New value of Value function: 0.0235544
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1910
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.343532
New value of Value function: 0.343532
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1911
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0603227
New value of Value function: 0.0603227
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1912
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0246581
New value of Value function: 0.0246581
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1913
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.447142
New value of Value function: 0.447142
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1914
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0597602
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1915
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00010393
New value of Value function: 0.0597602
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1916
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00610227
New value of Value function: 0.00610227
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1917
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0252407
New value of Value function: 0.0252407
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1918
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0596407
New value of Value function: 0.0596407
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1919
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0595214
New value of Value function: 0.0595214
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1920
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000211693
New value of Value function: 0.0595214
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1921
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00609007
New value of Value function: 0.00609007
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1922
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000162726
New value of Value function: 0.00609007
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1923
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00107743
New value of Value function: 0.00609007
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1924
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0594024
New value of Value function: 0.0594024
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1925
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0592836
New value of Value function: 0.0592836
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1926
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.059165
New value of Value function: 0.059165
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1927
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.118001
New value of Value function: 0.118001
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1928
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1929
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1930
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 0.00108
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1931
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00107784
New value of Value function: 0.00107784
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1932
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00107568
New value of Value function: 0.00107568
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1933
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0010994
New value of Value function: 0.0010994
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1934
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.118838
New value of Value function: 0.118838
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1935
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.46945e-05
New value of Value function: 0.00103757
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1936
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0010355
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1937
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.18396e-05
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1938
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.8639e-05
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1939
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.69052e-05
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1940
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.63604e-05
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1941
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.38722e-05
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1942
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000108642
New value of Value function: 0.0010355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1943
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00101513
New value of Value function: 0.00101513
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1944
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.88992e-05
New value of Value function: 1.88992e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1945
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.85213e-05
New value of Value function: 1.85213e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1946
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600183
New value of Value function: 0.0600183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1947
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00217525
New value of Value function: 0.00217525
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1948
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00213661
New value of Value function: 0.118838
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1949
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108033
New value of Value function: 0.0600183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1950
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108033
New value of Value function: 0.0600183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1951
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0610591
New value of Value function: 0.0610591
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 1952
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00111721
New value of Value function: 0.00111721
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1953
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215779
New value of Value function: 0.0610591
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 1954
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0621347
New value of Value function: 0.0621347
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1955
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.01098e-05
New value of Value function: 0.00111721
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1956
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00111498
New value of Value function: 0.00111498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1957
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00111275
New value of Value function: 0.00111275
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1958
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00220892
New value of Value function: 0.00220892
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1959
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00111843
New value of Value function: 0.0621347
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1960
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00221448
New value of Value function: 0.0621347
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1961
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0620105
New value of Value function: 0.0620105
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1962
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0618864
New value of Value function: 0.0618864
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1963
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.120688
New value of Value function: 0.120688
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1964
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00433713
New value of Value function: 0.00433713
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1965
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.120447
New value of Value function: 0.120447
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1966
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.060986
New value of Value function: 0.120447
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1967
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00430927
New value of Value function: 0.120447
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1968
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.118629
New value of Value function: 0.118629
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1969
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0620059
New value of Value function: 0.120447
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1970
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.120206
New value of Value function: 0.120206
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1971
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.17788
New value of Value function: 0.17788
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1972
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00432846
New value of Value function: 0.00432846
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1973
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00637721
New value of Value function: 0.00637721
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1974
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.119458
New value of Value function: 0.119458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1975
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.234437
New value of Value function: 0.234437
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1976
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0104695
New value of Value function: 0.0104695
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1977
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.289937
New value of Value function: 0.289937
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1978
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.015479
New value of Value function: 0.015479
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1979
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.289357
New value of Value function: 0.289357
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1980
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.343849
New value of Value function: 0.343849
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1981
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0154481
New value of Value function: 0.0154481
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1982
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00215025
New value of Value function: 0.0154481
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1983
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0623719
New value of Value function: 0.119458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1984
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0213284
New value of Value function: 0.0213284
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1985
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.397356
New value of Value function: 0.397356
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1986
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0280542
New value of Value function: 0.0280542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1987
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0679182
New value of Value function: 0.397356
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1988
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.449913
New value of Value function: 0.449913
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1989
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0279981
New value of Value function: 0.0279981
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1990
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0295884
New value of Value function: 0.0295884
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1991
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.125168
New value of Value function: 0.125168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1992
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.501448
New value of Value function: 0.501448
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1993
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0021464
New value of Value function: 0.0295884
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1994
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000111549
New value of Value function: 0.00217525
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1995
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0021709
New value of Value function: 0.0021709
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1996
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00438049
New value of Value function: 0.00438049
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 1997
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0031803
New value of Value function: 0.125168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1998
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.117894
New value of Value function: 0.117894
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1999
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0633775
New value of Value function: 0.125168
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2000
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.182743
New value of Value function: 0.182743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2001
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00758226
New value of Value function: 0.00758226
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2002
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.239225
New value of Value function: 0.239225
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2003
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0117367
New value of Value function: 0.0117367
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2004
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.118894
New value of Value function: 0.239225
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2005
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.015808
New value of Value function: 0.015808
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2006
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.071136
New value of Value function: 0.239225
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2007
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.551951
New value of Value function: 0.551951
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2008
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000532591
New value of Value function: 0.0295884
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2009
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0389317
New value of Value function: 0.0389317
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2010
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.550848
New value of Value function: 0.550848
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2011
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.600531
New value of Value function: 0.600531
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2012
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0388539
New value of Value function: 0.0388539
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2013
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000719077
New value of Value function: 0.0388539
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2014
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0488864
New value of Value function: 0.0488864
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2015
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.649401
New value of Value function: 0.649401
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2016
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00140189
New value of Value function: 0.0488864
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2017
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0595979
New value of Value function: 0.0595979
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2018
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.697485
New value of Value function: 0.697485
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2019
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00244662
New value of Value function: 0.0595979
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2020
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0709606
New value of Value function: 0.0709606
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2021
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0655004
New value of Value function: 0.697485
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2022
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0820962
New value of Value function: 0.0820962
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2023
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.69609
New value of Value function: 0.69609
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2024
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.07672
New value of Value function: 0.69609
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2025
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.694698
New value of Value function: 0.694698
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2026
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.742282
New value of Value function: 0.742282
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2027
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00640951
New value of Value function: 0.0820962
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2028
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.295918
New value of Value function: 0.295918
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2029
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00387542
New value of Value function: 0.0820962
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2030
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0857808
New value of Value function: 0.0857808
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2031
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.351544
New value of Value function: 0.351544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2032
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0903929
New value of Value function: 0.0903929
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2033
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.40614
New value of Value function: 0.40614
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2034
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0958956
New value of Value function: 0.0958956
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2035
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.459743
New value of Value function: 0.459743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2036
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.102253
New value of Value function: 0.102253
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2037
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.463909
New value of Value function: 0.463909
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2038
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.789277
New value of Value function: 0.789277
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2039
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.102049
New value of Value function: 0.102049
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2040
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.108358
New value of Value function: 0.108358
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2041
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.516582
New value of Value function: 0.516582
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2042
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.115489
New value of Value function: 0.115489
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2043
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.125814
New value of Value function: 0.516582
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2044
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0103548
New value of Value function: 0.516582
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2045
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.515548
New value of Value function: 0.515548
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2046
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.567316
New value of Value function: 0.567316
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2047
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.123391
New value of Value function: 0.123391
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2048
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.570177
New value of Value function: 0.570177
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2049
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.835712
New value of Value function: 0.835712
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2050
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.123144
New value of Value function: 0.123144
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2051
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.130945
New value of Value function: 0.130945
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2052
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.573816
New value of Value function: 0.573816
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2053
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0855143
New value of Value function: 0.835712
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2054
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.624697
New value of Value function: 0.624697
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2055
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0175259
New value of Value function: 0.130945
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2056
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.672488
New value of Value function: 0.672488
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2057
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0275966
New value of Value function: 0.0275966
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2058
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.719534
New value of Value function: 0.719534
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2059
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0275414
New value of Value function: 0.0275414
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2060
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0139464
New value of Value function: 0.0275414
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2061
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.13207
New value of Value function: 0.719534
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2062
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.143369
New value of Value function: 0.143369
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2063
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.881579
New value of Value function: 0.881579
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2064
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.143082
New value of Value function: 0.143082
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2065
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.156089
New value of Value function: 0.156089
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2066
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.926757
New value of Value function: 0.926757
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2067
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.169648
New value of Value function: 0.169648
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2068
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0727179
New value of Value function: 0.926757
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2069
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.718095
New value of Value function: 0.718095
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2070
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.764229
New value of Value function: 0.764229
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2071
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00316299
New value of Value function: 0.0275414
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2072
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00685158
New value of Value function: 0.169648
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2073
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.180012
New value of Value function: 0.180012
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2074
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.812185
New value of Value function: 0.812185
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2075
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.191031
New value of Value function: 0.191031
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2076
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.85938
New value of Value function: 0.85938
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2077
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00414325
New value of Value function: 0.191031
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2078
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.190649
New value of Value function: 0.190649
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2079
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.203517
New value of Value function: 0.203517
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2080
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0636633
New value of Value function: 0.926757
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2081
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0233962
New value of Value function: 0.203517
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2082
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.969377
New value of Value function: 0.969377
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2083
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0640551
New value of Value function: 0.0640551
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2084
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.063927
New value of Value function: 0.063927
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2085
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.122648
New value of Value function: 0.122648
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2086
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00220767
New value of Value function: 0.00220767
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2087
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.180235
New value of Value function: 0.180235
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2088
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.97381e-05
New value of Value function: 0.00220767
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2089
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.97381e-05
New value of Value function: 0.00220767
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2090
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0293327
New value of Value function: 0.0293327
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 1.62417
New value of Value function: 1.62417
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 1.62093
New value of Value function: 1.62093
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 1.61768
New value of Value function: 1.61768
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2094
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.183507
New value of Value function: 1.61768
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2095
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 1.61445
New value of Value function: 1.61445
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 1.61122
New value of Value function: 1.61122
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2097
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.208839
New value of Value function: 1.61122
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2098
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 1.608
New value of Value function: 1.608
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2099
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 1.60478
New value of Value function: 1.60478
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 1.60157
New value of Value function: 1.60157
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 1.59837
New value of Value function: 1.59837
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 1.59517
New value of Value function: 1.59517
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.127377
New value of Value function: 1.59517
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 1.59198
New value of Value function: 1.59198
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.233318
New value of Value function: 1.59198
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 1.5888
New value of Value function: 1.5888
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 1.58562
New value of Value function: 1.58562
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 1.58245
New value of Value function: 1.58245
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 1.57928
New value of Value function: 1.57928
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 1.57613
New value of Value function: 1.57613
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 1.57297
New value of Value function: 1.57297
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 1.56983
New value of Value function: 1.56983
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.190528
New value of Value function: 1.56983
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.256909
New value of Value function: 1.56983
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 1.56669
New value of Value function: 1.56669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.214918
New value of Value function: 1.56669
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 1.56355
New value of Value function: 1.56355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.152974
New value of Value function: 1.56355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.238764
New value of Value function: 1.56355
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 1.56043
New value of Value function: 1.56043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.279858
New value of Value function: 1.56043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 1.55731
New value of Value function: 1.55731
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 1.55419
New value of Value function: 1.55419
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.195465
New value of Value function: 1.55419
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 1.55108
New value of Value function: 1.55108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 1.54798
New value of Value function: 1.54798
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.219419
New value of Value function: 1.54798
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 1.54489
New value of Value function: 1.54489
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 1.5418
New value of Value function: 1.5418
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.261741
New value of Value function: 1.5418
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 1.53871
New value of Value function: 1.53871
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 1.53563
New value of Value function: 1.53563
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.242672
New value of Value function: 1.53563
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 1.53256
New value of Value function: 1.53256
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 1.5295
New value of Value function: 1.5295
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 1.52644
New value of Value function: 1.52644
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.283982
New value of Value function: 1.52644
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 1.52339
New value of Value function: 1.52339
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 1.52034
New value of Value function: 1.52034
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 1.5173
New value of Value function: 1.5173
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 1.51426
New value of Value function: 1.51426
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 1.51124
New value of Value function: 1.51124
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.301463
New value of Value function: 1.51124
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 1.50821
New value of Value function: 1.50821
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 1.5052
New value of Value function: 1.5052
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 1.50219
New value of Value function: 1.50219
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 1.49918
New value of Value function: 1.49918
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 1.49618
New value of Value function: 1.49618
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 1.49319
New value of Value function: 1.49319
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 1.4902
New value of Value function: 1.4902
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.176738
New value of Value function: 1.4902
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.305126
New value of Value function: 1.4902
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.264643
New value of Value function: 1.4902
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 1.48722
New value of Value function: 1.48722
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 1.48425
New value of Value function: 1.48425
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 1.48128
New value of Value function: 1.48128
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.286013
New value of Value function: 1.48128
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 1.47832
New value of Value function: 1.47832
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 1.47536
New value of Value function: 1.47536
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.19976
New value of Value function: 1.47536
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.32558
New value of Value function: 1.47536
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.306849
New value of Value function: 1.47536
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 1.47241
New value of Value function: 1.47241
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.327216
New value of Value function: 1.47241
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 1.46947
New value of Value function: 1.46947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 1.46653
New value of Value function: 1.46653
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 1.46359
New value of Value function: 1.46359
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.222109
New value of Value function: 1.46359
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 1.46067
New value of Value function: 1.46067
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 1.45775
New value of Value function: 1.45775
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.243907
New value of Value function: 1.45775
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 1.45483
New value of Value function: 1.45483
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 1.45192
New value of Value function: 1.45192
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.321568
New value of Value function: 1.45192
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 1.44902
New value of Value function: 1.44902
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 1.44612
New value of Value function: 1.44612
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 1.44323
New value of Value function: 1.44323
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 1.44034
New value of Value function: 1.44034
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 1.43746
New value of Value function: 1.43746
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 1.43458
New value of Value function: 1.43458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.264851
New value of Value function: 1.43458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 1.43172
New value of Value function: 1.43172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 1.42885
New value of Value function: 1.42885
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 1.42599
New value of Value function: 1.42599
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.344736
New value of Value function: 1.42599
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.340805
New value of Value function: 1.42599
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 1.42314
New value of Value function: 1.42314
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 1.4203
New value of Value function: 1.4203
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 1.41746
New value of Value function: 1.41746
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 1.41462
New value of Value function: 1.41462
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.363305
New value of Value function: 1.41462
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 1.41179
New value of Value function: 1.41179
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 1.40897
New value of Value function: 1.40897
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 1.40615
New value of Value function: 1.40615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 1.40334
New value of Value function: 1.40334
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 1.40053
New value of Value function: 1.40053
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 1.39773
New value of Value function: 1.39773
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 1.39493
New value of Value function: 1.39493
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 1.39214
New value of Value function: 1.39214
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 1.38936
New value of Value function: 1.38936
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.34568
New value of Value function: 1.38936
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.284562
New value of Value function: 1.38936
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 1.38658
New value of Value function: 1.38658
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.380997
New value of Value function: 1.38658
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 1.38381
New value of Value function: 1.38381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 1.38104
New value of Value function: 1.38104
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.358848
New value of Value function: 1.38104
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 1.37828
New value of Value function: 1.37828
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 1.37552
New value of Value function: 1.37552
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 1.37277
New value of Value function: 1.37277
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 1.37003
New value of Value function: 1.37003
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.376331
New value of Value function: 1.37003
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 1.36729
New value of Value function: 1.36729
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 1.36455
New value of Value function: 1.36455
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 1.36182
New value of Value function: 1.36182
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 1.3591
New value of Value function: 1.3591
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 1.35638
New value of Value function: 1.35638
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 1.35367
New value of Value function: 1.35367
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 1.35096
New value of Value function: 1.35096
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 1.34826
New value of Value function: 1.34826
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 265
New value of Q matrix: 1.36129
New value of Value function: 1.36129
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2222
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2223
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0245033
New value of Value function: 0.0245033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.393308
New value of Value function: 1.36129
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 1.35857
New value of Value function: 1.35857
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 1.35585
New value of Value function: 1.35585
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 268
New value of Q matrix: 1.36918
New value of Value function: 1.36918
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2228
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000752978
New value of Value function: 0.0245033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2229
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0604417
New value of Value function: 0.0604417
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2230
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000441059
New value of Value function: 0.0245033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2231
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00182587
New value of Value function: 0.0245033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2232
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.119674
New value of Value function: 0.119674
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2233
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000873297
New value of Value function: 0.0245033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2234
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0244543
New value of Value function: 0.0244543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2235
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0246452
New value of Value function: 0.0246452
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 269
New value of Q matrix: 1.38224
New value of Value function: 1.38224
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2237
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00129944
New value of Value function: 0.0246452
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2238
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0245959
New value of Value function: 0.0245959
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2239
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0488454
New value of Value function: 0.0488454
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 1.37947
New value of Value function: 1.37947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 271
New value of Q matrix: 1.39276
New value of Value function: 1.39276
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2242
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000879218
New value of Value function: 0.0488454
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2243
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00215267
New value of Value function: 0.0488454
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2244
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0487478
New value of Value function: 0.0487478
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2245
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00298708
New value of Value function: 0.0487478
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2246
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00266681
New value of Value function: 0.0487478
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2247
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000861634
New value of Value function: 0.0487478
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2248
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00087746
New value of Value function: 0.00087746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2249
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0486503
New value of Value function: 0.0486503
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2250
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00348918
New value of Value function: 0.0486503
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2251
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.048553
New value of Value function: 0.048553
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2252
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0726516
New value of Value function: 0.0726516
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 1.38998
New value of Value function: 1.38998
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.398397
New value of Value function: 1.38998
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 273
New value of Q matrix: 1.40349
New value of Value function: 1.40349
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2256
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0725063
New value of Value function: 0.0725063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2257
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0963189
New value of Value function: 0.0963189
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 1.40068
New value of Value function: 1.40068
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 275
New value of Q matrix: 1.4144
New value of Value function: 1.4144
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2260
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0961263
New value of Value function: 0.0961263
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2261
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.119663
New value of Value function: 0.119663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 1.41157
New value of Value function: 1.41157
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 277
New value of Q matrix: 1.42549
New value of Value function: 1.42549
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2264
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.119424
New value of Value function: 0.119424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2265
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0290783
New value of Value function: 0.119424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 278
New value of Q matrix: 1.43913
New value of Value function: 1.43913
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2267
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.119185
New value of Value function: 0.119185
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2268
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.142705
New value of Value function: 0.142705
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 1.43625
New value of Value function: 1.43625
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 280
New value of Q matrix: 1.4501
New value of Value function: 1.4501
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2271
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.14242
New value of Value function: 0.14242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2272
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0310602
New value of Value function: 0.14242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2273
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.024104
New value of Value function: 0.14242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2274
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2275
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0261017
New value of Value function: 0.0261017
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 281
New value of Q matrix: 1.46366
New value of Value function: 1.46366
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2277
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.142135
New value of Value function: 0.142135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2278
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0309089
New value of Value function: 0.142135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2279
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000469831
New value of Value function: 0.0261017
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2280
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00255843
New value of Value function: 0.0261017
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2281
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.141851
New value of Value function: 0.141851
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2282
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.16536
New value of Value function: 0.16536
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.305217
New value of Value function: 1.46366
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 282
New value of Q matrix: 1.47736
New value of Value function: 1.47736
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2285
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.165029
New value of Value function: 0.165029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2286
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.188321
New value of Value function: 0.188321
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.412034
New value of Value function: 1.47736
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 1.47441
New value of Value function: 1.47441
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 1.47146
New value of Value function: 1.47146
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.365252
New value of Value function: 1.47146
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.416915
New value of Value function: 1.47146
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.384434
New value of Value function: 1.47146
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 1.46852
New value of Value function: 1.46852
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.43501
New value of Value function: 1.46852
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 286
New value of Q matrix: 1.47962
New value of Value function: 1.47962
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2296
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0260495
New value of Value function: 0.0260495
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2297
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00589704
New value of Value function: 0.0260495
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2298
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.185023
New value of Value function: 0.185023
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2299
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0259974
New value of Value function: 0.0259974
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2300
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000928389
New value of Value function: 0.0259974
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2301
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0275429
New value of Value function: 0.0275429
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 1.47666
New value of Value function: 1.47666
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.45289
New value of Value function: 1.47666
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 1.4737
New value of Value function: 1.4737
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.43032
New value of Value function: 1.4737
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.325639
New value of Value function: 1.4737
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 289
New value of Q matrix: 1.48756
New value of Value function: 1.48756
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2308
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.184653
New value of Value function: 0.184653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2309
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.207736
New value of Value function: 0.207736
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 1.48458
New value of Value function: 1.48458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 291
New value of Q matrix: 1.49863
New value of Value function: 1.49863
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2312
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.207321
New value of Value function: 0.207321
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2313
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.23015
New value of Value function: 0.23015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 1.49563
New value of Value function: 1.49563
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 293
New value of Q matrix: 1.50986
New value of Value function: 1.50986
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2316
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.22969
New value of Value function: 0.22969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2317
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.252273
New value of Value function: 0.252273
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 1.50684
New value of Value function: 1.50684
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 295
New value of Q matrix: 1.52125
New value of Value function: 1.52125
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2320
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.251769
New value of Value function: 0.251769
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2321
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0303098
New value of Value function: 0.251769
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 296
New value of Q matrix: 1.53536
New value of Value function: 1.53536
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2323
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0342355
New value of Value function: 0.251769
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2324
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.251265
New value of Value function: 0.251265
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2325
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0512583
New value of Value function: 0.251265
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 1.53228
New value of Value function: 1.53228
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 0.363649
New value of Value function: 1.53228
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2328
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.250763
New value of Value function: 0.250763
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2329
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0778143
New value of Value function: 0.250763
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 1.52922
New value of Value function: 1.52922
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 0.40089
New value of Value function: 1.52922
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2332
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.250261
New value of Value function: 0.250261
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2333
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.272782
New value of Value function: 0.272782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 1.52616
New value of Value function: 1.52616
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 300
New value of Q matrix: 1.54055
New value of Value function: 1.54055
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2336
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00575448
New value of Value function: 0.272782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2337
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.272236
New value of Value function: 0.272236
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2338
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.271692
New value of Value function: 0.271692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2339
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0351812
New value of Value function: 0.271692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2340
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0811484
New value of Value function: 0.271692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2341
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.107255
New value of Value function: 0.271692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 1.53747
New value of Value function: 1.53747
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 302
New value of Q matrix: 1.55161
New value of Value function: 1.55161
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2344
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.271149
New value of Value function: 0.271149
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2345
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.293654
New value of Value function: 0.293654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 1.54851
New value of Value function: 1.54851
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.449587
New value of Value function: 1.54851
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.420745
New value of Value function: 1.54851
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.404618
New value of Value function: 1.54851
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 304
New value of Q matrix: 1.56282
New value of Value function: 1.56282
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2351
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.293067
New value of Value function: 0.293067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2352
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.315337
New value of Value function: 0.315337
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.471963
New value of Value function: 1.56282
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 1.5597
New value of Value function: 1.5597
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 1.55658
New value of Value function: 1.55658
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 307
New value of Q matrix: 1.57112
New value of Value function: 1.57112
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2357
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0113154
New value of Value function: 0.315337
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2358
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.314706
New value of Value function: 0.314706
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2359
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0401422
New value of Value function: 0.314706
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2360
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.314077
New value of Value function: 0.314077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2361
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0392041
New value of Value function: 0.314077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2362
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.313448
New value of Value function: 0.313448
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2363
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.33546
New value of Value function: 0.33546
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 1.56798
New value of Value function: 1.56798
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.468819
New value of Value function: 1.56798
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 1.56484
New value of Value function: 1.56484
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 310
New value of Q matrix: 1.57958
New value of Value function: 1.57958
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2368
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.334789
New value of Value function: 0.334789
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2369
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.356525
New value of Value function: 0.356525
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.440763
New value of Value function: 1.57958
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 311
New value of Q matrix: 1.59441
New value of Value function: 1.59441
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2372
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.355812
New value of Value function: 0.355812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2373
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.13381
New value of Value function: 0.355812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.425225
New value of Value function: 1.59441
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.491223
New value of Value function: 1.59441
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 1.59122
New value of Value function: 1.59122
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.488084
New value of Value function: 1.59122
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 1.58804
New value of Value function: 1.58804
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 1.58486
New value of Value function: 1.58486
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.445248
New value of Value function: 1.58486
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 315
New value of Q matrix: 1.59957
New value of Value function: 1.59957
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2382
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.355101
New value of Value function: 0.355101
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2383
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.376791
New value of Value function: 0.376791
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 1.59637
New value of Value function: 1.59637
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 317
New value of Q matrix: 1.61123
New value of Value function: 1.61123
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2386
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0178714
New value of Value function: 0.376791
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2387
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.376037
New value of Value function: 0.376037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2388
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.375285
New value of Value function: 0.375285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2389
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.396782
New value of Value function: 0.396782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 1.608
New value of Value function: 1.608
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 319
New value of Q matrix: 1.62298
New value of Value function: 1.62298
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2392
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.395988
New value of Value function: 0.395988
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2393
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.417282
New value of Value function: 0.417282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.465557
New value of Value function: 1.62298
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 1.61974
New value of Value function: 1.61974
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 321
New value of Q matrix: 1.63486
New value of Value function: 1.63486
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2397
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.416447
New value of Value function: 0.416447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2398
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0468354
New value of Value function: 0.416447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2399
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.415615
New value of Value function: 0.415615
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2400
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.43673
New value of Value function: 0.43673
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 1.63159
New value of Value function: 1.63159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.510767
New value of Value function: 1.63159
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 1.62832
New value of Value function: 1.62832
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 324
New value of Q matrix: 1.64362
New value of Value function: 1.64362
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2405
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.435856
New value of Value function: 0.435856
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2406
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.456724
New value of Value function: 0.456724
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 1.64033
New value of Value function: 1.64033
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 326
New value of Q matrix: 1.65574
New value of Value function: 1.65574
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2409
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0541198
New value of Value function: 0.456724
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2410
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.455811
New value of Value function: 0.455811
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2411
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.454899
New value of Value function: 0.454899
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2412
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.475605
New value of Value function: 0.475605
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 1.65243
New value of Value function: 1.65243
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 328
New value of Q matrix: 1.66794
New value of Value function: 1.66794
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2415
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.474653
New value of Value function: 0.474653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2416
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.495183
New value of Value function: 0.495183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 1.66461
New value of Value function: 1.66461
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 330
New value of Q matrix: 1.68023
New value of Value function: 1.68023
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2419
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.494193
New value of Value function: 0.494193
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2420
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.514553
New value of Value function: 0.514553
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.48649
New value of Value function: 1.68023
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 1.67687
New value of Value function: 1.67687
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 332
New value of Q matrix: 1.69259
New value of Value function: 1.69259
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2424
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.513524
New value of Value function: 0.513524
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2425
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0267574
New value of Value function: 0.513524
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2426
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.140377
New value of Value function: 0.513524
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2427
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.53372
New value of Value function: 0.53372
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 1.68921
New value of Value function: 1.68921
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 0.481555
New value of Value function: 1.68921
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2430
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.532653
New value of Value function: 0.532653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2431
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.552406
New value of Value function: 0.552406
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.502329
New value of Value function: 1.68921
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 334
New value of Q matrix: 1.69592
New value of Value function: 1.69592
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2434
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0157224
New value of Value function: 0.0275429
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2435
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.541853
New value of Value function: 0.541853
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2436
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0274878
New value of Value function: 0.0274878
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2437
----------
State: 1797
	Distance: 3
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0574646
New value of Value function: 0.0574646
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.531078
New value of Value function: 1.69592
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 1.69253
New value of Value function: 1.69253
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 1.68914
New value of Value function: 1.68914
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 337
New value of Q matrix: 1.70511
New value of Value function: 1.70511
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2442
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.54077
New value of Value function: 0.54077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2443
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.560646
New value of Value function: 0.560646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 1.7017
New value of Value function: 1.7017
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.551087
New value of Value function: 1.7017
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 1.6983
New value of Value function: 1.6983
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 340
New value of Q matrix: 1.71443
New value of Value function: 1.71443
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2448
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.063129
New value of Value function: 0.560646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2449
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.026238
New value of Value function: 0.560646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2450
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0100916
New value of Value function: 0.0100916
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2451
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.559525
New value of Value function: 0.559525
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2452
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.558406
New value of Value function: 0.558406
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2453
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.578097
New value of Value function: 0.578097
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 1.711
New value of Value function: 1.711
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 342
New value of Q matrix: 1.72718
New value of Value function: 1.72718
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2456
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.576941
New value of Value function: 0.576941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2457
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0695093
New value of Value function: 0.576941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 343
New value of Q matrix: 1.74302
New value of Value function: 1.74302
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2459
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.575787
New value of Value function: 0.575787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2460
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0360774
New value of Value function: 0.575787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2461
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.574636
New value of Value function: 0.574636
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2462
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.168944
New value of Value function: 0.574636
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.57144
New value of Value function: 1.74302
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.591385
New value of Value function: 1.74302
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 1.73954
New value of Value function: 1.73954
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.523594
New value of Value function: 1.73954
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 1.73606
New value of Value function: 1.73606
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 346
New value of Q matrix: 1.74134
New value of Value function: 1.74134
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2469
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2470
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0313441
New value of Value function: 0.0313441
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 347
New value of Q matrix: 1.74708
New value of Value function: 1.74708
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2472
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0307172
New value of Value function: 0.0307172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2473
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00055291
New value of Value function: 0.00055291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2474
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.95237e-06
New value of Value function: 0.0307172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2475
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00055291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2476
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1888
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2477
----------
State: 1888
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000181649
New value of Value function: 0.000181649
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2478
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000181649
New value of Value function: 0.0100916
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2479
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000181649
New value of Value function: 0.0100916
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2480
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0100714
New value of Value function: 0.0100714
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2481
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00987002
New value of Value function: 0.00987002
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2482
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00017766
New value of Value function: 0.00017766
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2483
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00967582
New value of Value function: 0.00967582
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2484
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000177305
New value of Value function: 0.000177305
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2485
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.19149e-06
New value of Value function: 0.000177305
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2486
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06001
New value of Value function: 0.06001
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2487
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1266
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00055291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2488
----------
State: 1266
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.95237e-06
New value of Value function: 9.95237e-06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2489
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.00055291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2490
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2491
----------
State: 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2492
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2493
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.95237e-06
New value of Value function: 9.95237e-06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2494
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000551804
New value of Value function: 0.000551804
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2495
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1312
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.000551804
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2496
----------
State: 1312
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00055291
New value of Value function: 0.00055291
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2497
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.96858e-05
New value of Value function: 0.0307172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2498
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00109368
New value of Value function: 0.00109368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2499
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00109947
New value of Value function: 0.0307172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2500
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.119363
New value of Value function: 0.119363
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2501
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00055291
New value of Value function: 0.0307172
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2502
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0306558
New value of Value function: 0.0306558
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2503
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0300623
New value of Value function: 0.0300623
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2504
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00161293
New value of Value function: 0.00161293
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2505
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0294901
New value of Value function: 0.0294901
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2506
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00211149
New value of Value function: 0.00211149
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2507
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0289383
New value of Value function: 0.0289383
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2508
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00259015
New value of Value function: 0.00259015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2509
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0284062
New value of Value function: 0.0284062
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2510
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00214853
New value of Value function: 0.00259015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2511
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.177022
New value of Value function: 0.177022
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2512
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00304966
New value of Value function: 0.00304966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2513
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00426388
New value of Value function: 0.0284062
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2514
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0605144
New value of Value function: 0.177022
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2515
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00105316
New value of Value function: 0.0284062
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2516
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0283494
New value of Value function: 0.0283494
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2517
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0309688
New value of Value function: 0.0309688
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2518
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.234039
New value of Value function: 0.234039
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2519
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0304043
New value of Value function: 0.0304043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2520
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000547277
New value of Value function: 0.00304966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2521
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0298511
New value of Value function: 0.0298511
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2522
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00352599
New value of Value function: 0.00352599
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2523
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0293176
New value of Value function: 0.0293176
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2524
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00398318
New value of Value function: 0.00398318
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2525
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0042503
New value of Value function: 0.0293176
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2526
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00443123
New value of Value function: 0.00443123
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2527
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.028811
New value of Value function: 0.028811
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2528
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00486121
New value of Value function: 0.00486121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2529
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0283222
New value of Value function: 0.0283222
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2530
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00631826
New value of Value function: 0.00631826
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2531
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.289472
New value of Value function: 0.289472
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2532
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0114024
New value of Value function: 0.0114024
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2533
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.343888
New value of Value function: 0.343888
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2534
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0173643
New value of Value function: 0.0173643
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2535
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.397323
New value of Value function: 0.397323
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2536
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0241688
New value of Value function: 0.0241688
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2537
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00732557
New value of Value function: 0.397323
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2538
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.449811
New value of Value function: 0.449811
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2539
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1314
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0241688
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2540
----------
State: 1314
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1314
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2541
----------
State: 1314
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.79143e-07
New value of Value function: 1.79143e-07
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2542
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.00108
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2543
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2544
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1936
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2545
----------
State: 1936
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2546
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2547
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2548
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.944e-05
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2549
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00105875
New value of Value function: 0.00105875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2550
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2551
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2552
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2553
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2554
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2555
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1356
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2556
----------
State: 1356
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 1408
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2557
----------
State: 1408
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.4992e-07
New value of Value function: 3.4992e-07
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2558
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.4992e-07
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2559
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.42922e-07
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2560
----------
State: 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.4992e-07
New value of Value function: 3.4992e-07
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2561
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.42362e-07
New value of Value function: 1.944e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2562
----------
State: 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1458
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3.4992e-07
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2563
----------
State: 1458
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.4992e-07
New value of Value function: 3.4992e-07
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2564
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.94011e-05
New value of Value function: 1.94011e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2565
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.4922e-07
New value of Value function: 1.94011e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2566
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1459
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 1
Action: 0
	Turn left
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2567
----------
State: 1459
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 1
State': 1411
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 1
Action: 2
	Move front
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2568
----------
State: 1411
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2569
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1459
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 1
Action: 0
	Turn left
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 2.036
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2570
----------
State: 1459
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 1
State': 1453
	Distance: 2
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.96
New value of Value function: 1.96
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2571
----------
State: 1453
	Distance: 2
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.036648
New value of Value function: 0.036648
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2572
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2573
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2574
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2575
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2576
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.036648
New value of Value function: 0.036648
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2577
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000659664
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2578
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1458
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.035915
New value of Value function: 0.035915
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2579
----------
State: 1458
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 0
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000646471
New value of Value function: 0.000646471
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2580
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0718447
New value of Value function: 0.0718447
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2581
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00129321
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2582
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00129321
New value of Value function: 0.0718447
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2583
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00129321
New value of Value function: 0.0718447
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2584
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0718447
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2585
----------
State: 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0612932
New value of Value function: 0.0612932
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2586
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.107056
New value of Value function: 0.107056
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2587
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0372673
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2588
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2589
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00108
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2590
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0021384
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2591
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600191
New value of Value function: 0.0600191
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2592
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90575e-05
New value of Value function: 0.00105875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2593
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1308
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.00105875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2594
----------
State: 1308
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2595
----------
State: 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90575e-05
New value of Value function: 1.90575e-05
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2596
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00105663
New value of Value function: 0.00105663
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2597
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.87727e-05
New value of Value function: 0.00105663
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2598
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00105452
New value of Value function: 0.00105452
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2599
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00105241
New value of Value function: 0.00105241
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2600
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0370314
New value of Value function: 0.0370314
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2601
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.996
New value of Value function: 1.996
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2602
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.95801
New value of Value function: 1.95801
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2603
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.141563
New value of Value function: 0.141563
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2604
----------
State: 1456
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 0
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0717661
New value of Value function: 2.036
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2605
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.9214
New value of Value function: 1.9214
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2606
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00110328
New value of Value function: 0.141563
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 2607
----------
State: 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00110328
New value of Value function: 0.0612932
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2608
----------
State: 2033
	Distance: 3
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108121
New value of Value function: 0.0612932
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2609
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2610
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2611
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2612
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2613
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2614
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2615
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2616
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2617
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2618
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2619
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.97892e-05
New value of Value function: 1.97892e-05
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2620
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.0600004
New value of Value function: 0.0600004
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2621
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00108001
New value of Value function: 0.00108001
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2622
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588003
New value of Value function: 0.0588003
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2623
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2624
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00105841
New value of Value function: 0.00105841
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2625
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0576434
New value of Value function: 0.0576434
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2626
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00207482
New value of Value function: 0.00207482
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2627
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0565279
New value of Value function: 0.0565279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2628
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00305082
New value of Value function: 0.00305082
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2629
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00103655
New value of Value function: 0.0565279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2630
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0554522
New value of Value function: 0.0554522
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2631
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.49148e-05
New value of Value function: 0.00305082
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2632
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.49148e-05
New value of Value function: 0.00305082
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2633
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00304472
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2634
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.4805e-05
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2635
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000108622
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2636
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.4805e-05
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2637
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000108514
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2638
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000108622
New value of Value function: 0.00304472
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2639
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00303863
New value of Value function: 0.00303863
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2640
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.0601063
New value of Value function: 0.0601063
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2641
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.94401e-05
New value of Value function: 1.94401e-05
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2642
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00107785
New value of Value function: 0.00107785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2643
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.87947e-05
New value of Value function: 0.00107785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2644
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.94012e-05
New value of Value function: 0.00107785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2645
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00107569
New value of Value function: 0.00107569
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2646
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00205232
New value of Value function: 0.00205232
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2647
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0553413
New value of Value function: 0.0553413
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2648
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0553164
New value of Value function: 0.0553164
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2649
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118905
New value of Value function: 0.118905
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2650
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.5993e-05
New value of Value function: 5.5993e-05
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2651
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00300697
New value of Value function: 0.00300697
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2652
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.0600732
New value of Value function: 0.0600732
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2653
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00402814
New value of Value function: 0.00402814
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2654
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.059953
New value of Value function: 0.059953
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2655
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.118826
New value of Value function: 0.118826
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2656
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000110525
New value of Value function: 0.00402814
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2657
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000108315
New value of Value function: 0.00402814
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2658
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2659
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2660
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2661
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000495745
New value of Value function: 0.000495745
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2662
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.0631087
New value of Value function: 0.0631087
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2663
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00162179
New value of Value function: 0.00162179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2664
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.121876
New value of Value function: 0.121876
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2665
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.91921e-05
New value of Value function: 0.00162179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2666
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.91921e-05
New value of Value function: 0.00162179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2667
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.86083e-05
New value of Value function: 0.00162179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2668
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.91921e-05
New value of Value function: 2.91921e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2669
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00161854
New value of Value function: 0.00161854
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2670
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.71699e-05
New value of Value function: 0.00161854
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2671
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00161531
New value of Value function: 0.00161531
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2672
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00161207
New value of Value function: 0.00161207
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2673
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0037736
New value of Value function: 0.0037736
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2674
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0291843
New value of Value function: 0.121876
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2675
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.121632
New value of Value function: 0.121632
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2676
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.179267
New value of Value function: 0.179267
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2677
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00692493
New value of Value function: 0.00692493
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2678
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.235807
New value of Value function: 0.235807
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2679
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.011031
New value of Value function: 0.011031
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2680
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.291289
New value of Value function: 0.291289
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2681
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000227165
New value of Value function: 0.011031
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2682
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0110089
New value of Value function: 0.0110089
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2683
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0160319
New value of Value function: 0.0160319
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2684
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.073668
New value of Value function: 0.291289
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2685
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.25459e-07
New value of Value function: 2.91921e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2686
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.25459e-07
New value of Value function: 2.91921e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2687
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.25459e-07
New value of Value function: 2.91921e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2688
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.91338e-05
New value of Value function: 2.91338e-05
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2689
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000317126
New value of Value function: 0.000317126
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2690
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0209545
New value of Value function: 0.0209545
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2691
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.34584
New value of Value function: 0.34584
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2692
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.17348e-05
New value of Value function: 0.0209545
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2693
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000687964
New value of Value function: 0.000687964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2694
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000235005
New value of Value function: 0.0209545
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2695
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.28983e-05
New value of Value function: 0.000687964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2696
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.28983e-05
New value of Value function: 0.000687964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2697
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.28983e-05
New value of Value function: 0.000687964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2698
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000686588
New value of Value function: 0.000686588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2699
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.49989e-05
New value of Value function: 0.000686588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2700
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000685214
New value of Value function: 0.000685214
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2701
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00104869
New value of Value function: 0.00104869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2702
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0209126
New value of Value function: 0.0209126
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2703
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000606732
New value of Value function: 0.0209126
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2704
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0208707
New value of Value function: 0.0208707
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2705
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0266785
New value of Value function: 0.0266785
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2706
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.132214
New value of Value function: 0.34584
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2707
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00725284
New value of Value function: 0.00725284
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2708
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.399404
New value of Value function: 0.399404
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2709
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0333342
New value of Value function: 0.0333342
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2710
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00718927
New value of Value function: 0.399404
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2711
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00918436
New value of Value function: 0.399404
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2712
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.118589
New value of Value function: 0.118589
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2713
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.17629
New value of Value function: 0.17629
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2714
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00402009
New value of Value function: 0.00402009
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2715
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0071129
New value of Value function: 0.0071129
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2716
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.232892
New value of Value function: 0.232892
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2717
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0111627
New value of Value function: 0.0111627
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2718
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.288435
New value of Value function: 0.288435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2719
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0161313
New value of Value function: 0.0161313
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2720
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.006246
New value of Value function: 0.288435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2721
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.287858
New value of Value function: 0.287858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2722
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00826668
New value of Value function: 0.287858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2723
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.452016
New value of Value function: 0.452016
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2724
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000600015
New value of Value function: 0.0333342
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2725
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0408038
New value of Value function: 0.0408038
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2726
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.50371
New value of Value function: 0.50371
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2727
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0490545
New value of Value function: 0.0490545
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2728
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.554519
New value of Value function: 0.554519
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2729
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0580547
New value of Value function: 0.0580547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2730
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.604473
New value of Value function: 0.604473
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2731
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0677741
New value of Value function: 0.0677741
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2732
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.653604
New value of Value function: 0.653604
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2733
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0781835
New value of Value function: 0.0781835
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2734
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.701939
New value of Value function: 0.701939
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2735
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0014678
New value of Value function: 0.0781835
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2736
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0780271
New value of Value function: 0.0780271
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2737
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0891015
New value of Value function: 0.0891015
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2738
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.749504
New value of Value function: 0.749504
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2739
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.100811
New value of Value function: 0.100811
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2740
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.796328
New value of Value function: 0.796328
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2741
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.113128
New value of Value function: 0.113128
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2742
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.842438
New value of Value function: 0.842438
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2743
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.12603
New value of Value function: 0.12603
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2744
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.887858
New value of Value function: 0.887858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2745
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.13949
New value of Value function: 0.13949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2746
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0141821
New value of Value function: 0.887858
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2747
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.344612
New value of Value function: 0.344612
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2748
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00394927
New value of Value function: 0.13949
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2749
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.139211
New value of Value function: 0.139211
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2750
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0063761
New value of Value function: 0.139211
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2751
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00875438
New value of Value function: 0.139211
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2752
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.138933
New value of Value function: 0.138933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2753
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00309539
New value of Value function: 0.138933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2754
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.138655
New value of Value function: 0.138655
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2755
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00308381
New value of Value function: 0.138655
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2756
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.151863
New value of Value function: 0.151863
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2757
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.932834
New value of Value function: 0.932834
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2758
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.165617
New value of Value function: 0.165617
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2759
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.977159
New value of Value function: 0.977159
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2760
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.179894
New value of Value function: 0.179894
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2761
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 1.02085
New value of Value function: 1.02085
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2762
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.194671
New value of Value function: 0.194671
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2763
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.046976
New value of Value function: 1.02085
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2764
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.01881
New value of Value function: 1.01881
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2765
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 1.06194
New value of Value function: 1.06194
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2766
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.209893
New value of Value function: 0.209893
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2767
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 1.10448
New value of Value function: 1.10448
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2768
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.225576
New value of Value function: 0.225576
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2769
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 1.14645
New value of Value function: 1.14645
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2770
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.2417
New value of Value function: 0.2417
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2771
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 1.18787
New value of Value function: 1.18787
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2772
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.241217
New value of Value function: 0.241217
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2773
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.257774
New value of Value function: 0.257774
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2774
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 1.1855
New value of Value function: 1.1855
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2775
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 1.22643
New value of Value function: 1.22643
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2776
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00870984
New value of Value function: 0.257774
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2777
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0117477
New value of Value function: 0.0117477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2778
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.257258
New value of Value function: 0.257258
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2779
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000290363
New value of Value function: 0.257258
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2780
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0220117
New value of Value function: 0.0220117
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2781
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.398116
New value of Value function: 0.398116
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2782
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0287375
New value of Value function: 0.0287375
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2783
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.450671
New value of Value function: 0.450671
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2784
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0362748
New value of Value function: 0.0362748
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2785
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.50231
New value of Value function: 0.50231
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2786
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0445909
New value of Value function: 0.0445909
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2787
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.556895
New value of Value function: 0.556895
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2788
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.262137
New value of Value function: 0.262137
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2789
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.610475
New value of Value function: 0.610475
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2790
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0077406
New value of Value function: 0.262137
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2791
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.267883
New value of Value function: 0.267883
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2792
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.663088
New value of Value function: 0.663088
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2793
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0122201
New value of Value function: 0.267883
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2794
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.710628
New value of Value function: 0.710628
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2795
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00082165
New value of Value function: 0.0445909
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2796
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000802636
New value of Value function: 0.0445909
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2797
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0445017
New value of Value function: 0.0445017
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2798
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.056403
New value of Value function: 0.056403
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2799
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.757431
New value of Value function: 0.757431
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2800
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000787591
New value of Value function: 0.056403
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2801
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00107013
New value of Value function: 0.00107013
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2802
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0562902
New value of Value function: 0.0562902
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2803
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00291212
New value of Value function: 0.0562902
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2804
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.176546
New value of Value function: 0.176546
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2805
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00317782
New value of Value function: 0.00317782
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2806
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00328427
New value of Value function: 0.176546
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2807
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.233072
New value of Value function: 0.233072
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2808
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.72008e-05
New value of Value function: 0.00317782
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2809
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00317147
New value of Value function: 0.00317147
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2810
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00730333
New value of Value function: 0.00730333
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2811
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00717316
New value of Value function: 0.233072
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2812
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.232606
New value of Value function: 0.232606
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2813
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00740549
New value of Value function: 0.232606
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2814
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.0673888
New value of Value function: 0.232606
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2815
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00418691
New value of Value function: 0.00730333
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2816
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.288085
New value of Value function: 0.288085
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2817
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00423463
New value of Value function: 0.00730333
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2818
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00728873
New value of Value function: 0.00728873
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2819
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0123285
New value of Value function: 0.0123285
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2820
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.342545
New value of Value function: 0.342545
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2821
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00206195
New value of Value function: 0.0123285
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2822
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0687982
New value of Value function: 0.0687982
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2823
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.803521
New value of Value function: 0.803521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2824
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0818856
New value of Value function: 0.0818856
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2825
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.848924
New value of Value function: 0.848924
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2826
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0955285
New value of Value function: 0.0955285
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2827
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.847227
New value of Value function: 0.847227
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2828
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.892002
New value of Value function: 0.892002
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2829
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0953374
New value of Value function: 0.0953374
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2830
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.109487
New value of Value function: 0.109487
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2831
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.936132
New value of Value function: 0.936132
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2832
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.124147
New value of Value function: 0.124147
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2833
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.979644
New value of Value function: 0.979644
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2834
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.139298
New value of Value function: 0.139298
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2835
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0603759
New value of Value function: 0.979644
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2836
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00621953
New value of Value function: 0.342545
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2837
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.34186
New value of Value function: 0.34186
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2838
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.39753
New value of Value function: 0.39753
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2839
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.143668
New value of Value function: 0.143668
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2840
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0132507
New value of Value function: 0.39753
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2841
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0246633
New value of Value function: 0.39753
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2842
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.977685
New value of Value function: 0.977685
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2843
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0186142
New value of Value function: 0.977685
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2844
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 1.02072
New value of Value function: 1.02072
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2845
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.159167
New value of Value function: 0.159167
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2846
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 1.06317
New value of Value function: 1.06317
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2847
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.175121
New value of Value function: 0.175121
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2848
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 1.10506
New value of Value function: 1.10506
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2849
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.191509
New value of Value function: 0.191509
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2850
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 1.1464
New value of Value function: 1.1464
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2851
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.208315
New value of Value function: 0.208315
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2852
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 1.18722
New value of Value function: 1.18722
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2853
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.225518
New value of Value function: 0.225518
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2854
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0274911
New value of Value function: 1.18722
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2855
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 1.18485
New value of Value function: 1.18485
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2856
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 1.22521
New value of Value function: 1.22521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2857
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0249077
New value of Value function: 0.225518
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2858
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0663239
New value of Value function: 1.22521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2859
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0201412
New value of Value function: 0.39753
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2860
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0268939
New value of Value function: 0.39753
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2861
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.396735
New value of Value function: 0.396735
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2862
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00724769
New value of Value function: 0.396735
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2863
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.395942
New value of Value function: 0.395942
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2864
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.448245
New value of Value function: 0.448245
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2865
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0201503
New value of Value function: 0.0201503
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2866
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.499643
New value of Value function: 0.499643
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2867
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00451264
New value of Value function: 0.0201503
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2868
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00238342
New value of Value function: 0.0201503
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2869
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00639508
New value of Value function: 0.0201503
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2870
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.225067
New value of Value function: 0.225067
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2871
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.24262
New value of Value function: 0.24262
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2872
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 1.26508
New value of Value function: 1.26508
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2873
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.260539
New value of Value function: 0.260539
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2874
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 1.30446
New value of Value function: 1.30446
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2875
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.278808
New value of Value function: 0.278808
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2876
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 1.34339
New value of Value function: 1.34339
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2877
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.297413
New value of Value function: 0.297413
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2878
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 1.38188
New value of Value function: 1.38188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2879
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00545958
New value of Value function: 0.297413
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2880
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.316339
New value of Value function: 0.316339
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2881
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 1.41993
New value of Value function: 1.41993
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2882
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0056941
New value of Value function: 0.316339
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2883
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.335571
New value of Value function: 0.335571
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2884
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 1.45758
New value of Value function: 1.45758
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2885
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.355096
New value of Value function: 0.355096
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2886
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0444782
New value of Value function: 1.45758
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2887
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0698251
New value of Value function: 1.45758
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2888
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 1.49482
New value of Value function: 1.49482
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2889
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.3749
New value of Value function: 0.3749
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2890
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.53167
New value of Value function: 1.53167
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2891
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.394972
New value of Value function: 0.394972
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2892
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 1.56814
New value of Value function: 1.56814
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2893
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.4153
New value of Value function: 0.4153
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2894
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 1.60426
New value of Value function: 1.60426
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2895
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0130556
New value of Value function: 0.4153
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2896
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0101723
New value of Value function: 0.4153
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2897
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.284601
New value of Value function: 0.284601
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2898
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0221821
New value of Value function: 1.22643
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2899
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 1.26702
New value of Value function: 1.26702
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2900
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.301716
New value of Value function: 0.301716
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2901
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 1.30711
New value of Value function: 1.30711
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2902
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.301112
New value of Value function: 0.301112
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2903
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.318618
New value of Value function: 0.318618
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2904
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.153097
New value of Value function: 1.30711
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2905
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0452665
New value of Value function: 1.30711
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2906
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 1.3467
New value of Value function: 1.3467
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2907
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.336486
New value of Value function: 0.336486
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2908
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 1.38583
New value of Value function: 1.38583
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2909
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00324494
New value of Value function: 0.336486
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2910
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000235958
New value of Value function: 0.0117477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2911
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0117242
New value of Value function: 0.0117242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2912
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0175465
New value of Value function: 0.0175465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2913
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.354701
New value of Value function: 0.354701
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2914
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 1.42449
New value of Value function: 1.42449
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2915
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.373248
New value of Value function: 0.373248
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2916
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0716774
New value of Value function: 1.42449
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2917
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.46272
New value of Value function: 1.46272
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2918
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0143043
New value of Value function: 0.373248
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2919
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.392112
New value of Value function: 0.392112
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2920
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 1.4598
New value of Value function: 1.4598
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2921
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0706375
New value of Value function: 1.4598
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2922
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 1.49766
New value of Value function: 1.49766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2923
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.411228
New value of Value function: 0.411228
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2924
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.53511
New value of Value function: 1.53511
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2925
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00349588
New value of Value function: 0.411228
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2926
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000328477
New value of Value function: 0.0175465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2927
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0245977
New value of Value function: 0.0245977
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2928
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.430635
New value of Value function: 0.430635
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2929
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.210478
New value of Value function: 1.53511
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2930
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0517377
New value of Value function: 0.0517377
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2931
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.57216
New value of Value function: 1.57216
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2932
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.429774
New value of Value function: 0.429774
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2933
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.449477
New value of Value function: 0.449477
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2934
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 1.56901
New value of Value function: 1.56901
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2935
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.60572
New value of Value function: 1.60572
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2936
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.448578
New value of Value function: 0.448578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2937
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.46851
New value of Value function: 0.46851
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2938
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 1.60251
New value of Value function: 1.60251
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2939
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.09807
New value of Value function: 1.60251
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2940
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 1.6389
New value of Value function: 1.6389
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2941
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0204089
New value of Value function: 0.46851
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2942
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.48864
New value of Value function: 0.48864
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2943
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 1.67491
New value of Value function: 1.67491
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2944
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0122215
New value of Value function: 0.48864
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2945
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.487663
New value of Value function: 0.487663
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2946
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.508058
New value of Value function: 0.508058
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2947
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.67156
New value of Value function: 1.67156
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2948
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 1.70728
New value of Value function: 1.70728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2949
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.507042
New value of Value function: 0.507042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2950
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.527632
New value of Value function: 0.527632
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2951
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.2672
New value of Value function: 1.70728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2952
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0814339
New value of Value function: 0.0814339
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2953
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.100975
New value of Value function: 1.70728
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2954
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 1.70386
New value of Value function: 1.70386
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2955
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.70045
New value of Value function: 1.70045
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2956
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 1.72791
New value of Value function: 1.72791
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2957
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0893026
New value of Value function: 0.0893026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2958
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.548181
New value of Value function: 0.548181
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2959
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 1.76322
New value of Value function: 1.76322
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2960
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0135845
New value of Value function: 0.548181
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2961
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00986727
New value of Value function: 0.0893026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2962
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.568956
New value of Value function: 0.568956
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2963
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 1.7982
New value of Value function: 1.7982
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2964
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.589944
New value of Value function: 0.589944
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2965
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.323463
New value of Value function: 1.7982
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2966
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.119884
New value of Value function: 0.119884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2967
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 1.83285
New value of Value function: 1.83285
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2968
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.611137
New value of Value function: 0.611137
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2969
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 1.8672
New value of Value function: 1.8672
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2970
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.632523
New value of Value function: 0.632523
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2971
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.129718
New value of Value function: 1.8672
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2972
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 1.89201
New value of Value function: 1.89201
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2973
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00247982
New value of Value function: 0.119884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2974
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0437261
New value of Value function: 0.119884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2975
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 1.91633
New value of Value function: 1.91633
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2976
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00458814
New value of Value function: 0.119884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2977
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.15198
New value of Value function: 0.15198
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2978
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 1.94939
New value of Value function: 1.94939
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2979
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0313862
New value of Value function: 0.632523
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2980
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.654962
New value of Value function: 0.654962
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2981
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 1.98219
New value of Value function: 1.98219
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2982
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0258075
New value of Value function: 0.654962
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2983
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.677542
New value of Value function: 0.677542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2984
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 2.01474
New value of Value function: 2.01474
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2985
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0207314
New value of Value function: 0.677542
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2986
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.676187
New value of Value function: 0.676187
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2987
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.698929
New value of Value function: 0.698929
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2988
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 2.04703
New value of Value function: 2.04703
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2989
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.721796
New value of Value function: 0.721796
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2990
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 2.07908
New value of Value function: 2.07908
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2991
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.744784
New value of Value function: 0.744784
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2992
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 2.1109
New value of Value function: 2.1109
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2993
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0382338
New value of Value function: 0.744784
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2994
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.43587
New value of Value function: 0.43587
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2995
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.64002
New value of Value function: 1.64002
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2996
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.456673
New value of Value function: 0.456673
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2997
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 1.67544
New value of Value function: 1.67544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2998
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00902533
New value of Value function: 0.456673
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 2999
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.45576
New value of Value function: 0.45576
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3000
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.476803
New value of Value function: 0.476803
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3001
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 1.71051
New value of Value function: 1.71051
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3002
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.032992
New value of Value function: 0.476803
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3003
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.498056
New value of Value function: 0.498056
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3004
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.74527
New value of Value function: 1.74527
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3005
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0178098
New value of Value function: 0.498056
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3006
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0412972
New value of Value function: 0.498056
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3007
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0217595
New value of Value function: 0.498056
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3008
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.519509
New value of Value function: 0.519509
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3009
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 1.77971
New value of Value function: 1.77971
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3010
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.541154
New value of Value function: 0.541154
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3011
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 1.81386
New value of Value function: 1.81386
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3012
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.540072
New value of Value function: 0.540072
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3013
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.56192
New value of Value function: 0.56192
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3014
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0359349
New value of Value function: 1.81386
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3015
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.522299
New value of Value function: 0.522299
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3016
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 1.8477
New value of Value function: 1.8477
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3017
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.58394
New value of Value function: 0.58394
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3018
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.844
New value of Value function: 1.844
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3019
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0684082
New value of Value function: 1.844
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3020
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 1.87763
New value of Value function: 1.87763
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3021
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0551217
New value of Value function: 0.58394
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3022
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 1.91059
New value of Value function: 1.91059
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3023
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.606652
New value of Value function: 0.606652
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3024
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 1.9433
New value of Value function: 1.9433
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3025
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0408339
New value of Value function: 0.606652
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3026
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.02011
New value of Value function: 0.02011
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3027
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0291092
New value of Value function: 0.0291092
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3028
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.521255
New value of Value function: 0.521255
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3029
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.571354
New value of Value function: 0.571354
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3030
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.029051
New value of Value function: 0.029051
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3031
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0387543
New value of Value function: 0.0387543
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3032
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.620624
New value of Value function: 0.620624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3033
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0491505
New value of Value function: 0.0491505
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3034
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0772123
New value of Value function: 0.620624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3035
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.619383
New value of Value function: 0.619383
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3036
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0868169
New value of Value function: 0.619383
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3037
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.66788
New value of Value function: 0.66788
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3038
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0490522
New value of Value function: 0.0490522
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3039
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.060093
New value of Value function: 0.060093
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3040
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.666544
New value of Value function: 0.666544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3041
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.714295
New value of Value function: 0.714295
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3042
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0717484
New value of Value function: 0.0717484
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3043
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 0.761301
New value of Value function: 0.761301
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3044
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0171869
New value of Value function: 0.0717484
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3045
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.605438
New value of Value function: 0.605438
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3046
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.628309
New value of Value function: 0.628309
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3047
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.93941
New value of Value function: 1.93941
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3048
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.0794109
New value of Value function: 1.93941
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3049
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.650652
New value of Value function: 0.650652
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3050
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 1.97233
New value of Value function: 1.97233
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3051
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.673141
New value of Value function: 0.673141
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3052
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.115819
New value of Value function: 1.97233
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3053
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.3904
New value of Value function: 2.1109
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3054
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.767885
New value of Value function: 0.767885
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3055
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 2.10668
New value of Value function: 2.10668
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3056
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 2.13837
New value of Value function: 2.13837
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3057
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.766349
New value of Value function: 0.766349
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3058
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0160485
New value of Value function: 0.766349
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3059
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.162735
New value of Value function: 0.162735
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3060
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.789512
New value of Value function: 0.789512
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3061
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 2.13409
New value of Value function: 2.13409
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3062
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 2.16562
New value of Value function: 2.16562
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3063
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.787933
New value of Value function: 0.787933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3064
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0394741
New value of Value function: 0.787933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3065
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.811156
New value of Value function: 0.811156
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3066
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.166105
New value of Value function: 2.16562
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3067
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 2.16129
New value of Value function: 2.16129
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3068
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 2.18099
New value of Value function: 2.18099
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3069
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.174081
New value of Value function: 0.174081
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3070
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.834191
New value of Value function: 0.834191
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3071
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 2.21239
New value of Value function: 2.21239
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3072
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0537001
New value of Value function: 0.834191
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3073
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.832522
New value of Value function: 0.832522
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3074
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.855695
New value of Value function: 0.855695
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3075
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 2.20796
New value of Value function: 2.20796
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3076
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 75
New value of Q matrix: 2.23921
New value of Value function: 2.23921
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3077
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.853983
New value of Value function: 0.853983
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3078
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.877209
New value of Value function: 0.877209
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3079
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.422898
New value of Value function: 2.23921
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3080
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 76
New value of Q matrix: 2.25756
New value of Value function: 2.25756
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3081
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.186389
New value of Value function: 0.186389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3082
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.900301
New value of Value function: 0.900301
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3083
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0494005
New value of Value function: 2.25756
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3084
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.96839
New value of Value function: 1.96839
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3085
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.100428
New value of Value function: 1.96839
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3086
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.112123
New value of Value function: 1.96839
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3087
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.818191
New value of Value function: 0.818191
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3088
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.674406
New value of Value function: 0.674406
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3089
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.873967
New value of Value function: 0.873967
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3090
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.696349
New value of Value function: 0.696349
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3091
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 2.00156
New value of Value function: 2.00156
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3092
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.71845
New value of Value function: 0.71845
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3093
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.149531
New value of Value function: 2.00156
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3094
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.99755
New value of Value function: 1.99755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3095
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 2.03053
New value of Value function: 2.03053
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3096
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.717013
New value of Value function: 0.717013
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3097
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.739222
New value of Value function: 0.739222
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3098
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 2.06323
New value of Value function: 2.06323
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3099
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.761576
New value of Value function: 0.761576
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3100
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 2.09567
New value of Value function: 2.09567
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3101
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.784066
New value of Value function: 0.784066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3102
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 2.09148
New value of Value function: 2.09148
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3103
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.147528
New value of Value function: 2.09148
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3104
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 2.12377
New value of Value function: 2.12377
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3105
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0315668
New value of Value function: 0.784066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3106
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.782498
New value of Value function: 0.782498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3107
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0681042
New value of Value function: 0.782498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3108
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0413087
New value of Value function: 0.782498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3109
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0716049
New value of Value function: 0.0716049
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3110
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0859042
New value of Value function: 0.0859042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3111
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.872219
New value of Value function: 0.872219
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3112
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.916321
New value of Value function: 0.916321
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3113
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00596866
New value of Value function: 0.0859042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3114
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00154628
New value of Value function: 0.0859042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3115
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00739557
New value of Value function: 0.0859042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3116
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00879393
New value of Value function: 0.0859042
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3117
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0857324
New value of Value function: 0.0857324
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3118
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00159924
New value of Value function: 0.0857324
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3119
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.100512
New value of Value function: 0.100512
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3120
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.959803
New value of Value function: 0.959803
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3121
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.115778
New value of Value function: 0.115778
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3122
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0436325
New value of Value function: 0.959803
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3123
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.957884
New value of Value function: 0.957884
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3124
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 1.00081
New value of Value function: 1.00081
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3125
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.115546
New value of Value function: 0.115546
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3126
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.13125
New value of Value function: 0.13125
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3127
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 1.04316
New value of Value function: 1.04316
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3128
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00156726
New value of Value function: 0.13125
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3129
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0023625
New value of Value function: 0.0023625
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3130
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.147402
New value of Value function: 0.147402
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3131
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 1.04107
New value of Value function: 1.04107
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3132
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 1.0829
New value of Value function: 1.0829
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3133
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00416858
New value of Value function: 0.147402
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3134
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.147107
New value of Value function: 0.147107
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3135
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00157844
New value of Value function: 0.147107
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3136
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00496317
New value of Value function: 0.00496317
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3137
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.163657
New value of Value function: 0.163657
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3138
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 1.12419
New value of Value function: 1.12419
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3139
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.180619
New value of Value function: 0.180619
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3140
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 1.16496
New value of Value function: 1.16496
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3141
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.180258
New value of Value function: 0.180258
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3142
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.197622
New value of Value function: 0.197622
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3143
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 1.16263
New value of Value function: 1.16263
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3144
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 1.20293
New value of Value function: 1.20293
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3145
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.215322
New value of Value function: 0.215322
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3146
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0458228
New value of Value function: 1.20293
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3147
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 1.24275
New value of Value function: 1.24275
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3148
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.214892
New value of Value function: 0.214892
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3149
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.232963
New value of Value function: 0.232963
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3150
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 1.28209
New value of Value function: 1.28209
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3151
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.251382
New value of Value function: 0.251382
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3152
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 1.32097
New value of Value function: 1.32097
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3153
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.270132
New value of Value function: 0.270132
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3154
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 1.35941
New value of Value function: 1.35941
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3155
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.289198
New value of Value function: 0.289198
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3156
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 1.39743
New value of Value function: 1.39743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3157
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.308568
New value of Value function: 0.308568
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3158
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.110234
New value of Value function: 1.39743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3159
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0831341
New value of Value function: 1.39743
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3160
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 2.15538
New value of Value function: 2.15538
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3161
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0450205
New value of Value function: 0.782498
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3162
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.780933
New value of Value function: 0.780933
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3163
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.804111
New value of Value function: 0.804111
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3164
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 2.18674
New value of Value function: 2.18674
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3165
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.802503
New value of Value function: 0.802503
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3166
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.825814
New value of Value function: 0.825814
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3167
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 2.18237
New value of Value function: 2.18237
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3168
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 2.21359
New value of Value function: 2.21359
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3169
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.849143
New value of Value function: 0.849143
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3170
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 2.2446
New value of Value function: 2.2446
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3171
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.872563
New value of Value function: 0.872563
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 3172
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 2.27541
New value of Value function: 2.27541
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3173
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.870817
New value of Value function: 0.870817
New value of Policy matrix: 3

