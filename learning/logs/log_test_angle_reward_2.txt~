=======================================
Simulation: 1
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 2
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 4
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 8
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.12132
New value of Value function: 2.12132
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 16
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 24
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 25
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 27
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 28
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 29
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 30
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 31
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 32
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 33
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 34
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 35
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 36
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 37
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 38
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 39
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 40
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.46447
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -2.35101
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 45
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 46
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.82843
New value of Value function: 3.82843
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 47
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 48
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 50
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 52
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.98506
New value of Value function: 4.98506
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 53
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.20986
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 55
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.50484
New value of Value function: 4.50484
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 56
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.540213
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 57
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.75242
New value of Value function: 4.75242
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 58
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 59
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 60
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 61
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 62
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 63
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 64
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.11154
New value of Value function: -0.11154
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 65
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 5.31035
New value of Value function: 5.31035
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 66
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 67
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.93521
New value of Value function: 5.93521
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 4.93046
New value of Value function: 4.93046
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 71
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 5.98102
New value of Value function: 5.98102
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.118849
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 73
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.51434
New value of Value function: 4.51434
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 74
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 78
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.921212
New value of Value function: 0.921212
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 90
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 5.99198
New value of Value function: 5.99198
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 92
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 93
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: -0.818097
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 94
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.13857
New value of Value function: 5.13857
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 95
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.111145
New value of Value function: -0.111145
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 96
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.110775
New value of Value function: -0.110775
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 97
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.110425
New value of Value function: -0.110425
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 98
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.110092
New value of Value function: -0.110092
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 99
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.109774
New value of Value function: -0.109774
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 100
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.109469
New value of Value function: -0.109469
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 101
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.109177
New value of Value function: -0.109177
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 102
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.108895
New value of Value function: -0.108895
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 103
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.839798
New value of Value function: -0.108895
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 104
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.912
New value of Value function: 4.912
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.914698
New value of Value function: 0.914698
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 106
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.909417
New value of Value function: 0.909417
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 107
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.90487
New value of Value function: 0.90487
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 108
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.900823
New value of Value function: 0.900823
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 109
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.897146
New value of Value function: 0.897146
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 110
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0.897146
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 111
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.62803
New value of Value function: 2.62803
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 112
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.893755
New value of Value function: 0.893755
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 113
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.890595
New value of Value function: 0.890595
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 114
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.887626
New value of Value function: 0.887626
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 115
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.884819
New value of Value function: 0.884819
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 116
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.86288
New value of Value function: 0.884819
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 117
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.88652
New value of Value function: 4.88652
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 0.899063
New value of Value function: 0.899063
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 119
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.91482
New value of Value function: 5.91482
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.42074
New value of Value function: 4.88652
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.88857
New value of Value function: 4.88857
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.896467
New value of Value function: 0.896467
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 123
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.893981
New value of Value function: 0.893981
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 124
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.891592
New value of Value function: 0.891592
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 125
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 0.882317
New value of Value function: 0.882317
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 126
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 5.88122
New value of Value function: 5.88122
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 128
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 129
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.025
New value of Value function: -0.025
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 130
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.9825
New value of Value function: 4.9825
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 131
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0248882
New value of Value function: -0.0248882
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 132
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0247866
New value of Value function: -0.0247866
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 133
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.0408649
New value of Value function: -0.0408649
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 134
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.96925
New value of Value function: 4.96925
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 135
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0407205
New value of Value function: -0.0407205
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 136
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0405847
New value of Value function: -0.0405847
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 137
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0632208
New value of Value function: -0.0405847
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 138
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0731661
New value of Value function: -0.0405847
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 139
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.96453
New value of Value function: 4.96453
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 140
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0404564
New value of Value function: -0.0404564
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 141
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0403344
New value of Value function: -0.0403344
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 142
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.104098
New value of Value function: -0.0403344
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 143
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 144
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 145
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 146
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.899893
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.77178
New value of Value function: 3.77178
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 148
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 149
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.734062
New value of Value function: 0.734062
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 2
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 3
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 4
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 5
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 6
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 7
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 11
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 12
----------
State: 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 13
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.265107
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 15
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 17
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 18
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 19
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 20
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.0204124
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 21
----------
State: 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 22
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.46447
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 23
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 24
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 25
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.734062
New value of Value function: 0.734062
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3.38589
New value of Value function: 3.38589
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 27
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.726721
New value of Value function: 0.726721
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 29
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.28055
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 30
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 31
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 32
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 33
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 34
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 35
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 36
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 37
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 38
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0995
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 39
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.98536
New value of Value function: 4.98536
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 40
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 41
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 42
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 43
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.07475
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 44
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.99381
New value of Value function: 4.99381
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 45
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 46
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 47
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 48
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 49
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 50
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 51
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 52
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 53
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 54
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 55
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.79098
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 56
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.40007
New value of Value function: 4.40007
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 57
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.12132
New value of Value function: 4.12132
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 58
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 59
----------
State: 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.975
New value of Value function: 1.975
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 61
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 62
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.352031
New value of Value function: 0.352031
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 3.65606
New value of Value function: 3.65606
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 64
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.361488
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 65
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1.24643
New value of Value function: 1.24643
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 66
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0.352031
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 67
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 68
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 69
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.619496
New value of Value function: 0.619496
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3.65606
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 71
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.619496
New value of Value function: 0.619496
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.08972
New value of Value function: 3.65606
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.6195
New value of Value function: 3.65606
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 3.38822
New value of Value function: 3.6195
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 75
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 76
----------
State: 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.583301
New value of Value function: 0.583301
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.5939
New value of Value function: 3.5939
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.57315
New value of Value function: 3.57315
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.55529
New value of Value function: 3.55529
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.53939
New value of Value function: 3.53939
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.52494
New value of Value function: 3.52494
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.51161
New value of Value function: 3.51161
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.4992
New value of Value function: 3.4992
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.48754
New value of Value function: 3.48754
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.47651
New value of Value function: 3.47651
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.46602
New value of Value function: 3.46602
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.45602
New value of Value function: 3.45602
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.44643
New value of Value function: 3.44643
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 5.11241
New value of Value function: 5.11241
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 90
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 91
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.87255
New value of Value function: 4.87255
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 92
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1.30537
New value of Value function: 1.30537
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 93
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.56066
New value of Value function: 1.56066
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 6.07104
New value of Value function: 6.07104
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 95
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.54505
New value of Value function: 6.54505
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 96
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.39763
New value of Value function: 2.39763
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.20723
New value of Value function: 7.20723
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 98
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.13096
New value of Value function: 7.13096
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 99
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.26639
New value of Value function: 3.26639
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 8.10924
New value of Value function: 8.10924
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 101
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.468955
New value of Value function: 7.13096
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 102
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.25169
New value of Value function: 9.25169
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 103
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.36799
New value of Value function: 4.87255
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 104
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.619496
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 105
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 106
----------
State: 2701
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.41191
New value of Value function: 5.41191
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 107
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 5.1149
New value of Value function: 5.1149
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 108
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 2.76955
New value of Value function: 2.76955
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 109
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.05427
New value of Value function: 4.05427
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 7.39545
New value of Value function: 7.39545
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 111
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.77318
New value of Value function: 3.77318
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 112
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.16337
New value of Value function: 4.16337
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 7.20492
New value of Value function: 7.20492
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 114
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 4.32372
New value of Value function: 4.32372
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 115
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.15184
New value of Value function: 4.15184
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 7.22588
New value of Value function: 7.22588
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 117
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 4.62103
New value of Value function: 4.62103
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 118
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 4.15247
New value of Value function: 4.15247
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 7.31914
New value of Value function: 7.31914
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 120
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 4.79424
New value of Value function: 4.79424
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 121
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.18363
New value of Value function: 4.18363
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.42943
New value of Value function: 7.42943
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 123
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 4.91009
New value of Value function: 4.91009
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 124
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 4.23786
New value of Value function: 4.23786
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 7.53732
New value of Value function: 7.53732
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 126
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 5.00034
New value of Value function: 5.00034
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 127
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 4.30543
New value of Value function: 4.30543
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 7.63749
New value of Value function: 7.63749
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 129
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 5.07935
New value of Value function: 5.07935
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 130
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 4.37924
New value of Value function: 4.37924
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 7.72967
New value of Value function: 7.72967
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 132
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 3.90174
New value of Value function: 3.90174
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 133
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.65237
New value of Value function: 4.65237
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 7.53077
New value of Value function: 7.53077
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 135
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 4.37437
New value of Value function: 4.37437
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 136
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.60584
New value of Value function: 4.65237
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 137
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4.65237
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 138
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 139
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 140
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 141
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1592
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.108623
New value of Value function: -0.108623
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 2
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 3
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 4
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.08719
New value of Value function: 7.08719
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.08719
New value of Value function: 5.13857
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 7
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.66077
New value of Value function: 5.66077
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 8
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.268982
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 9
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.96462
New value of Value function: 5.96462
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 10
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.505708
New value of Value function: 0.268982
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 11
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 13
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 15
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 16
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 18
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -5.525
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 19
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.48882
New value of Value function: 2.48882
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 20
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 1
New value of Q matrix: 8
New value of Value function: 8
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 21
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 22
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 23
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 24
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.63945
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 25
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 26
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 27
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.17157
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 28
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 29
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 30
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 31
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 32
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 33
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 34
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 35
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 36
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 37
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 38
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 39
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 40
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 41
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.88675
New value of Value function: 2.88675
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 42
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 43
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.88675
New value of Value function: 2.88675
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 44
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 45
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 46
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 47
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 48
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.14212
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 49
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.85788
New value of Value function: 2.88675
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 50
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.94338
New value of Value function: 3.94338
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 51
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 52
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.40244
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 53
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.41591
New value of Value function: 4.41591
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 54
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 55
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 56
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 57
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 58
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 59
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 60
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 61
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 62
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 63
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 64
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 65
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 66
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 67
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 68
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 69
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 70
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 71
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 72
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.95546
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 73
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.65437
New value of Value function: 4.65437
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 74
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.97917
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 75
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.94338
New value of Value function: 3.94338
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 76
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 77
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.673819
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 78
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.09528
New value of Value function: 4.65437
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 79
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.785
New value of Value function: 4.785
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 80
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 81
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 82
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 83
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 84
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 85
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.490027
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 86
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.86102
New value of Value function: 4.86102
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 87
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.366559
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 88
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 4.90734
New value of Value function: 4.90734
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 89
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 90
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 91
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 92
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 93
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 94
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.50018
New value of Value function: 2.50018
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 95
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 96
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 97
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 98
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 99
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 100
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 101
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 102
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 103
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 104
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 105
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 106
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 107
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -2.24979
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 108
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.89196
New value of Value function: 2.50018
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 109
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.52285
New value of Value function: 5.52285
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 110
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.437554
New value of Value function: 2.50018
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 111
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 3.3661
New value of Value function: 3.3661
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 112
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 113
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 114
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 115
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 116
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 117
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 118
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 119
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 120
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 121
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 122
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 123
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 124
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.98
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 125
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50018
New value of Value function: 5.50018
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 126
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 127
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 128
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 129
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 130
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1558
	Distance: 2
	Angle: 8
	Height: 5
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 2
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 3
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 4
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 6
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 7
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 8
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 9
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 10
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 11
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 12
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 13
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 14
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 15
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 16
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 17
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 18
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 19
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04475
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 20
----------
State: 2653
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 3.9229
New value of Value function: 3.9229
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 21
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 4.63123
New value of Value function: 4.63123
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 22
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.44209
New value of Value function: 4.44209
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 23
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.61947
New value of Value function: 4.61947
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 24
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.5928
New value of Value function: 4.60584
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 25
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.57328
New value of Value function: 4.5928
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 26
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.56984
New value of Value function: 4.57328
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 27
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.54687
New value of Value function: 4.56984
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 28
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.3867
New value of Value function: 4.56984
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 29
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 30
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 31
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 32
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.397667
New value of Value function: 0.397667
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.46402
New value of Value function: 4.46402
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 34
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.5494
New value of Value function: 4.5494
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 35
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.53083
New value of Value function: 4.54687
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 36
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.52414
New value of Value function: 4.53083
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 37
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.5137
New value of Value function: 4.52414
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 38
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.50391
New value of Value function: 4.5137
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 39
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.49774
New value of Value function: 4.50391
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 40
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.48478
New value of Value function: 4.50391
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 41
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.48552
New value of Value function: 4.48552
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 42
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.46856
New value of Value function: 4.48478
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 43
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.4706
New value of Value function: 4.4706
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 44
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.45348
New value of Value function: 4.4706
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 45
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.45712
New value of Value function: 4.45712
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 46
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.43984
New value of Value function: 4.45712
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 47
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.43121
New value of Value function: 4.45712
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 48
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.42558
New value of Value function: 4.45712
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 49
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.44426
New value of Value function: 4.44426
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 50
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4.44426
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 51
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 52
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 53
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 54
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 55
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1542
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 2
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.19989
New value of Value function: 7.19989
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 3
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.856846
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 4
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.50464
New value of Value function: 3.50464
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 5
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.12789
New value of Value function: 7.19989
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 6
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 6.4696
New value of Value function: 7.19989
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 7
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.86447
New value of Value function: 3.86447
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 8
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.72149
New value of Value function: 7.19989
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 9
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.99618
New value of Value function: 3.99618
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 10
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.32262
New value of Value function: 8.32262
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 11
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.0502525
New value of Value function: 0.0502525
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 12
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.08011
New value of Value function: 9.08011
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 13
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.77178
New value of Value function: 5.77178
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 14
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.10821
New value of Value function: 2.10821
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 16
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 17
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1494
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.08559
New value of Value function: 7.12789
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 2
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.62272
New value of Value function: 4.62272
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 3
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 4
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 5
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 6
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 75.0036
New value of Value function: 75.0036
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 7
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1494
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.07749
New value of Value function: 7.08559
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 2
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.96626
New value of Value function: 7.96626
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 3
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 0.549687
New value of Value function: 4.62272
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 4
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.15013
New value of Value function: 5.15013
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: -0.464466
New value of Value function: 4.62272
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 6
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 7
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 8
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 9
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.88659
New value of Value function: 2.88659
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 10
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.54463
New value of Value function: 7.96626
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 11
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 8.503
New value of Value function: 8.503
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 12
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.41797
New value of Value function: 4.62272
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 13
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.84247
New value of Value function: 8.84247
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 14
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.9964
New value of Value function: 6.9964
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 15
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 5.32977
New value of Value function: 5.32977
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 16
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 17
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.9205
New value of Value function: 1.9205
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 18
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 51.955
New value of Value function: 51.955
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 19
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 30.202
New value of Value function: 75.0036
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 20
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 51.955
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 21
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 22
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 23
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1450
	Distance: 2
	Angle: 6
	Height: 2
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.63617
New value of Value function: 0.63617
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 2
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.85301
New value of Value function: 5.85301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 3
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 4
New value of Q matrix: -0.244697
New value of Value function: 0.63617
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 4
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96128
New value of Value function: 7.08719
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 5
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 7.58732
New value of Value function: 7.58732
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.51145
New value of Value function: 5.85301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 7
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.43362
New value of Value function: 7.58732
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 8
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.97253
New value of Value function: 7.58732
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.09353
New value of Value function: 6.97253
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 10
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 11
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.26223
New value of Value function: 3.26223
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 12
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.44982
New value of Value function: 6.44982
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 13
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.2296
New value of Value function: 1.2296
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 14
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.32377
New value of Value function: 3.32377
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 15
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.31558
New value of Value function: 6.31558
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 16
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.48146
New value of Value function: 2.48146
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 17
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.4452
New value of Value function: 10.4452
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 18
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 5.50018
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 19
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 20
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 21
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 22
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 23
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 24
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 25
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 26
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 27
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 28
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 29
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 30
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 31
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 32
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 33
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 34
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 35
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 36
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 37
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.35639
New value of Value function: 2.35639
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 38
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.17805
New value of Value function: 4.17805
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 39
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 40
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 41
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 42
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.99
New value of Value function: 4.99
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 43
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.05
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 44
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.40417
New value of Value function: 5.40417
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 45
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 46
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 47
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 48
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 49
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 50
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.35044
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 51
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.8481
New value of Value function: 3.8481
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 52
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.99
New value of Value function: 4.99
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 53
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 54
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 55
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 56
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 57
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 58
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 59
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.45547
New value of Value function: 4.45547
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.45547
New value of Value function: 7.53077
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 4.50599
New value of Value function: 7.53077
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 62
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.45547
New value of Value function: 4.45547
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 7.44256
New value of Value function: 7.45547
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 64
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 1.41618
New value of Value function: 4.17805
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 65
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.62559
New value of Value function: 5.62559
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 66
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 67
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 68
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 69
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 70
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.07522
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 71
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.54117
New value of Value function: 4.54117
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 72
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.226975
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 73
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.75443
New value of Value function: 5.75443
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 74
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 75
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 76
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 77
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 78
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 79
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 103
New value of Value function: 103
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 80
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2128
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 25.7538
New value of Value function: 25.7538
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.81581
New value of Value function: 8.81581
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 2
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 9.71377
New value of Value function: 9.71377
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 3
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 4.26555
New value of Value function: 6.9964
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 4
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 10.3275
New value of Value function: 10.3275
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.46329
New value of Value function: 8.46329
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 6
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.14227
New value of Value function: 5.32977
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 7
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 2.88659
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 8
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 9
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.9013
New value of Value function: 6.9013
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 10
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 36.2258
New value of Value function: 36.2258
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 11
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 63.6744
New value of Value function: 63.6744
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 12
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 34.587
New value of Value function: 34.587
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 13
----------
State: 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.60631
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 14
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.413018
New value of Value function: 0.413018
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 15
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2213
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -10
New value of Visit matrix: 15
New value of Q matrix: 0.729423
New value of Value function: 0.729423
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 16
----------
State: 2213
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 14.3998
New value of Value function: 14.3998
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 17
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 61.1577
New value of Value function: 61.1577
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 18
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 102
New value of Value function: 102
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 19
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1494
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.715327
New value of Value function: 0.715327
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 2
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.80721
New value of Value function: 5.80721
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 3
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.730448
New value of Value function: 0.730448
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 4
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 5.78186
New value of Value function: 5.78186
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 5
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 5
New value of Q matrix: -0.17873
New value of Value function: 0.730448
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 6
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.29054
New value of Value function: 8.29054
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 7
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.29187
New value of Value function: 3.29187
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 8
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -4
New value of Value function: 6.31558
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 9
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 10
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 11
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 12
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 13
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 10.2524
New value of Value function: 10.2524
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 14
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 3.65779
New value of Value function: 3.65779
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 15
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 16
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 17
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.43532
New value of Value function: 8.43532
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 18
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 3.03928
New value of Value function: 4.09528
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 19
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.38091
New value of Value function: 4.38091
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.40275
New value of Value function: 7.44256
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 7.54566
New value of Value function: 7.54566
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 22
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.4676
New value of Value function: 10.4676
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 23
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.92332
New value of Value function: 4.92332
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 24
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.07163
New value of Value function: 4.07163
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 25
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.05127
New value of Value function: 4.05127
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 26
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.03316
New value of Value function: 4.03316
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 27
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.01669
New value of Value function: 4.01669
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 28
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.00151
New value of Value function: 4.00151
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 29
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.32771
New value of Value function: 4.00151
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 30
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.0479
New value of Value function: 10.0479
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 31
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.55979
New value of Value function: 4.55979
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 32
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.98736
New value of Value function: 3.98736
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 33
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.905022
New value of Value function: 3.98736
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 34
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.73102
New value of Value function: 8.73102
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 35
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.48398
New value of Value function: 3.98736
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 36
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.34331
New value of Value function: 4.34331
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 37
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.97407
New value of Value function: 3.97407
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 38
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 2.63446
New value of Value function: 3.97407
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 39
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.915
New value of Value function: 4.915
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 40
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.88662
New value of Value function: 4.88662
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 41
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.86219
New value of Value function: 4.86219
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 42
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.09863
New value of Value function: 8.09863
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 43
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.28467
New value of Value function: 7.28467
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 44
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.07024
New value of Value function: 9.07024
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 45
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 46
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -1.68521
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 47
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 5.50018
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 48
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.1485
New value of Value function: 12.1485
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 49
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2128
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 7.99808
New value of Value function: 7.99808
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 11.3035
New value of Value function: 11.3035
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 2
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.52615
New value of Value function: 9.52615
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 3
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: 1.98931
New value of Value function: 5.32977
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 4
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.876032
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 5
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.2118
New value of Value function: 12.2118
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 6
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.66933
New value of Value function: 7.28467
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 7
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 9.59288
New value of Value function: 9.59288
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 8
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 8.85179
New value of Value function: 8.85179
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 9
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.79143
New value of Value function: 9.79143
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 10
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 36.6837
New value of Value function: 36.6837
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 11
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 47.9577
New value of Value function: 47.9577
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 12
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.58492
New value of Value function: 34.587
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 13
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 4.83202
New value of Value function: 4.83202
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 14
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -1.71792
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 15
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 0.522193
New value of Value function: 0.522193
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 16
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 17
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.40007
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 18
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.12132
New value of Value function: 4.12132
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 19
----------
State: 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2072
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 8.66613
New value of Value function: 11.3035
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 2
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 13.3089
New value of Value function: 13.3089
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 3
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 8.61798
New value of Value function: 8.61798
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 4
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 12.1788
New value of Value function: 12.1788
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 20.2999
New value of Value function: 20.2999
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 6
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 36.6837
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 7
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 8
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 7.83228
New value of Value function: 7.83228
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 9
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.84977
New value of Value function: 4.84977
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 10
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 11
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 12
----------
State: 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.4702
New value of Value function: 4.4702
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 6.57652
New value of Value function: 7.40275
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 14
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 15
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 16
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 17
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.97
New value of Value function: 4.97
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 18
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 19
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.32872
New value of Value function: 4.32872
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 6.85672
New value of Value function: 7.40275
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 21
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.97
New value of Value function: 4.97
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 22
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 5.4742
New value of Value function: 5.4742
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 23
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.32872
New value of Value function: 4.32872
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.36001
New value of Value function: 7.36001
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.32321
New value of Value function: 7.32321
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.29046
New value of Value function: 7.29046
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.2607
New value of Value function: 7.2607
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.23325
New value of Value function: 7.23325
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.20768
New value of Value function: 7.20768
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.18365
New value of Value function: 7.18365
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 7.16094
New value of Value function: 7.16094
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 7.13935
New value of Value function: 7.13935
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 7.11874
New value of Value function: 7.11874
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.86205
New value of Value function: 7.11874
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.5465
New value of Value function: 7.11874
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 7.09899
New value of Value function: 7.09899
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 7.08002
New value of Value function: 7.08002
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 7.06174
New value of Value function: 7.06174
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 7.04408
New value of Value function: 7.04408
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 7.027
New value of Value function: 7.027
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 7.01044
New value of Value function: 7.01044
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.99435
New value of Value function: 6.99435
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.97871
New value of Value function: 6.97871
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.96349
New value of Value function: 6.96349
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.94864
New value of Value function: 6.94864
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.93415
New value of Value function: 6.93415
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.92
New value of Value function: 6.92
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 6.90616
New value of Value function: 6.90616
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 6.89261
New value of Value function: 6.89261
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 6.06947
New value of Value function: 6.89261
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 51
----------
State: 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 52
----------
State: 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 53
----------
State: 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.4195
New value of Value function: 10.4195
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 54
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.7371
New value of Value function: 3.7371
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 55
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.82369
New value of Value function: 3.82369
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 6.87935
New value of Value function: 6.87935
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 6.86635
New value of Value function: 6.86635
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.8536
New value of Value function: 6.8536
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 6.43963
New value of Value function: 6.8536
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 60
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.39131
New value of Value function: 5.39131
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 61
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 4.65315
New value of Value function: 4.65315
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 62
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.79637
New value of Value function: 3.79637
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 6.84108
New value of Value function: 6.84108
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 6.8288
New value of Value function: 6.8288
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 6.81182
New value of Value function: 6.8288
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 66
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.99896
New value of Value function: 5.99896
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 67
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 5.10437
New value of Value function: 5.10437
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 68
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.76051
New value of Value function: 3.79637
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 6.81672
New value of Value function: 6.81672
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 6.80486
New value of Value function: 6.81182
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 7.22119
New value of Value function: 7.22119
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 72
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.47049
New value of Value function: 6.47049
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 73
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 5.92873
New value of Value function: 5.92873
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 74
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.28543
New value of Value function: 4.32872
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 75
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.22494
New value of Value function: 4.28543
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 7.63404
New value of Value function: 7.63404
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 77
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.04161
New value of Value function: 7.04161
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 78
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.97119
New value of Value function: 5.92873
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 79
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.75396
New value of Value function: 7.04161
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 80
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 6.39614
New value of Value function: 6.39614
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 81
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.74788
New value of Value function: 7.74788
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 82
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 6.39325
New value of Value function: 6.39325
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 83
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.25513
New value of Value function: 4.25513
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 84
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.23056
New value of Value function: 4.23056
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 85
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.20941
New value of Value function: 4.22494
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 86
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.39132
New value of Value function: 4.39132
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 6.77352
New value of Value function: 6.80486
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 88
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 5.31526
New value of Value function: 5.31526
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 89
----------
State: 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.0628
New value of Value function: 11.0628
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 90
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 6.7113
New value of Value function: 6.7113
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 91
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.09861
New value of Value function: 4.20941
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 6.79319
New value of Value function: 6.79319
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.63588
New value of Value function: 6.79319
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.079
New value of Value function: 6.79319
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.49056
New value of Value function: 6.79319
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 6.78171
New value of Value function: 6.78171
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 6.7704
New value of Value function: 6.77352
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 7.35733
New value of Value function: 7.35733
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 99
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 7.64733
New value of Value function: 7.64733
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 100
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 6.85551
New value of Value function: 6.85551
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 101
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.342403
New value of Value function: 4.20941
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 102
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.16732
New value of Value function: 7.16732
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 103
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.19059
New value of Value function: 4.19059
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 104
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.17348
New value of Value function: 4.17348
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 105
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.1577
New value of Value function: 4.1577
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 106
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.1577
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 107
----------
State: 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.26211
New value of Value function: 7.26211
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 108
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.27162
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 109
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 110
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 111
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 112
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 113
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 114
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 115
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.4238
New value of Value function: 10.4238
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 116
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.29703
New value of Value function: 7.74788
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 117
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.7209
New value of Value function: 11.7209
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 118
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 9.26742
New value of Value function: 9.26742
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 119
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.29605
New value of Value function: 6.29605
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 120
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 121
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 122
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 123
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1398
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 10.099
New value of Value function: 12.1788
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 2
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 8.76433
New value of Value function: 8.76433
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 3
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 15.4083
New value of Value function: 15.4083
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 4
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 17.1232
New value of Value function: 17.1232
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 5
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.8045
New value of Value function: 15.4083
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 6
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 9.86794
New value of Value function: 9.86794
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 7
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 16.9954
New value of Value function: 16.9954
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 8
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 24.4179
New value of Value function: 24.4179
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 9
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 43.7472
New value of Value function: 43.7472
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 10
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 40.9291
New value of Value function: 40.9291
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 11
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 19.7935
New value of Value function: 30.202
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 12
----------
State: 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.919893
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 13
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.62863
New value of Value function: 4.62863
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 14
----------
State: 1497
	Distance: 2
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 1.95
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 15
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 75.0036
New value of Value function: 75.0036
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 16
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1446
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 19.8658
New value of Value function: 19.8658
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 2
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.05789
New value of Value function: 24.4179
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 3
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 31.3148
New value of Value function: 31.3148
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 4
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 44.4708
New value of Value function: 44.4708
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 5
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 35.6099
New value of Value function: 35.6099
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 6
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 33.7279
New value of Value function: 33.7279
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 7
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 36.8635
New value of Value function: 36.8635
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 8
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 35.8038
New value of Value function: 35.8038
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 9
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 36.5681
New value of Value function: 36.5681
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 10
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 35.5031
New value of Value function: 35.5031
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 11
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 36.3256
New value of Value function: 36.3256
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 12
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 35.2613
New value of Value function: 35.2613
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 13
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 36.1171
New value of Value function: 36.1171
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 14
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 35.055
New value of Value function: 35.055
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 15
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 35.9325
New value of Value function: 35.9325
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 16
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 35.055
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 17
----------
State: 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 18
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 19
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 20
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 21
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 22
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.50018
New value of Value function: 4.50018
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 23
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 24
----------
State: 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 25
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 26
----------
State: 1401
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 27
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 28
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 29
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 30
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 31
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 32
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 33
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1398
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 0.199355
New value of Value function: 0.730448
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 2
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.040218
New value of Value function: -0.040218
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 3
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.70064
New value of Value function: 5.70064
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 4
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 5
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 6
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 7
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 8
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.28631
New value of Value function: 7.28631
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 9
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 10
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 11
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 12
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 13
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 14
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 15
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.0856079
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 16
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.58579
New value of Value function: 3.58579
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 17
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 18
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 19
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 20
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 21
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 22
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 23
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 24
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1261
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 25
----------
State: 1261
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1261
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 26
----------
State: 1261
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 27
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 28
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.87868
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 29
----------
State: 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 30
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 31
----------
State: 1309
	Distance: 2
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 32
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1458
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 101
New value of Visit matrix: 1
New value of Q matrix: 101
New value of Value function: 101
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 1
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 10.9561
New value of Value function: 19.8658
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 2
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 14.152
New value of Value function: 14.152
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 3
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.918
New value of Value function: 11.918
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 4
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 23.5677
New value of Value function: 23.5677
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 36.2271
New value of Value function: 36.2271
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 6
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 42.9977
New value of Value function: 42.9977
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 7
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 35.8394
New value of Value function: 35.8394
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 8
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 34.838
New value of Value function: 34.838
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 9
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 35.7072
New value of Value function: 35.7072
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 10
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 34.6655
New value of Value function: 34.6655
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 11
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 35.5699
New value of Value function: 35.6099
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 12
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 34.5283
New value of Value function: 34.5283
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 13
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 34.0152
New value of Value function: 35.5699
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 14
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 35.287
New value of Value function: 35.287
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 15
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 33.633
New value of Value function: 35.5699
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 16
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 36.0738
New value of Value function: 36.0738
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 17
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 35.2142
New value of Value function: 35.5699
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 18
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 35.441
New value of Value function: 35.441
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 19
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 34.3886
New value of Value function: 34.3886
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 20
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 35.3157
New value of Value function: 35.3157
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 21
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 34.2601
New value of Value function: 34.2601
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 22
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 35.1956
New value of Value function: 35.2142
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 23
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 23.9833
New value of Value function: 34.2601
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 24
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 34.1452
New value of Value function: 34.1452
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 25
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 34.9652
New value of Value function: 35.1956
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 26
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 35.0825
New value of Value function: 35.0825
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 27
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 34.0305
New value of Value function: 34.0305
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 28
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1449
	Distance: 2
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 35.0825
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 29
----------
State: 1449
	Distance: 2
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 30
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1446
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 99
New value of Visit matrix: 3
New value of Q matrix: 99.4226
New value of Value function: 99.4226
New value of Policy matrix: 4

