=======================================
Episode: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0392
New value of Value function: 0.0392
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.038416
New value of Value function: 0.038416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.038416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.038416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0376477
New value of Value function: 0.0376477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0376477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0376477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.0768947
New value of Value function: 0.0768947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 18
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 19
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 20
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 21
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 22
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 23
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 24
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 25
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 26
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 27
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 28
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 29
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 30
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 31
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 32
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 33
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 34
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 35
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 36
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.06
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 37
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 38
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 39
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 40
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 41
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 42
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 43
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 44
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 45
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 46
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 47
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 48
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 49
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 50
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 51
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 52
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 53
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 54
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 55
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 56
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 57
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 58
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 59
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 60
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 61
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 63
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 64
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.116424
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 65
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 66
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 67
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 68
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 69
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 70
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 72
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 73
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 74
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 75
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.114096
New value of Value function: 0.114096
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 76
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 77
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 78
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 79
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 80
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 81
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0564715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 82
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0564715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 83
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0553421
New value of Value function: 0.0553421
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 84
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0553421
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 85
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0553421
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 86
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 87
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 88
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 89
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 90
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 91
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.114235
New value of Value function: 0.114235
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 92
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 93
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.171814
New value of Value function: 0.171814
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 94
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 95
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.228377
New value of Value function: 0.228377
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 96
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 97
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 98
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 99
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 100
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 101
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 102
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 103
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 104
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 105
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 106
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 107
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 108
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 109
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 110
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.111951
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 111
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 112
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0588
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 113
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 114
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.116424
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 115
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.116424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 116
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.174096
New value of Value function: 0.174096
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 117
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 118
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0588
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 119
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.116424
New value of Value function: 0.116424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 120
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.114096
New value of Value function: 0.114096
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 121
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 122
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 123
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 124
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 125
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 126
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 127
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 128
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 129
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 130
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 131
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 132
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 133
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 134
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 135
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 136
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 137
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 138
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 139
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0588
New value of Value function: 0.114096
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 140
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.111814
New value of Value function: 0.111814
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 141
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.109577
New value of Value function: 0.109577
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 142
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.057624
New value of Value function: 0.109577
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 143
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 144
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0768947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0768947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.115357
New value of Value function: 0.115357
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 148
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 149
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.15305
New value of Value function: 0.15305
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 151
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.057624
New value of Value function: 0.109577
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 152
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.107386
New value of Value function: 0.107386
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.15305
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.15305
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.149989
New value of Value function: 0.149989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 0.186989
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 157
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 158
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 159
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 160
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 161
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.186989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.183249
New value of Value function: 0.183249
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.183249
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 0.219584
New value of Value function: 0.219584
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 170
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 171
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.255192
New value of Value function: 0.255192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 173
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.107386
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 174
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0564715
New value of Value function: 0.107386
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 175
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.105238
New value of Value function: 0.105238
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 176
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0564715
New value of Value function: 0.105238
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 177
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.103133
New value of Value function: 0.103133
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 178
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.101071
New value of Value function: 0.101071
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 179
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0990492
New value of Value function: 0.0990492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 180
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0990492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 181
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 182
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 183
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 184
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 185
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.0990492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 186
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 187
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 188
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 189
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 190
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 191
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 192
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.170614
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 193
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 194
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 195
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 196
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 197
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 198
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.109712
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 199
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0588
New value of Value function: 0.228377
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 200
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.228377
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 201
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.22381
New value of Value function: 0.22381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 202
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.057624
New value of Value function: 0.22381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 203
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.22381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 204
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.22381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 205
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 206
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 207
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 208
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 209
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 210
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 211
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 212
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 213
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 214
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 215
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 216
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 217
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 218
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 219
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 220
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 221
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 222
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 223
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 224
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 225
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 226
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 227
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 228
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 229
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 230
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 231
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 232
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 233
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 234
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 235
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 236
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 237
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 238
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 239
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 240
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 241
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 242
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 243
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 244
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 245
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 246
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 247
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 248
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 249
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 250
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 251
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 252
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 253
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 254
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 255
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.22381
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 256
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.219334
New value of Value function: 0.219334
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 257
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0564715
New value of Value function: 0.219334
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 258
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.219334
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 259
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.214947
New value of Value function: 0.214947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 260
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.210648
New value of Value function: 0.210648
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 261
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.107517
New value of Value function: 0.170614
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 262
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.210648
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 263
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.210648
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 264
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.210648
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 265
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 266
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.167201
New value of Value function: 0.167201
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 267
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 268
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 269
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 270
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 271
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 272
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 273
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 274
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 275
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 276
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 277
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 278
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 279
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 280
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0970682
New value of Value function: 0.0970682
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 281
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0553421
New value of Value function: 0.0970682
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 282
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0542352
New value of Value function: 0.0970682
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 283
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.057624
New value of Value function: 0.0970682
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 284
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0951269
New value of Value function: 0.0951269
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 285
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 286
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 287
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0553421
New value of Value function: 0.0951269
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 288
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0932243
New value of Value function: 0.0932243
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 289
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 290
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.255192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.290089
New value of Value function: 0.290089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 293
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 294
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 295
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 296
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 297
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 298
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 299
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.284287
New value of Value function: 0.284287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.284287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.284287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.284287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.284287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.278601
New value of Value function: 0.278601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.273029
New value of Value function: 0.273029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 0.307569
New value of Value function: 0.307569
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 308
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0913599
New value of Value function: 0.0913599
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 309
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0895327
New value of Value function: 0.0895327
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 310
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 311
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 312
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.116424
New value of Value function: 0.116424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 0.341417
New value of Value function: 0.341417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 314
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.0895327
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 315
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 316
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0531505
New value of Value function: 0.0895327
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 317
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.087742
New value of Value function: 0.087742
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 318
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.116424
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 319
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.232896
New value of Value function: 0.232896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 320
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 321
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0859872
New value of Value function: 0.0859872
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 322
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 323
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 324
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 325
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0842674
New value of Value function: 0.0842674
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 326
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0564715
New value of Value function: 0.0842674
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 327
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0520875
New value of Value function: 0.0842674
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 328
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0542352
New value of Value function: 0.0842674
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 329
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 330
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0510458
New value of Value function: 0.0842674
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 331
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 332
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0825821
New value of Value function: 0.0825821
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 333
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0500249
New value of Value function: 0.0825821
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 334
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0531505
New value of Value function: 0.0825821
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 335
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0520875
New value of Value function: 0.0825821
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.334589
New value of Value function: 0.334589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.334589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 0.367897
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 339
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0809304
New value of Value function: 0.0809304
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 340
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0553421
New value of Value function: 0.0809304
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 341
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0793118
New value of Value function: 0.0793118
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 342
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0510458
New value of Value function: 0.0793118
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 343
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 344
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0777256
New value of Value function: 0.0777256
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 345
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0761711
New value of Value function: 0.0761711
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 346
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.117624
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 347
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 348
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 349
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.06
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 350
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 351
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 352
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 353
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.367897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.360539
New value of Value function: 0.360539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.353328
New value of Value function: 0.353328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.386262
New value of Value function: 0.386262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 363
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0746477
New value of Value function: 0.0746477
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 364
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0542352
New value of Value function: 0.0746477
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 365
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.0746477
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 366
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.232896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 367
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.288238
New value of Value function: 0.288238
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 368
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 369
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 370
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0731547
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 371
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 372
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.342473
New value of Value function: 0.342473
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 373
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 374
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 375
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 376
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 377
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 378
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 379
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 380
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 381
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.418537
New value of Value function: 0.418537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 383
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 384
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 385
----------
State: 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 386
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 387
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.176424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 388
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 389
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0500249
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 390
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 391
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 392
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 0.450166
New value of Value function: 0.450166
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 394
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 395
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0490244
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 396
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 397
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.342473
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 398
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.395623
New value of Value function: 0.395623
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 399
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 400
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 401
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 402
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 403
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 404
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 405
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 406
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 407
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0480439
New value of Value function: 0.0731547
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 408
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0716916
New value of Value function: 0.0716916
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 409
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0531505
New value of Value function: 0.0716916
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 410
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0702578
New value of Value function: 0.0702578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 411
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.047083
New value of Value function: 0.0702578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 412
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.0702578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 413
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 414
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 415
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 416
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 417
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0520875
New value of Value function: 0.0702578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 418
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0461413
New value of Value function: 0.0702578
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 419
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0688526
New value of Value function: 0.0688526
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 420
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0674756
New value of Value function: 0.0674756
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 421
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0661261
New value of Value function: 0.0661261
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 422
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0510458
New value of Value function: 0.0661261
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 423
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0661261
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 424
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.395623
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 425
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.387711
New value of Value function: 0.387711
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 426
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.1188
New value of Value function: 0.387711
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 427
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0648035
New value of Value function: 0.0648035
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 428
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0500249
New value of Value function: 0.0648035
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 429
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0648035
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 430
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.439957
New value of Value function: 0.439957
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 431
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 432
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 433
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 434
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 435
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 436
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.232896
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 437
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0635075
New value of Value function: 0.0635075
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 438
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.0635075
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 439
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.232896
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 440
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0622373
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 441
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0490244
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 442
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0452185
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 443
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0490244
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 444
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 445
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.228238
New value of Value function: 0.232896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 446
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.228238
New value of Value function: 0.228238
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 0.481162
New value of Value function: 0.481162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 448
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0480439
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 449
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.047083
New value of Value function: 0.0622373
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 450
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0609926
New value of Value function: 0.0609926
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 451
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.0609926
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 452
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0597727
New value of Value function: 0.0597727
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 453
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.223673
New value of Value function: 0.228238
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 454
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.283673
New value of Value function: 0.283673
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 455
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0480439
New value of Value function: 0.0597727
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 456
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0585773
New value of Value function: 0.0585773
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 0.511539
New value of Value function: 0.511539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 458
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0574057
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 459
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.337999
New value of Value function: 0.337999
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 460
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.047083
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.511539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.511539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.501308
New value of Value function: 0.501308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.501308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.501308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.501308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.501308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.491282
New value of Value function: 0.491282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 0.521457
New value of Value function: 0.521457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 470
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0461413
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 471
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0452185
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.521457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.521457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.511027
New value of Value function: 0.511027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 0.540807
New value of Value function: 0.540807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 476
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0461413
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 477
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0452185
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 478
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0443141
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 479
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0434279
New value of Value function: 0.0574057
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 480
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 481
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0562576
New value of Value function: 0.0562576
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 482
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0551325
New value of Value function: 0.0551325
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 483
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0425593
New value of Value function: 0.0551325
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 484
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0540298
New value of Value function: 0.0540298
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 485
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.331239
New value of Value function: 0.331239
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 486
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.324615
New value of Value function: 0.324615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.529991
New value of Value function: 0.529991
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 0.559391
New value of Value function: 0.559391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 489
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0443141
New value of Value function: 0.0540298
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 490
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0529492
New value of Value function: 0.0529492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.559391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.559391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.559391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.548203
New value of Value function: 0.548203
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.548203
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.548203
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 0.577239
New value of Value function: 0.577239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 498
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0443141
New value of Value function: 0.0529492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 499
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0434279
New value of Value function: 0.0529492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 500
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0425593
New value of Value function: 0.0529492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.565694
New value of Value function: 0.565694
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 0.59438
New value of Value function: 0.59438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 503
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0417081
New value of Value function: 0.0529492
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 504
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0518902
New value of Value function: 0.0518902
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.59438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.59438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.582493
New value of Value function: 0.582493
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 0.610843
New value of Value function: 0.610843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 509
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0434279
New value of Value function: 0.0518902
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 510
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0508524
New value of Value function: 0.0508524
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 511
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0498354
New value of Value function: 0.0498354
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 512
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 513
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0488387
New value of Value function: 0.0488387
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 514
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.114096
New value of Value function: 0.324615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 515
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.06
New value of Value function: 0.324615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 516
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0417081
New value of Value function: 0.0488387
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 517
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0478619
New value of Value function: 0.0478619
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 518
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0469047
New value of Value function: 0.0469047
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 519
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.0469047
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 520
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0459666
New value of Value function: 0.0459666
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 521
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0425593
New value of Value function: 0.0459666
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 522
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.040874
New value of Value function: 0.0459666
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 523
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.171814
New value of Value function: 0.324615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 524
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0450472
New value of Value function: 0.0450472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 525
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.279199
New value of Value function: 0.324615
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 526
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.0450472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 527
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 528
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.176424
New value of Value function: 0.439957
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 529
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 530
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0417081
New value of Value function: 0.0450472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 531
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.040874
New value of Value function: 0.0450472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 532
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.333615
New value of Value function: 0.333615
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 533
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0400565
New value of Value function: 0.0450472
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 534
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0441463
New value of Value function: 0.0441463
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 535
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0432634
New value of Value function: 0.0432634
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 536
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0423981
New value of Value function: 0.0423981
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 537
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.0423981
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 538
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.439957
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 539
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.431158
New value of Value function: 0.431158
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 540
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.06
New value of Value function: 0.431158
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 541
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 542
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0415501
New value of Value function: 0.0417081
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 543
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.040874
New value of Value function: 0.0415501
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 544
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 545
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.610843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.610843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.610843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.598626
New value of Value function: 0.598626
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 0.626654
New value of Value function: 0.626654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 551
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0400565
New value of Value function: 0.0415501
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 552
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0407191
New value of Value function: 0.040874
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.626654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.626654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.626654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 0.654121
New value of Value function: 0.654121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 557
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0400565
New value of Value function: 0.0407191
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 558
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0392553
New value of Value function: 0.0407191
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 559
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0399047
New value of Value function: 0.0400565
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 0.681038
New value of Value function: 0.681038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 561
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 0.386943
New value of Value function: 0.386943
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 562
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0392553
New value of Value function: 0.0400565
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 563
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0391066
New value of Value function: 0.0400565
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 564
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.0400565
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 565
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0384702
New value of Value function: 0.0400565
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 566
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 0.439204
New value of Value function: 0.439204
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 567
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0.0400565
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 568
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 569
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 570
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0392553
New value of Value function: 0.0392553
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 571
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0384702
New value of Value function: 0.0392553
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 572
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0384702
New value of Value function: 0.0391066
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 573
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0383245
New value of Value function: 0.0384702
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 574
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.037558
New value of Value function: 0.0384702
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 575
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.0368069
New value of Value function: 0.0384702
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 576
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0377008
New value of Value function: 0.0384702
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 577
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0377008
New value of Value function: 0.0384702
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.681038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.667417
New value of Value function: 0.667417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 47
New value of Q matrix: 0.694069
New value of Value function: 0.694069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 581
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0377008
New value of Value function: 0.0377008
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 582
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0369468
New value of Value function: 0.0377008
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 583
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0369468
New value of Value function: 0.0377008
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.694069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 0.720188
New value of Value function: 0.720188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 586
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.0360707
New value of Value function: 0.0377008
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 587
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0362079
New value of Value function: 0.0377008
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 588
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0.0377008
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 589
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0369468
New value of Value function: 0.0369468
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 590
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0362079
New value of Value function: 0.0369468
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 591
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0362079
New value of Value function: 0.0362079
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 592
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.0353493
New value of Value function: 0.0362079
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 593
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0354837
New value of Value function: 0.0362079
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 594
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0354837
New value of Value function: 0.0362079
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 595
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0.0362079
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 596
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0354837
New value of Value function: 0.0354837
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 597
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0347741
New value of Value function: 0.0354837
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 598
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0347741
New value of Value function: 0.0354837
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 599
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0347741
New value of Value function: 0.0353493
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 49
New value of Q matrix: 0.745784
New value of Value function: 0.745784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 601
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0340786
New value of Value function: 0.0353493
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 602
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.0346423
New value of Value function: 0.0347741
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.745784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.745784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 0.770868
New value of Value function: 0.770868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 606
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0340786
New value of Value function: 0.0347741
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 607
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0340786
New value of Value function: 0.0346423
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 608
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 609
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.0339495
New value of Value function: 0.0340786
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 610
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.49042
New value of Value function: 0.49042
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 611
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.033397
New value of Value function: 0.0340786
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 612
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.033397
New value of Value function: 0.0340786
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 51
New value of Q matrix: 0.795451
New value of Value function: 0.795451
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 614
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 615
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 616
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 617
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 618
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 619
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0327291
New value of Value function: 0.0340786
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 620
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 621
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 622
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 623
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 624
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 625
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.779542
New value of Value function: 0.779542
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 53
New value of Q matrix: 0.803951
New value of Value function: 0.803951
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 627
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 628
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 629
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 630
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 631
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 632
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 633
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 634
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.787872
New value of Value function: 0.787872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.787872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.787872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.787872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.787872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.772115
New value of Value function: 0.772115
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.772115
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.772115
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.756672
New value of Value function: 0.756672
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 57
New value of Q matrix: 0.781539
New value of Value function: 0.781539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 645
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 646
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 647
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.033397
New value of Value function: 0.0339495
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 648
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0327291
New value of Value function: 0.0339495
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 649
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 650
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0320745
New value of Value function: 0.0339495
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 651
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.031433
New value of Value function: 0.0339495
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 652
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.0332705
New value of Value function: 0.033397
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 653
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.0326051
New value of Value function: 0.033397
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 654
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.031953
New value of Value function: 0.033397
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 655
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0327291
New value of Value function: 0.0327291
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 656
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0320745
New value of Value function: 0.0327291
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 657
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 0.0908043
New value of Value function: 0.0908043
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 658
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 659
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0889882
New value of Value function: 0.0889882
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 660
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.031433
New value of Value function: 0.0889882
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 661
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 662
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 663
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 0.805908
New value of Value function: 0.805908
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 665
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 666
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0308043
New value of Value function: 0.0889882
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 667
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 0.0913139
New value of Value function: 0.0913139
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 668
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 669
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0872085
New value of Value function: 0.0913139
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 670
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0.0913139
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 671
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 672
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 673
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.78979
New value of Value function: 0.78979
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 60
New value of Q matrix: 0.813994
New value of Value function: 0.813994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 676
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 677
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0.0913139
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 678
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 679
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0.0913139
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 680
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 681
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.0894876
New value of Value function: 0.0894876
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 682
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0854643
New value of Value function: 0.0894876
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 683
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.0876979
New value of Value function: 0.0876979
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 684
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0320745
New value of Value function: 0.0876979
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 685
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.0859439
New value of Value function: 0.0859439
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 686
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.540612
New value of Value function: 0.540612
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 687
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.0842251
New value of Value function: 0.0854643
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 688
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.083755
New value of Value function: 0.0842251
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 689
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.0825406
New value of Value function: 0.083755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 690
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0301882
New value of Value function: 0.083755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 691
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0.083755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 692
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.031433
New value of Value function: 0.083755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 693
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.0808897
New value of Value function: 0.083755
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 694
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0820799
New value of Value function: 0.0820799
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 695
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0308043
New value of Value function: 0.0820799
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 696
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0804383
New value of Value function: 0.0808897
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 697
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.0792719
New value of Value function: 0.0804383
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 698
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0788296
New value of Value function: 0.0792719
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 699
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.0776865
New value of Value function: 0.0788296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 700
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.0761328
New value of Value function: 0.0788296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 701
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 702
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0295845
New value of Value function: 0.0788296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 703
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0301882
New value of Value function: 0.0788296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.813994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.813994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.813994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.813994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.797714
New value of Value function: 0.797714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.797714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.78176
New value of Value function: 0.78176
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 0.04
New value of Value function: 0.78176
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 712
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 713
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 714
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0564715
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 715
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0289928
New value of Value function: 0.0788296
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 716
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.0564715
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 717
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.077253
New value of Value function: 0.077253
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 718
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0553421
New value of Value function: 0.0553421
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 719
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0542352
New value of Value function: 0.0542352
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 63
New value of Q matrix: 0.806125
New value of Value function: 0.806125
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 721
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.0746101
New value of Value function: 0.077253
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 722
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0757079
New value of Value function: 0.0757079
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 723
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0.0757079
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 724
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0553421
New value of Value function: 0.0553421
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 725
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0741937
New value of Value function: 0.0746101
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 726
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.0731179
New value of Value function: 0.0741937
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 727
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0727099
New value of Value function: 0.0731179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 728
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0712557
New value of Value function: 0.0731179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 729
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0.0731179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 730
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0.0731179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 731
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0553421
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 732
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0542352
New value of Value function: 0.0542352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 733
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.0716556
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 734
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0295845
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 735
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0284129
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 736
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0289928
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 737
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0284129
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 738
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0278447
New value of Value function: 0.0716556
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 739
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.0702224
New value of Value function: 0.0712557
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 740
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0278447
New value of Value function: 0.0712557
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 741
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0.0712557
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 742
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0.0712557
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 743
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0531505
New value of Value function: 0.0531505
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 744
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.068818
New value of Value function: 0.0712557
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 745
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0698306
New value of Value function: 0.0698306
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 746
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0.0698306
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 747
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0520875
New value of Value function: 0.0520875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 748
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0272878
New value of Value function: 0.0698306
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 749
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.0674416
New value of Value function: 0.0698306
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 750
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0.0698306
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 751
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0510458
New value of Value function: 0.0510458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 752
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.068434
New value of Value function: 0.068434
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 753
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0272878
New value of Value function: 0.068434
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 754
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.0542352
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 755
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.0542352
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.806125
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 64
New value of Q matrix: 0.830002
New value of Value function: 0.830002
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 758
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0531505
New value of Value function: 0.0531505
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 759
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0531505
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 760
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.0660928
New value of Value function: 0.068434
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 761
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.026742
New value of Value function: 0.068434
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 762
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0670653
New value of Value function: 0.0670653
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 763
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.064771
New value of Value function: 0.0670653
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 764
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.0634755
New value of Value function: 0.0670653
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 765
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0.0670653
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 766
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0510458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 767
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0.0510458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 768
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0500249
New value of Value function: 0.0500249
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 769
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.026742
New value of Value function: 0.0670653
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 770
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.065724
New value of Value function: 0.065724
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 771
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.0531505
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 772
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.0531505
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 773
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0520875
New value of Value function: 0.0520875
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0392
New value of Value function: 0.830002
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 65
New value of Q matrix: 0.853402
New value of Value function: 0.853402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 776
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.0520875
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 777
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0644095
New value of Value function: 0.0644095
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 778
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0262072
New value of Value function: 0.0644095
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 779
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0631213
New value of Value function: 0.0634755
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 780
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.062206
New value of Value function: 0.0631213
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 781
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0.0631213
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 782
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0490244
New value of Value function: 0.0490244
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 783
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.0609619
New value of Value function: 0.0631213
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 784
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0618589
New value of Value function: 0.0618589
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 785
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0262072
New value of Value function: 0.0618589
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 786
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0510458
New value of Value function: 0.0510458
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 787
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0500249
New value of Value function: 0.0500249
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 66
New value of Q matrix: 0.876334
New value of Value function: 0.876334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 789
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0606217
New value of Value function: 0.0609619
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 790
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0594093
New value of Value function: 0.0609619
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 791
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.0597427
New value of Value function: 0.0597427
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 792
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0.0597427
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 793
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.0585478
New value of Value function: 0.0594093
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 794
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0490244
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 795
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0582211
New value of Value function: 0.0585478
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 796
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.0573769
New value of Value function: 0.0582211
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 797
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 0.108044
New value of Value function: 0.108044
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 798
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 799
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.038416
New value of Value function: 0.876334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.876334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0.876334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0376477
New value of Value function: 0.876334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 67
New value of Q matrix: 0.898807
New value of Value function: 0.898807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 805
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 806
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 807
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0.898807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.880831
New value of Value function: 0.880831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.863215
New value of Value function: 0.863215
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 70
New value of Q matrix: 0.88595
New value of Value function: 0.88595
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 812
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 0.117057
New value of Value function: 0.117057
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 813
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 814
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.868231
New value of Value function: 0.868231
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 72
New value of Q matrix: 0.890867
New value of Value function: 0.890867
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 817
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 818
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.873049
New value of Value function: 0.873049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.873049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.873049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 74
New value of Q matrix: 0.895588
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 823
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 824
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0368947
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 828
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 829
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.895588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.877677
New value of Value function: 0.877677
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.860123
New value of Value function: 0.860123
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 77
New value of Q matrix: 0.882921
New value of Value function: 0.882921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 834
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 835
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.882921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.865262
New value of Value function: 0.865262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0.865262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0.865262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 79
New value of Q matrix: 0.887957
New value of Value function: 0.887957
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 841
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.025683
New value of Value function: 0.117057
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 842
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 0.174716
New value of Value function: 0.174716
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 843
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 844
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 845
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 846
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.870198
New value of Value function: 0.870198
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 0.892794
New value of Value function: 0.892794
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 849
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 850
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.874938
New value of Value function: 0.874938
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 83
New value of Q matrix: 0.897439
New value of Value function: 0.897439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 853
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 0.231221
New value of Value function: 0.231221
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 854
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 855
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 0.286597
New value of Value function: 0.286597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 856
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 857
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 858
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 0.06
New value of Value function: 0.286597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 859
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 860
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 861
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 862
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 863
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.87949
New value of Value function: 0.87949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0.87949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.87949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.861901
New value of Value function: 0.861901
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 86
New value of Q matrix: 0.884663
New value of Value function: 0.884663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 869
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 870
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.884663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0.884663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.866969
New value of Value function: 0.866969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0.866969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0361568
New value of Value function: 0.866969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0354337
New value of Value function: 0.866969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.84963
New value of Value function: 0.84963
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 89
New value of Q matrix: 0.872637
New value of Value function: 0.872637
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 879
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 880
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 881
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 882
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.034725
New value of Value function: 0.872637
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.855185
New value of Value function: 0.855185
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 91
New value of Q matrix: 0.878081
New value of Value function: 0.878081
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 886
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 887
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 92
New value of Q matrix: 0.900519
New value of Value function: 0.900519
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 889
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 890
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.882509
New value of Value function: 0.882509
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 94
New value of Q matrix: 0.904859
New value of Value function: 0.904859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 893
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 894
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.025683
New value of Value function: 0.286597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 895
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 92
New value of Q matrix: 0.116229
New value of Value function: 0.286597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 896
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 897
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 898
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 899
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 900
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 901
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 902
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.886762
New value of Value function: 0.886762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 96
New value of Q matrix: 0.909026
New value of Value function: 0.909026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 905
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 906
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 907
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.890846
New value of Value function: 0.890846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0.890846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 98
New value of Q matrix: 0.913029
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 911
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 912
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0340305
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0.913029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.894768
New value of Value function: 0.894768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0.894768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0333499
New value of Value function: 0.894768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0326829
New value of Value function: 0.894768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.876873
New value of Value function: 0.876873
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 101
New value of Q matrix: 0.899336
New value of Value function: 0.899336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 924
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0251694
New value of Value function: 0.286597
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 925
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.280865
New value of Value function: 0.280865
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0.899336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0.899336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0320293
New value of Value function: 0.899336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 102
New value of Q matrix: 0.921349
New value of Value function: 0.921349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 930
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 0.335248
New value of Value function: 0.335248
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 931
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 932
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.902922
New value of Value function: 0.902922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 0.924863
New value of Value function: 0.924863
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 935
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 936
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.906366
New value of Value function: 0.906366
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0.906366
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0313887
New value of Value function: 0.906366
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 106
New value of Q matrix: 0.928239
New value of Value function: 0.928239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 941
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.328543
New value of Value function: 0.328543
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 942
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 0.381972
New value of Value function: 0.381972
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 943
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 944
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 945
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0.928239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0.928239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.909674
New value of Value function: 0.909674
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.891481
New value of Value function: 0.891481
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 109
New value of Q matrix: 0.913651
New value of Value function: 0.913651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 951
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 952
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 953
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0.913651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0307609
New value of Value function: 0.913651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 110
New value of Q matrix: 0.935378
New value of Value function: 0.935378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 957
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 958
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 0.434332
New value of Value function: 0.434332
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 959
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 960
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 961
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 962
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 963
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 964
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 965
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 966
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 967
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 111
New value of Q matrix: 0.95667
New value of Value function: 0.95667
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 969
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 970
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 0.485646
New value of Value function: 0.485646
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 971
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 972
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0.95667
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0.95667
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 112
New value of Q matrix: 0.977537
New value of Value function: 0.977537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 976
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 977
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 978
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 979
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 980
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0.977537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.957986
New value of Value function: 0.957986
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0.957986
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.938826
New value of Value function: 0.938826
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 115
New value of Q matrix: 0.96005
New value of Value function: 0.96005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 986
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 987
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0.96005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0301457
New value of Value function: 0.96005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0.96005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.940849
New value of Value function: 0.940849
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.922032
New value of Value function: 0.922032
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0.922032
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0295428
New value of Value function: 0.922032
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 118
New value of Q matrix: 0.943591
New value of Value function: 0.943591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 996
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 997
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 998
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0289519
New value of Value function: 0.943591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 119
New value of Q matrix: 0.96472
New value of Value function: 0.96472
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1001
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1002
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0283729
New value of Value function: 0.96472
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1004
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 120
New value of Q matrix: 0.985425
New value of Value function: 0.985425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1005
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1006
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.965717
New value of Value function: 0.965717
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 122
New value of Q matrix: 0.986402
New value of Value function: 0.986402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1009
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1010
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1011
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.108044
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1012
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.108044
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1013
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.105883
New value of Value function: 0.105883
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1014
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0588
New value of Value function: 0.485646
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1015
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.105883
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1016
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.103765
New value of Value function: 0.103765
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1017
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.103765
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1018
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 0.084666
New value of Value function: 0.485646
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1019
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1020
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1021
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0278054
New value of Value function: 0.986402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1022
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 123
New value of Q matrix: 1.00667
New value of Value function: 1.00667
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1023
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1024
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1025
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1026
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1027
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1028
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1029
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 124
New value of Q matrix: 1.02654
New value of Value function: 1.02654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1030
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1031
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.103765
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1032
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.103765
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1033
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 0.16169
New value of Value function: 0.16169
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1034
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1035
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1036
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1037
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 0.218456
New value of Value function: 0.218456
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1038
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1039
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1040
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1041
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1042
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1043
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 1.00601
New value of Value function: 1.00601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1044
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 1.00601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 1.00601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1046
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 126
New value of Q matrix: 1.02589
New value of Value function: 1.02589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1047
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1048
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1049
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 1.00537
New value of Value function: 1.00537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1050
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 128
New value of Q matrix: 1.02526
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1051
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1052
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1053
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1054
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1055
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 129
New value of Q matrix: 1.04476
New value of Value function: 1.04476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1056
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1057
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 1.02386
New value of Value function: 1.02386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1059
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 1.02386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 1.00339
New value of Value function: 1.00339
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1061
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 1.00339
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 1.00339
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1063
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 1.02332
New value of Value function: 1.02332
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1064
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1065
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1066
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1067
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1068
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1069
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1070
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1071
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1072
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 1.00285
New value of Value function: 1.00285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1073
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 1.00285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1074
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 1.0228
New value of Value function: 1.0228
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1075
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1076
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1077
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1078
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 1.00234
New value of Value function: 1.00234
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 136
New value of Q matrix: 1.02229
New value of Value function: 1.02229
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1080
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1081
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1082
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1083
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 1.02229
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 1.00185
New value of Value function: 1.00185
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1086
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.98181
New value of Value function: 0.98181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1087
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 139
New value of Q matrix: 1.00217
New value of Value function: 1.00217
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1088
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1089
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1090
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 0.0851694
New value of Value function: 0.485646
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1091
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1092
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 140
New value of Q matrix: 1.02213
New value of Value function: 1.02213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1094
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1095
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 1.00169
New value of Value function: 1.00169
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1097
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0272493
New value of Value function: 1.00169
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1098
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 0.0667043
New value of Value function: 1.00169
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1099
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0490244
New value of Value function: 0.0490244
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1100
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.0490244
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1101
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.0490244
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1102
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0480439
New value of Value function: 0.0480439
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1103
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.0480439
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1104
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.0480439
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1105
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.475933
New value of Value function: 0.475933
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1106
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.047083
New value of Value function: 0.047083
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1107
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0461413
New value of Value function: 0.0461413
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 142
New value of Q matrix: 1.02165
New value of Value function: 1.02165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1109
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1110
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 143
New value of Q matrix: 1.04122
New value of Value function: 1.04122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1112
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.466414
New value of Value function: 0.466414
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1113
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 0.517086
New value of Value function: 0.517086
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1114
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1115
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 1.0204
New value of Value function: 1.0204
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 145
New value of Q matrix: 1.03999
New value of Value function: 1.03999
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1118
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1119
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1120
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1121
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 146
New value of Q matrix: 1.05919
New value of Value function: 1.05919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1123
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 0.566744
New value of Value function: 0.566744
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1124
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1125
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1126
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 71
New value of Q matrix: 0.615409
New value of Value function: 0.615409
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1127
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1128
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1129
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 147
New value of Q matrix: 1.07801
New value of Value function: 1.07801
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1131
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1132
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1133
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 148
New value of Q matrix: 1.09644
New value of Value function: 1.09644
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1135
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1136
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1137
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1138
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1139
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1140
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 0.274087
New value of Value function: 0.274087
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1141
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1142
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1143
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1144
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1145
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1146
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 149
New value of Q matrix: 1.11452
New value of Value function: 1.11452
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1148
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1149
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 1.09223
New value of Value function: 1.09223
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 1.09223
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 151
New value of Q matrix: 1.11038
New value of Value function: 1.11038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1153
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1154
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 1.11038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 1.11038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 1.11038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 1.08817
New value of Value function: 1.08817
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 1.08817
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 1.06641
New value of Value function: 1.06641
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 1.06641
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 1.04508
New value of Value function: 1.04508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 1.04508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0653702
New value of Value function: 1.04508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 1.02418
New value of Value function: 1.02418
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 156
New value of Q matrix: 1.0437
New value of Value function: 1.0437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1167
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1168
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1169
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1170
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1171
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1172
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1173
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1174
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 1.02282
New value of Value function: 1.02282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 1.02282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 158
New value of Q matrix: 1.04237
New value of Value function: 1.04237
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1178
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1179
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 1.02152
New value of Value function: 1.02152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 1.02152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 1.00109
New value of Value function: 1.00109
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 161
New value of Q matrix: 1.02107
New value of Value function: 1.02107
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1184
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1185
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1186
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.274087
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1187
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1188
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1189
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1190
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1191
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1192
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1193
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1194
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1195
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1196
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1197
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1198
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1199
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1200
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 1.00065
New value of Value function: 1.00065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 163
New value of Q matrix: 1.02063
New value of Value function: 1.02063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1203
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1204
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 1.00022
New value of Value function: 1.00022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 165
New value of Q matrix: 1.02022
New value of Value function: 1.02022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1207
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1208
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 1.02022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 1.02022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.999811
New value of Value function: 0.999811
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.979815
New value of Value function: 0.979815
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0.979815
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.960219
New value of Value function: 0.960219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0.960219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 169
New value of Q matrix: 0.981014
New value of Value function: 0.981014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1217
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1218
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1219
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0.961394
New value of Value function: 0.961394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 171
New value of Q matrix: 0.982166
New value of Value function: 0.982166
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1222
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1223
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1224
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1225
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1226
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1227
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1228
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 172
New value of Q matrix: 1.00252
New value of Value function: 1.00252
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1230
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1231
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1232
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1233
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1234
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1235
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1236
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1237
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 1.00252
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 173
New value of Q matrix: 1.02247
New value of Value function: 1.02247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1240
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1241
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1242
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1243
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1244
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1245
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1246
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1247
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1248
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1249
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 1.02247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 1.02247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 1.00202
New value of Value function: 1.00202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 175
New value of Q matrix: 1.02198
New value of Value function: 1.02198
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1254
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1255
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 1.00154
New value of Value function: 1.00154
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 177
New value of Q matrix: 1.02151
New value of Value function: 1.02151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1258
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1259
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 1.02151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0640628
New value of Value function: 1.02151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 1.02151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 1.00108
New value of Value function: 1.00108
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 179
New value of Q matrix: 1.02106
New value of Value function: 1.02106
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1265
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1266
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1267
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1268
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 1.00064
New value of Value function: 1.00064
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 181
New value of Q matrix: 1.02063
New value of Value function: 1.02063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1271
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1272
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1273
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 182
New value of Q matrix: 1.04021
New value of Value function: 1.04021
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1275
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1276
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1277
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 183
New value of Q matrix: 1.05941
New value of Value function: 1.05941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1279
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1280
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 1.03822
New value of Value function: 1.03822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 1.03822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 185
New value of Q matrix: 1.05746
New value of Value function: 1.05746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1284
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1285
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1286
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1287
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1288
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1289
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1290
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1291
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1292
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1293
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0627816
New value of Value function: 1.05746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 1.03631
New value of Value function: 1.03631
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 187
New value of Q matrix: 1.05558
New value of Value function: 1.05558
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1297
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1298
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 1.03447
New value of Value function: 1.03447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 189
New value of Q matrix: 1.05378
New value of Value function: 1.05378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1301
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1302
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1303
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1304
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 1.0327
New value of Value function: 1.0327
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 1.0327
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 1.01205
New value of Value function: 1.01205
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 1.01205
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 192
New value of Q matrix: 1.03181
New value of Value function: 1.03181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1310
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1311
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 0.101526
New value of Value function: 1.03181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1313
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1314
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 1.01117
New value of Value function: 1.01117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 194
New value of Q matrix: 1.03095
New value of Value function: 1.03095
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1317
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1318
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.172896
New value of Value function: 0.172896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1319
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1320
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1321
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1322
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1323
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1324
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1325
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1326
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1327
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1328
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 1.01033
New value of Value function: 1.01033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 196
New value of Q matrix: 1.03012
New value of Value function: 1.03012
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1331
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1332
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 1.00952
New value of Value function: 1.00952
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 1.00952
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 198
New value of Q matrix: 1.02933
New value of Value function: 1.02933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1336
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1337
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1338
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1339
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1340
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1341
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 0.229438
New value of Value function: 0.229438
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1342
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1343
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1344
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1345
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1346
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0994954
New value of Value function: 1.02933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 1.02933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 1.02933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0975055
New value of Value function: 1.02933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 1.00874
New value of Value function: 1.00874
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 1.00874
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 200
New value of Q matrix: 1.02857
New value of Value function: 1.02857
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1354
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1355
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 1.02857
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 1.008
New value of Value function: 1.008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 1.008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.987839
New value of Value function: 0.987839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0.987839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0.968082
New value of Value function: 0.968082
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0.968082
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0.968082
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.94872
New value of Value function: 0.94872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0.94872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0.94872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0.94872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0.929746
New value of Value function: 0.929746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0.929746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0.929746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0955554
New value of Value function: 0.929746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.911151
New value of Value function: 0.911151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.892928
New value of Value function: 0.892928
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 208
New value of Q matrix: 0.915069
New value of Value function: 0.915069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1375
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1376
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0.896768
New value of Value function: 0.896768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0.896768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 210
New value of Q matrix: 0.918833
New value of Value function: 0.918833
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1380
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1381
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0.918833
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.900456
New value of Value function: 0.900456
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0.882447
New value of Value function: 0.882447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 213
New value of Q matrix: 0.904798
New value of Value function: 0.904798
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1386
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1387
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1388
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0.886702
New value of Value function: 0.886702
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 215
New value of Q matrix: 0.908968
New value of Value function: 0.908968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1391
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1392
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0936443
New value of Value function: 0.908968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 216
New value of Q matrix: 0.930788
New value of Value function: 0.930788
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1395
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1396
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0.912173
New value of Value function: 0.912173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 218
New value of Q matrix: 0.933929
New value of Value function: 0.933929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1399
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1400
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0.933929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0.915251
New value of Value function: 0.915251
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 220
New value of Q matrix: 0.936946
New value of Value function: 0.936946
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1404
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1405
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0.936946
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0.918207
New value of Value function: 0.918207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 222
New value of Q matrix: 0.939843
New value of Value function: 0.939843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1409
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1410
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1411
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0.939843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0.939843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0.921046
New value of Value function: 0.921046
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0.902625
New value of Value function: 0.902625
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 225
New value of Q matrix: 0.924572
New value of Value function: 0.924572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1417
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1418
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0.924572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0.924572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0.924572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0.906081
New value of Value function: 0.906081
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0917714
New value of Value function: 0.906081
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.089936
New value of Value function: 0.906081
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0.887959
New value of Value function: 0.887959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0.887959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 228
New value of Q matrix: 0.9102
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1428
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1429
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0881373
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0.9102
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0.891996
New value of Value function: 0.891996
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0.874156
New value of Value function: 0.874156
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0.874156
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0.856673
New value of Value function: 0.856673
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 232
New value of Q matrix: 0.87954
New value of Value function: 0.87954
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1440
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1441
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1442
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1443
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1444
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1445
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0.87954
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0.87954
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.861949
New value of Value function: 0.861949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 234
New value of Q matrix: 0.88471
New value of Value function: 0.88471
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1450
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1451
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.867016
New value of Value function: 0.867016
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 236
New value of Q matrix: 0.889675
New value of Value function: 0.889675
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1454
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1455
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0.889675
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0.889675
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0.889675
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0863745
New value of Value function: 0.889675
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.871882
New value of Value function: 0.871882
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 238
New value of Q matrix: 0.894444
New value of Value function: 0.894444
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1462
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1463
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0.876555
New value of Value function: 0.876555
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 240
New value of Q matrix: 0.899024
New value of Value function: 0.899024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1466
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1467
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.084647
New value of Value function: 0.899024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 241
New value of Q matrix: 0.921044
New value of Value function: 0.921044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1470
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1471
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1472
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1473
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1474
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1475
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1476
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 242
New value of Q matrix: 0.942623
New value of Value function: 0.942623
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1478
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1479
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.92377
New value of Value function: 0.92377
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0829541
New value of Value function: 0.92377
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 244
New value of Q matrix: 0.945295
New value of Value function: 0.945295
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1483
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1484
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 245
New value of Q matrix: 0.966389
New value of Value function: 0.966389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1486
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1487
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1488
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1489
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1490
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.229438
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1491
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.284849
New value of Value function: 0.284849
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1492
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1493
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1494
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1495
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1496
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.339152
New value of Value function: 0.339152
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1497
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1498
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.947061
New value of Value function: 0.947061
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0.947061
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.92812
New value of Value function: 0.92812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 248
New value of Q matrix: 0.949558
New value of Value function: 0.949558
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1503
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1504
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 249
New value of Q matrix: 0.970566
New value of Value function: 0.970566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1506
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1507
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0.970566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 250
New value of Q matrix: 0.991155
New value of Value function: 0.991155
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1510
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1511
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1512
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1513
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1514
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1515
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1516
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1517
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0.971332
New value of Value function: 0.971332
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.081295
New value of Value function: 0.971332
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 252
New value of Q matrix: 0.991905
New value of Value function: 0.991905
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1521
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1522
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0.991905
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0796691
New value of Value function: 0.991905
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0.972067
New value of Value function: 0.972067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 254
New value of Q matrix: 0.992626
New value of Value function: 0.992626
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1527
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1528
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1529
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1530
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1531
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 255
New value of Q matrix: 1.01277
New value of Value function: 1.01277
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1533
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1534
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0.992518
New value of Value function: 0.992518
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 257
New value of Q matrix: 1.01267
New value of Value function: 1.01267
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1537
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1538
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 1.01267
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0.992414
New value of Value function: 0.992414
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 259
New value of Q matrix: 1.01257
New value of Value function: 1.01257
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1542
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1543
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1544
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1545
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0.992315
New value of Value function: 0.992315
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 261
New value of Q matrix: 1.01247
New value of Value function: 1.01247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1548
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1549
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 1.01247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0.992219
New value of Value function: 0.992219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0780757
New value of Value function: 0.992219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 263
New value of Q matrix: 1.01237
New value of Value function: 1.01237
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1554
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1555
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1556
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1557
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1558
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1559
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1560
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1561
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 264
New value of Q matrix: 1.03213
New value of Value function: 1.03213
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1563
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1564
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 265
New value of Q matrix: 1.05148
New value of Value function: 1.05148
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1566
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1567
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 1.03045
New value of Value function: 1.03045
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 1.03045
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 267
New value of Q matrix: 1.04985
New value of Value function: 1.04985
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1571
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1572
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1573
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1574
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 1.02885
New value of Value function: 1.02885
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 269
New value of Q matrix: 1.04827
New value of Value function: 1.04827
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1577
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1578
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1579
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1580
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 1.02731
New value of Value function: 1.02731
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 271
New value of Q matrix: 1.04676
New value of Value function: 1.04676
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1583
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1584
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1585
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 1.02583
New value of Value function: 1.02583
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 1.02583
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 1.02583
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0765142
New value of Value function: 1.02583
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 273
New value of Q matrix: 1.04531
New value of Value function: 1.04531
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1590
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1591
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 1.0244
New value of Value function: 1.0244
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 275
New value of Q matrix: 1.04391
New value of Value function: 1.04391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1594
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1595
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 1.02304
New value of Value function: 1.02304
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 277
New value of Q matrix: 1.04258
New value of Value function: 1.04258
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1598
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1599
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 1.04258
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 1.02172
New value of Value function: 1.02172
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 1.02172
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 279
New value of Q matrix: 1.04129
New value of Value function: 1.04129
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1604
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1605
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1606
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 1.02046
New value of Value function: 1.02046
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 281
New value of Q matrix: 1.04005
New value of Value function: 1.04005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1609
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1610
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1611
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1612
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0749839
New value of Value function: 1.04005
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 1.01925
New value of Value function: 1.01925
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 1.01925
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 283
New value of Q matrix: 1.03887
New value of Value function: 1.03887
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1617
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1618
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1619
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 1.01809
New value of Value function: 1.01809
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 1.01809
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0734842
New value of Value function: 1.01809
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0720146
New value of Value function: 1.01809
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1624
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 285
New value of Q matrix: 1.03773
New value of Value function: 1.03773
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1625
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.392369
New value of Value function: 0.392369
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1626
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1627
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 286
New value of Q matrix: 1.05697
New value of Value function: 1.05697
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1629
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1630
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1631
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 1.03583
New value of Value function: 1.03583
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 288
New value of Q matrix: 1.05512
New value of Value function: 1.05512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1634
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1635
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1636
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 1.03402
New value of Value function: 1.03402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 290
New value of Q matrix: 1.05334
New value of Value function: 1.05334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1639
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1640
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 1.05334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 1.03227
New value of Value function: 1.03227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 1.01162
New value of Value function: 1.01162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 1.01162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0705743
New value of Value function: 1.01162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.0691628
New value of Value function: 1.01162
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 293
New value of Q matrix: 1.03139
New value of Value function: 1.03139
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1648
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.392369
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1649
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0.392369
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1650
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.384521
New value of Value function: 0.384521
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 294
New value of Q matrix: 1.05076
New value of Value function: 1.05076
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1652
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1653
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 295
New value of Q matrix: 1.06975
New value of Value function: 1.06975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1655
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1656
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1657
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1658
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 1.04835
New value of Value function: 1.04835
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 297
New value of Q matrix: 1.06739
New value of Value function: 1.06739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1661
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1662
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 1.04604
New value of Value function: 1.04604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 60
New value of Q matrix: 0.10778
New value of Value function: 1.04604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1665
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1666
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.376831
New value of Value function: 0.376831
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1667
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 1668
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1669
----------
State: 2857
	Distance: 4
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 1.04604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.105624
New value of Value function: 1.04604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 1.02512
New value of Value function: 1.02512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 300
New value of Q matrix: 1.04462
New value of Value function: 1.04462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1674
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1675
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 301
New value of Q matrix: 1.06372
New value of Value function: 1.06372
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1677
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1678
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1679
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 1.04245
New value of Value function: 1.04245
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 303
New value of Q matrix: 1.0616
New value of Value function: 1.0616
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1681
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1682
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1683
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1684
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 1.04037
New value of Value function: 1.04037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 305
New value of Q matrix: 1.05956
New value of Value function: 1.05956
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1687
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1688
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 1.03837
New value of Value function: 1.03837
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 307
New value of Q matrix: 1.0576
New value of Value function: 1.0576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1691
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1692
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 1.03645
New value of Value function: 1.03645
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1694
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 309
New value of Q matrix: 1.05572
New value of Value function: 1.05572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1695
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1696
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 1.03461
New value of Value function: 1.03461
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 311
New value of Q matrix: 1.05391
New value of Value function: 1.05391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1699
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1700
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 1.03284
New value of Value function: 1.03284
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 1.03284
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1703
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 313
New value of Q matrix: 1.05218
New value of Value function: 1.05218
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1704
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1705
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1706
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1707
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.115342
New value of Value function: 0.115342
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1708
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1709
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 1.03114
New value of Value function: 1.03114
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 1.03114
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1712
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 315
New value of Q matrix: 1.05051
New value of Value function: 1.05051
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1713
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1714
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1715
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1716
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 1.05051
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 1.0295
New value of Value function: 1.0295
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 1.00891
New value of Value function: 1.00891
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 1.00891
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0.988734
New value of Value function: 0.988734
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 319
New value of Q matrix: 1.00896
New value of Value function: 1.00896
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1722
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1723
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1724
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1725
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1726
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.103511
New value of Value function: 1.00896
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 1.00896
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0.98878
New value of Value function: 0.98878
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 321
New value of Q matrix: 1.009
New value of Value function: 1.009
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1731
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1732
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 322
New value of Q matrix: 1.02882
New value of Value function: 1.02882
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1734
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1735
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 1.00825
New value of Value function: 1.00825
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 324
New value of Q matrix: 1.02808
New value of Value function: 1.02808
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1738
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1739
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1740
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1741
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 1.02808
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 1.00752
New value of Value function: 1.00752
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 326
New value of Q matrix: 1.02737
New value of Value function: 1.02737
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1745
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1746
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 1.02737
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.101441
New value of Value function: 1.02737
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 327
New value of Q matrix: 1.04682
New value of Value function: 1.04682
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1750
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1751
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1752
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 1.04682
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.0994124
New value of Value function: 1.04682
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 1.02589
New value of Value function: 1.02589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 1.02589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 1.00537
New value of Value function: 1.00537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 330
New value of Q matrix: 1.02526
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1759
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1760
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1761
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.0974242
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 1.02526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 1.00476
New value of Value function: 1.00476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 1.00476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.0954757
New value of Value function: 1.00476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 1.00476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 332
New value of Q matrix: 1.02466
New value of Value function: 1.02466
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1771
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1772
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1773
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1774
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1775
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 333
New value of Q matrix: 1.04417
New value of Value function: 1.04417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1777
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1778
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1779
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1780
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1781
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1782
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1783
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1784
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 1.02328
New value of Value function: 1.02328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 335
New value of Q matrix: 1.04282
New value of Value function: 1.04282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1787
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1788
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 1.02196
New value of Value function: 1.02196
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.0935662
New value of Value function: 1.02196
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 1.02196
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1792
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 337
New value of Q matrix: 1.04152
New value of Value function: 1.04152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1793
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1794
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 1.02069
New value of Value function: 1.02069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.0916948
New value of Value function: 1.02069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 339
New value of Q matrix: 1.04028
New value of Value function: 1.04028
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1798
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 0.429294
New value of Value function: 0.429294
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1799
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1800
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 1.01947
New value of Value function: 1.01947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 341
New value of Q matrix: 1.03908
New value of Value function: 1.03908
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1803
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1804
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.480709
New value of Value function: 0.480709
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1805
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1806
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1807
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 1.0183
New value of Value function: 1.0183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 343
New value of Q matrix: 1.03794
New value of Value function: 1.03794
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1810
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.232896
New value of Value function: 0.232896
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1811
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1812
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 1.01718
New value of Value function: 1.01718
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 1.01718
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 1.01718
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 345
New value of Q matrix: 1.03683
New value of Value function: 1.03683
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1817
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1818
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1819
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1820
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 1.0161
New value of Value function: 1.0161
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 347
New value of Q matrix: 1.03578
New value of Value function: 1.03578
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1823
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1824
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1825
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1826
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1827
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1828
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1829
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1830
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1831
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 1.03578
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 1.03578
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 348
New value of Q matrix: 1.05506
New value of Value function: 1.05506
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1835
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1836
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 1.03396
New value of Value function: 1.03396
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 350
New value of Q matrix: 1.05328
New value of Value function: 1.05328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1839
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1840
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 1.03221
New value of Value function: 1.03221
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 352
New value of Q matrix: 1.05157
New value of Value function: 1.05157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1843
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1844
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1845
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1846
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1847
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.0898609
New value of Value function: 1.05157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 1.03054
New value of Value function: 1.03054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 354
New value of Q matrix: 1.04993
New value of Value function: 1.04993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1851
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1852
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1853
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1854
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 355
New value of Q matrix: 1.06893
New value of Value function: 1.06893
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1856
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1857
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1858
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1859
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1860
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 1.06893
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 1.04755
New value of Value function: 1.04755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 1.04755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 1.0266
New value of Value function: 1.0266
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 358
New value of Q matrix: 1.04607
New value of Value function: 1.04607
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1865
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1866
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1867
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1868
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 1.02515
New value of Value function: 1.02515
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 360
New value of Q matrix: 1.04464
New value of Value function: 1.04464
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1871
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1872
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 1.04464
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 1.02375
New value of Value function: 1.02375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 1.00328
New value of Value function: 1.00328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 1.00328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 363
New value of Q matrix: 1.02321
New value of Value function: 1.02321
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1878
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1879
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1880
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 1.02321
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 1.00275
New value of Value function: 1.00275
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 0.982691
New value of Value function: 0.982691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0.982691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 0.963037
New value of Value function: 0.963037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.0880637
New value of Value function: 0.963037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0.963037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 367
New value of Q matrix: 0.983776
New value of Value function: 0.983776
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1889
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1890
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1891
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 0.964101
New value of Value function: 0.964101
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 369
New value of Q matrix: 0.984819
New value of Value function: 0.984819
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1894
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1895
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0.984819
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 0.965122
New value of Value function: 0.965122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0.965122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0.965122
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1900
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 0.94582
New value of Value function: 0.94582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1901
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 372
New value of Q matrix: 0.966903
New value of Value function: 0.966903
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1902
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1903
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.0863024
New value of Value function: 0.966903
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 0.947565
New value of Value function: 0.947565
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 374
New value of Q matrix: 0.968614
New value of Value function: 0.968614
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1907
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1908
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 0.949242
New value of Value function: 0.949242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1910
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 72
New value of Q matrix: 0.124576
New value of Value function: 0.949242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1911
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1912
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 0.930257
New value of Value function: 0.930257
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 377
New value of Q matrix: 0.951652
New value of Value function: 0.951652
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1915
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1916
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 0.932619
New value of Value function: 0.932619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 379
New value of Q matrix: 0.953966
New value of Value function: 0.953966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1919
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1920
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.122085
New value of Value function: 0.953966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1922
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 380
New value of Q matrix: 0.974887
New value of Value function: 0.974887
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1923
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1924
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 0.955389
New value of Value function: 0.955389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0.955389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 382
New value of Q matrix: 0.976282
New value of Value function: 0.976282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1928
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1929
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1930
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0.976282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 0.956756
New value of Value function: 0.956756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0.956756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 0.937621
New value of Value function: 0.937621
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 385
New value of Q matrix: 0.958868
New value of Value function: 0.958868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1936
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1937
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1938
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1939
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0.958868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 0.939691
New value of Value function: 0.939691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 0.920897
New value of Value function: 0.920897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 388
New value of Q matrix: 0.942479
New value of Value function: 0.942479
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1944
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1945
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 0.92363
New value of Value function: 0.92363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 390
New value of Q matrix: 0.945157
New value of Value function: 0.945157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1948
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1949
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0.945157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 0.926254
New value of Value function: 0.926254
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 0.907729
New value of Value function: 0.907729
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 393
New value of Q matrix: 0.929574
New value of Value function: 0.929574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1954
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1955
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 0.910983
New value of Value function: 0.910983
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 395
New value of Q matrix: 0.932763
New value of Value function: 0.932763
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1958
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1959
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 0.288238
New value of Value function: 0.288238
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1960
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1961
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 0.914108
New value of Value function: 0.914108
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 397
New value of Q matrix: 0.935826
New value of Value function: 0.935826
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1964
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1965
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 0.917109
New value of Value function: 0.917109
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 399
New value of Q matrix: 0.938767
New value of Value function: 0.938767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1968
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1969
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 0.919992
New value of Value function: 0.919992
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 401
New value of Q matrix: 0.941592
New value of Value function: 0.941592
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1972
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1973
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1974
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1975
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.342473
New value of Value function: 0.342473
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 1976
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1977
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1978
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1979
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 0.92276
New value of Value function: 0.92276
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 403
New value of Q matrix: 0.944305
New value of Value function: 0.944305
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1982
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1983
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 0.925419
New value of Value function: 0.925419
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 405
New value of Q matrix: 0.94691
New value of Value function: 0.94691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1986
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1987
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 0.927972
New value of Value function: 0.927972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0.927972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1990
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0.927972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0.927972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 0.909413
New value of Value function: 0.909413
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.119643
New value of Value function: 0.909413
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 408
New value of Q matrix: 0.931224
New value of Value function: 0.931224
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 1995
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1996
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1997
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1998
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 1999
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0.931224
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2001
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 0.9126
New value of Value function: 0.9126
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2002
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 410
New value of Q matrix: 0.934348
New value of Value function: 0.934348
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2003
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2004
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2005
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2006
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2007
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2008
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2009
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2010
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2011
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2012
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 0.915661
New value of Value function: 0.915661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2013
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0.915661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2014
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 0.897348
New value of Value function: 0.897348
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2015
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 413
New value of Q matrix: 0.919401
New value of Value function: 0.919401
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2016
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2017
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2018
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 0.901013
New value of Value function: 0.901013
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2019
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 415
New value of Q matrix: 0.922993
New value of Value function: 0.922993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2020
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2021
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2022
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0.922993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2023
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 416
New value of Q matrix: 0.944533
New value of Value function: 0.944533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2024
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2025
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2026
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.471094
New value of Value function: 0.471094
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2027
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.342473
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2028
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.335623
New value of Value function: 0.335623
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2029
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0.944533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2030
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 417
New value of Q matrix: 0.965642
New value of Value function: 0.965642
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2031
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2032
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2033
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 0.946329
New value of Value function: 0.946329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2034
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 419
New value of Q matrix: 0.967403
New value of Value function: 0.967403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2035
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2036
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2037
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2038
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0.967403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2039
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0.967403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2040
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 0.948055
New value of Value function: 0.948055
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2041
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 0.929093
New value of Value function: 0.929093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2042
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 422
New value of Q matrix: 0.950512
New value of Value function: 0.950512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2043
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2044
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 423
New value of Q matrix: 0.971501
New value of Value function: 0.971501
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2046
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2047
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2048
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 0.952071
New value of Value function: 0.952071
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2049
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0.952071
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2050
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0.952071
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2051
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 0.93303
New value of Value function: 0.93303
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2052
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.11725
New value of Value function: 0.93303
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2053
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 426
New value of Q matrix: 0.954369
New value of Value function: 0.954369
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2054
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2055
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2056
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0.954369
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2057
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 0.935282
New value of Value function: 0.935282
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 428
New value of Q matrix: 0.956576
New value of Value function: 0.956576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2059
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2060
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2061
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 0.937445
New value of Value function: 0.937445
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2063
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0.937445
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2064
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 0.918696
New value of Value function: 0.918696
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2065
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0.918696
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2066
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0.918696
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 0.900322
New value of Value function: 0.900322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2068
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 432
New value of Q matrix: 0.922316
New value of Value function: 0.922316
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2069
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2070
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2071
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 0.903869
New value of Value function: 0.903869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2072
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0.903869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2073
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0.903869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2074
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 0.885792
New value of Value function: 0.885792
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2075
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 0.868076
New value of Value function: 0.868076
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2076
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 436
New value of Q matrix: 0.890714
New value of Value function: 0.890714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2077
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2078
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 0.8729
New value of Value function: 0.8729
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 438
New value of Q matrix: 0.895442
New value of Value function: 0.895442
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2081
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2082
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2083
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 0.877533
New value of Value function: 0.877533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 76
New value of Q matrix: 0.154905
New value of Value function: 0.877533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2085
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2086
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2087
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0.877533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2088
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0.877533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 0.859983
New value of Value function: 0.859983
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0.859983
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 0.842783
New value of Value function: 0.842783
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 77
New value of Q matrix: 0.191807
New value of Value function: 0.842783
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2093
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2094
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2095
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2096
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2097
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2098
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 0.825927
New value of Value function: 0.825927
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2099
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 443
New value of Q matrix: 0.849409
New value of Value function: 0.849409
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2100
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2101
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 0.832421
New value of Value function: 0.832421
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 445
New value of Q matrix: 0.855772
New value of Value function: 0.855772
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2104
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2105
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 0.838657
New value of Value function: 0.838657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0.838657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0.838657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0.838657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 0.821884
New value of Value function: 0.821884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 448
New value of Q matrix: 0.845446
New value of Value function: 0.845446
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2112
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2113
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 0.828537
New value of Value function: 0.828537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 450
New value of Q matrix: 0.851966
New value of Value function: 0.851966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2116
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2117
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2118
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2119
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0.851966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0.851966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 451
New value of Q matrix: 0.874927
New value of Value function: 0.874927
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2123
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2124
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2125
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2126
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2127
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2128
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2129
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2130
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2131
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 0.857428
New value of Value function: 0.857428
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 453
New value of Q matrix: 0.88028
New value of Value function: 0.88028
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2134
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2135
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 0.862674
New value of Value function: 0.862674
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 455
New value of Q matrix: 0.885421
New value of Value function: 0.885421
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2138
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2139
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2140
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2141
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2142
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2143
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2144
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 456
New value of Q matrix: 0.907712
New value of Value function: 0.907712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2146
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2147
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0.907712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 0.889558
New value of Value function: 0.889558
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 0.871767
New value of Value function: 0.871767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 459
New value of Q matrix: 0.894332
New value of Value function: 0.894332
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2152
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2153
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2154
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 460
New value of Q matrix: 0.916445
New value of Value function: 0.916445
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2156
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2157
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 231
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2158
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2159
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 461
New value of Q matrix: 0.938116
New value of Value function: 0.938116
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2161
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2162
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 462
New value of Q matrix: 0.959354
New value of Value function: 0.959354
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2164
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2165
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 0.940167
New value of Value function: 0.940167
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0.940167
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 0.921363
New value of Value function: 0.921363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0.921363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0.921363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0.921363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 0.902936
New value of Value function: 0.902936
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 0.884877
New value of Value function: 0.884877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0.884877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0.884877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0.884877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.187971
New value of Value function: 0.884877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 467
New value of Q matrix: 0.90718
New value of Value function: 0.90718
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2179
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2180
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0.0564715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 468
New value of Q matrix: 0.929036
New value of Value function: 0.929036
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2182
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0.0553421
New value of Value function: 0.0553421
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2183
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0.0542352
New value of Value function: 0.0542352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0.929036
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 0.910455
New value of Value function: 0.910455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 470
New value of Q matrix: 0.932246
New value of Value function: 0.932246
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2187
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0.0531505
New value of Value function: 0.0531505
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2188
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0.0520875
New value of Value function: 0.0520875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0.932246
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 0.913601
New value of Value function: 0.913601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 0.895329
New value of Value function: 0.895329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0.895329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 0.877423
New value of Value function: 0.877423
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0.877423
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 474
New value of Q matrix: 0.899874
New value of Value function: 0.899874
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2196
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2197
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 239
New value of Q matrix: 0.111046
New value of Value function: 0.111046
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2198
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2199
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2200
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0.111046
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2201
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2202
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 240
New value of Q matrix: 0.168825
New value of Value function: 0.168825
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2203
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2204
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2205
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 0.881877
New value of Value function: 0.881877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0.881877
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 476
New value of Q matrix: 0.904239
New value of Value function: 0.904239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2209
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2210
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0.904239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 0.886155
New value of Value function: 0.886155
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 0.868431
New value of Value function: 0.868431
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 479
New value of Q matrix: 0.891063
New value of Value function: 0.891063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2215
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2216
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 480
New value of Q matrix: 0.913242
New value of Value function: 0.913242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2218
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2219
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 0.894977
New value of Value function: 0.894977
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 482
New value of Q matrix: 0.917077
New value of Value function: 0.917077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2222
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2223
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 0.898736
New value of Value function: 0.898736
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 484
New value of Q matrix: 0.920761
New value of Value function: 0.920761
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2226
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2227
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 0.902346
New value of Value function: 0.902346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 486
New value of Q matrix: 0.924299
New value of Value function: 0.924299
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2230
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2231
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0.924299
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 0.905813
New value of Value function: 0.905813
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 0.887697
New value of Value function: 0.887697
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 489
New value of Q matrix: 0.909943
New value of Value function: 0.909943
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2236
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2237
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2238
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2239
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0.168825
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2240
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 241
New value of Q matrix: 0.225448
New value of Value function: 0.225448
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2241
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2242
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0.220939
New value of Value function: 0.220939
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2243
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0.216521
New value of Value function: 0.216521
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0.909943
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 0.891744
New value of Value function: 0.891744
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 0.873909
New value of Value function: 0.873909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 492
New value of Q matrix: 0.896431
New value of Value function: 0.896431
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2248
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0.21219
New value of Value function: 0.21219
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2249
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0.207946
New value of Value function: 0.207946
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 0.878502
New value of Value function: 0.878502
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 494
New value of Q matrix: 0.900932
New value of Value function: 0.900932
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2252
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0.203787
New value of Value function: 0.203787
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2253
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0.199712
New value of Value function: 0.199712
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 0.882913
New value of Value function: 0.882913
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0.882913
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 0.865255
New value of Value function: 0.865255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 497
New value of Q matrix: 0.88795
New value of Value function: 0.88795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2258
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0.195717
New value of Value function: 0.195717
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2259
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0.195717
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2260
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0.191803
New value of Value function: 0.191803
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2261
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0.187967
New value of Value function: 0.187967
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0.88795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 0.870191
New value of Value function: 0.870191
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 0.852787
New value of Value function: 0.852787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0.852787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0.852787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 0.835732
New value of Value function: 0.835732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0.835732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 501
New value of Q matrix: 0.859017
New value of Value function: 0.859017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2270
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2271
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 0.841837
New value of Value function: 0.841837
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 503
New value of Q matrix: 0.865
New value of Value function: 0.865
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2274
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2275
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 0.8477
New value of Value function: 0.8477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 505
New value of Q matrix: 0.870746
New value of Value function: 0.870746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2278
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2279
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2280
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 0.853331
New value of Value function: 0.853331
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 507
New value of Q matrix: 0.876264
New value of Value function: 0.876264
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2283
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2284
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2285
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2286
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 0.858739
New value of Value function: 0.858739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0.858739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0.858739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0.858739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.184212
New value of Value function: 0.858739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 0.841564
New value of Value function: 0.841564
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 510
New value of Q matrix: 0.864733
New value of Value function: 0.864733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2294
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2295
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2296
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2297
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0.864733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 0.847438
New value of Value function: 0.847438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 0.83049
New value of Value function: 0.83049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 80
New value of Q matrix: 0.220527
New value of Value function: 0.83049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2302
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2303
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 0.81388
New value of Value function: 0.81388
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 0.256117
New value of Value function: 0.81388
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2306
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2307
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2308
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 0.797602
New value of Value function: 0.797602
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 515
New value of Q matrix: 0.82165
New value of Value function: 0.82165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2311
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2312
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 0.805217
New value of Value function: 0.805217
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 517
New value of Q matrix: 0.829113
New value of Value function: 0.829113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2315
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2316
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 0.81253
New value of Value function: 0.81253
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 519
New value of Q matrix: 0.83628
New value of Value function: 0.83628
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2319
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2320
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 0.819554
New value of Value function: 0.819554
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 521
New value of Q matrix: 0.843163
New value of Value function: 0.843163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2323
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2324
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 522
New value of Q matrix: 0.8663
New value of Value function: 0.8663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2326
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2327
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 251
New value of Q matrix: 0.244208
New value of Value function: 0.244208
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2328
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2329
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0.8663
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 0.848974
New value of Value function: 0.848974
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0.848974
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 0.831994
New value of Value function: 0.831994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 525
New value of Q matrix: 0.855355
New value of Value function: 0.855355
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2335
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2336
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 0.838247
New value of Value function: 0.838247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0.838247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 0.821483
New value of Value function: 0.821483
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 528
New value of Q matrix: 0.845053
New value of Value function: 0.845053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2341
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2342
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0.845053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0.845053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 0.828152
New value of Value function: 0.828152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0.828152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 0.811589
New value of Value function: 0.811589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.250995
New value of Value function: 0.811589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 531
New value of Q matrix: 0.835357
New value of Value function: 0.835357
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2350
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2351
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 0.81865
New value of Value function: 0.81865
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 533
New value of Q matrix: 0.842277
New value of Value function: 0.842277
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2354
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2355
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0.842277
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 0.825431
New value of Value function: 0.825431
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 0.808923
New value of Value function: 0.808923
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 536
New value of Q matrix: 0.832744
New value of Value function: 0.832744
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2360
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2361
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 0.816089
New value of Value function: 0.816089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0.816089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 0.799768
New value of Value function: 0.799768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 539
New value of Q matrix: 0.823772
New value of Value function: 0.823772
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2366
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2367
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 0.807297
New value of Value function: 0.807297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 541
New value of Q matrix: 0.831151
New value of Value function: 0.831151
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2370
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2371
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 0.814528
New value of Value function: 0.814528
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 543
New value of Q matrix: 0.838237
New value of Value function: 0.838237
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2374
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2375
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 0.821473
New value of Value function: 0.821473
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 83
New value of Q matrix: 0.285975
New value of Value function: 0.821473
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2378
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2379
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 0.805043
New value of Value function: 0.805043
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 546
New value of Q matrix: 0.828942
New value of Value function: 0.828942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2382
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2383
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0.828942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 0.812363
New value of Value function: 0.812363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 548
New value of Q matrix: 0.836116
New value of Value function: 0.836116
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2387
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2388
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2389
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2390
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 0.819394
New value of Value function: 0.819394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 550
New value of Q matrix: 0.843006
New value of Value function: 0.843006
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2393
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2394
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 0.826146
New value of Value function: 0.826146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0.826146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 552
New value of Q matrix: 0.849623
New value of Value function: 0.849623
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2398
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2399
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 0.83263
New value of Value function: 0.83263
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0.83263
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 0.815978
New value of Value function: 0.815978
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0.815978
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0.815978
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 0.799658
New value of Value function: 0.799658
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 0.783665
New value of Value function: 0.783665
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 0.767992
New value of Value function: 0.767992
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2408
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 558
New value of Q matrix: 0.792632
New value of Value function: 0.792632
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2409
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2410
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0.792632
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0.792632
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0.792632
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 0.776779
New value of Value function: 0.776779
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 0.761244
New value of Value function: 0.761244
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 561
New value of Q matrix: 0.786019
New value of Value function: 0.786019
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2417
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2418
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2419
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2420
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2421
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0.786019
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 0.770298
New value of Value function: 0.770298
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0.770298
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 0.754893
New value of Value function: 0.754893
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 564
New value of Q matrix: 0.779795
New value of Value function: 0.779795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2427
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2428
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0.779795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.280255
New value of Value function: 0.779795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0.779795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.27465
New value of Value function: 0.779795
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 0.764199
New value of Value function: 0.764199
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 566
New value of Q matrix: 0.788915
New value of Value function: 0.788915
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2435
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2436
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 0.773136
New value of Value function: 0.773136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0.773136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0.773136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 0.757674
New value of Value function: 0.757674
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0.757674
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 0.74252
New value of Value function: 0.74252
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 570
New value of Q matrix: 0.76767
New value of Value function: 0.76767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2444
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2445
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2446
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2447
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0.76767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0.76767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 0.752316
New value of Value function: 0.752316
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 0.73727
New value of Value function: 0.73727
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 0.722525
New value of Value function: 0.722525
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0.722525
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0.722525
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 0.708074
New value of Value function: 0.708074
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 575
New value of Q matrix: 0.733913
New value of Value function: 0.733913
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2457
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2458
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 0.719235
New value of Value function: 0.719235
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 0.70485
New value of Value function: 0.70485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0.70485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 578
New value of Q matrix: 0.730753
New value of Value function: 0.730753
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2463
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2464
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 0.716138
New value of Value function: 0.716138
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 580
New value of Q matrix: 0.741815
New value of Value function: 0.741815
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2467
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2468
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 0.726979
New value of Value function: 0.726979
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 582
New value of Q matrix: 0.752439
New value of Value function: 0.752439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2471
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2472
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 0.73739
New value of Value function: 0.73739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 584
New value of Q matrix: 0.762643
New value of Value function: 0.762643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2475
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2476
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 0.74739
New value of Value function: 0.74739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0.74739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0.74739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 0.732442
New value of Value function: 0.732442
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 0.717793
New value of Value function: 0.717793
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 0.703437
New value of Value function: 0.703437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 589
New value of Q matrix: 0.729368
New value of Value function: 0.729368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2484
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2485
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2486
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2487
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2488
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2489
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2490
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2491
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2492
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2493
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2494
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2495
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2496
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2497
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2498
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2499
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2500
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2501
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2502
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2503
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2504
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2505
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2506
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2507
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2508
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2509
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2510
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.116424
New value of Value function: 0.116424
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2511
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.114096
New value of Value function: 0.114096
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2512
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2513
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2514
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2515
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2516
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2517
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2518
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0.729368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 0.714781
New value of Value function: 0.714781
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 0.700485
New value of Value function: 0.700485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 592
New value of Q matrix: 0.726476
New value of Value function: 0.726476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2523
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2524
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 0.711946
New value of Value function: 0.711946
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 594
New value of Q matrix: 0.737707
New value of Value function: 0.737707
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2527
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2528
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2529
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2530
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0.737707
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 0.722953
New value of Value function: 0.722953
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 0.708494
New value of Value function: 0.708494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 597
New value of Q matrix: 0.734324
New value of Value function: 0.734324
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2535
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2536
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2537
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2538
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2539
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 0.719638
New value of Value function: 0.719638
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 599
New value of Q matrix: 0.745245
New value of Value function: 0.745245
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2542
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2543
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 0.73034
New value of Value function: 0.73034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 601
New value of Q matrix: 0.755733
New value of Value function: 0.755733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2546
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2547
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 0.740619
New value of Value function: 0.740619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0.740619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 603
New value of Q matrix: 0.765806
New value of Value function: 0.765806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2551
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2552
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 0.75049
New value of Value function: 0.75049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 605
New value of Q matrix: 0.77548
New value of Value function: 0.77548
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2555
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2556
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 0.759971
New value of Value function: 0.759971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 607
New value of Q matrix: 0.784771
New value of Value function: 0.784771
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2559
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2560
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2561
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2562
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 0.769076
New value of Value function: 0.769076
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0.769076
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 609
New value of Q matrix: 0.793694
New value of Value function: 0.793694
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2566
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2567
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 0.77782
New value of Value function: 0.77782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 611
New value of Q matrix: 0.802264
New value of Value function: 0.802264
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2570
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2571
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 0.786219
New value of Value function: 0.786219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 613
New value of Q matrix: 0.810494
New value of Value function: 0.810494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2574
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2575
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.269157
New value of Value function: 0.810494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0.810494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 0.794285
New value of Value function: 0.794285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 615
New value of Q matrix: 0.818399
New value of Value function: 0.818399
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2580
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2581
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2582
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 0.802031
New value of Value function: 0.802031
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2584
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 617
New value of Q matrix: 0.82599
New value of Value function: 0.82599
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2585
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2586
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.263774
New value of Value function: 0.82599
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 618
New value of Q matrix: 0.84947
New value of Value function: 0.84947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2589
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2590
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2591
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.258498
New value of Value function: 0.84947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2592
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0.84947
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 0.832481
New value of Value function: 0.832481
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 620
New value of Q matrix: 0.855831
New value of Value function: 0.855831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2595
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2596
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2597
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0.855831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.253328
New value of Value function: 0.855831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 621
New value of Q matrix: 0.878715
New value of Value function: 0.878715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2600
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2601
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2602
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 0.86114
New value of Value function: 0.86114
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 623
New value of Q matrix: 0.883918
New value of Value function: 0.883918
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2604
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2605
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2606
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 0.866239
New value of Value function: 0.866239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0.866239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 625
New value of Q matrix: 0.888915
New value of Value function: 0.888915
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2609
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2610
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 0.871136
New value of Value function: 0.871136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 627
New value of Q matrix: 0.893714
New value of Value function: 0.893714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2613
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2614
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 0.875839
New value of Value function: 0.875839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 629
New value of Q matrix: 0.898322
New value of Value function: 0.898322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2617
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2618
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2619
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2620
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0.898322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0.898322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 630
New value of Q matrix: 0.920356
New value of Value function: 0.920356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2624
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2625
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2626
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0.920356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2627
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0.920356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 0.901949
New value of Value function: 0.901949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 0.88391
New value of Value function: 0.88391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 0.866232
New value of Value function: 0.866232
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 0.848907
New value of Value function: 0.848907
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 635
New value of Q matrix: 0.871929
New value of Value function: 0.871929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2633
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2634
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0.871929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2636
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0.871929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2637
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 0.85449
New value of Value function: 0.85449
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 0.837401
New value of Value function: 0.837401
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 638
New value of Q matrix: 0.860653
New value of Value function: 0.860653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2640
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2641
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0.860653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 0.843439
New value of Value function: 0.843439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 0.826571
New value of Value function: 0.826571
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 641
New value of Q matrix: 0.850039
New value of Value function: 0.850039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2646
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2647
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0.850039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2649
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 0.833038
New value of Value function: 0.833038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 643
New value of Q matrix: 0.856378
New value of Value function: 0.856378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2651
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2652
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2653
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2654
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 0.83925
New value of Value function: 0.83925
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2656
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 645
New value of Q matrix: 0.862465
New value of Value function: 0.862465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2657
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2658
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2659
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0.862465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2661
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 0.845216
New value of Value function: 0.845216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0.845216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 0.828312
New value of Value function: 0.828312
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 0.811745
New value of Value function: 0.811745
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 649
New value of Q matrix: 0.83551
New value of Value function: 0.83551
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2666
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2667
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2668
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2669
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0.83551
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2671
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 0.8188
New value of Value function: 0.8188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0.8188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 0.802424
New value of Value function: 0.802424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2674
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 652
New value of Q matrix: 0.826376
New value of Value function: 0.826376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2675
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2676
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 0.809848
New value of Value function: 0.809848
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2678
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 654
New value of Q matrix: 0.833651
New value of Value function: 0.833651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2679
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2680
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 0.816978
New value of Value function: 0.816978
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2682
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0.816978
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 656
New value of Q matrix: 0.840639
New value of Value function: 0.840639
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2684
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2685
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0.840639
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.248262
New value of Value function: 0.840639
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 657
New value of Q matrix: 0.863826
New value of Value function: 0.863826
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2689
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2690
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 0.846549
New value of Value function: 0.846549
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 659
New value of Q matrix: 0.869618
New value of Value function: 0.869618
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2693
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2694
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2695
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2696
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2697
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2698
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 0.852226
New value of Value function: 0.852226
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0.852226
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 0.835181
New value of Value function: 0.835181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 662
New value of Q matrix: 0.858478
New value of Value function: 0.858478
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2703
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2704
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2705
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 0.841308
New value of Value function: 0.841308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 664
New value of Q matrix: 0.864482
New value of Value function: 0.864482
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2708
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2709
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 0.847192
New value of Value function: 0.847192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2711
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 666
New value of Q matrix: 0.870249
New value of Value function: 0.870249
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2712
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2713
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2714
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2715
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2716
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2717
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 0.852844
New value of Value function: 0.852844
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 668
New value of Q matrix: 0.875787
New value of Value function: 0.875787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2720
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2721
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 0.858271
New value of Value function: 0.858271
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2723
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 670
New value of Q matrix: 0.881106
New value of Value function: 0.881106
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2724
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2725
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2726
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2727
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 0.863484
New value of Value function: 0.863484
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 672
New value of Q matrix: 0.886214
New value of Value function: 0.886214
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2730
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2731
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 0.86849
New value of Value function: 0.86849
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 674
New value of Q matrix: 0.89112
New value of Value function: 0.89112
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2734
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2735
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 0.873297
New value of Value function: 0.873297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 676
New value of Q matrix: 0.895831
New value of Value function: 0.895831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2738
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2739
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 677
New value of Q matrix: 0.877915
New value of Value function: 0.877915
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 678
New value of Q matrix: 0.900357
New value of Value function: 0.900357
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2742
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2743
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 679
New value of Q matrix: 0.882349
New value of Value function: 0.882349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 91
New value of Q matrix: 0.283297
New value of Value function: 0.882349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2746
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2747
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0.882349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0.882349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 680
New value of Q matrix: 0.864702
New value of Value function: 0.864702
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 681
New value of Q matrix: 0.887408
New value of Value function: 0.887408
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2752
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2753
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 0.86966
New value of Value function: 0.86966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 92
New value of Q matrix: 0.317631
New value of Value function: 0.86966
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2756
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2757
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 0.852267
New value of Value function: 0.852267
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 684
New value of Q matrix: 0.875222
New value of Value function: 0.875222
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2760
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2761
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 0.857717
New value of Value function: 0.857717
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 686
New value of Q matrix: 0.880563
New value of Value function: 0.880563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2764
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2765
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 0.862952
New value of Value function: 0.862952
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 0.845693
New value of Value function: 0.845693
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 689
New value of Q matrix: 0.868779
New value of Value function: 0.868779
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2769
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2770
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.111814
New value of Value function: 0.111814
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2771
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2772
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2773
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 0.851403
New value of Value function: 0.851403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 691
New value of Q matrix: 0.874375
New value of Value function: 0.874375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2776
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2777
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2778
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 0.856888
New value of Value function: 0.856888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0.856888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.311278
New value of Value function: 0.856888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 94
New value of Q matrix: 0.345053
New value of Value function: 0.856888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2783
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2784
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 693
New value of Q matrix: 0.87975
New value of Value function: 0.87975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2786
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2787
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0.87975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 0.862155
New value of Value function: 0.862155
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 695
New value of Q matrix: 0.884912
New value of Value function: 0.884912
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2791
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2792
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 0.867214
New value of Value function: 0.867214
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2794
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 697
New value of Q matrix: 0.889869
New value of Value function: 0.889869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2795
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2796
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2797
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2798
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2799
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2800
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2801
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.169577
New value of Value function: 0.169577
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2802
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2803
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2804
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2805
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2806
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2807
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 0.872072
New value of Value function: 0.872072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 699
New value of Q matrix: 0.89463
New value of Value function: 0.89463
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2809
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2810
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0.89463
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 0.876738
New value of Value function: 0.876738
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 701
New value of Q matrix: 0.899203
New value of Value function: 0.899203
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2814
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2815
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0.899203
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 0.881219
New value of Value function: 0.881219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 703
New value of Q matrix: 0.903595
New value of Value function: 0.903595
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2819
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2820
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2821
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2822
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2823
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2824
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 0.885523
New value of Value function: 0.885523
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 705
New value of Q matrix: 0.907812
New value of Value function: 0.907812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2827
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2828
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2829
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2830
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.338151
New value of Value function: 0.907812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 706
New value of Q matrix: 0.929656
New value of Value function: 0.929656
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2833
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2834
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2835
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.057624
New value of Value function: 0.057624
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 0.911063
New value of Value function: 0.911063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0.911063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 0.892842
New value of Value function: 0.892842
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 709
New value of Q matrix: 0.914985
New value of Value function: 0.914985
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2840
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.0564715
New value of Value function: 0.0564715
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2841
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.0553421
New value of Value function: 0.0553421
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 0.896685
New value of Value function: 0.896685
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 711
New value of Q matrix: 0.918751
New value of Value function: 0.918751
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2844
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.0553421
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2845
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.166186
New value of Value function: 0.166186
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2846
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.0542352
New value of Value function: 0.0542352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2847
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.0542352
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2848
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.0531505
New value of Value function: 0.0531505
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2849
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.0520875
New value of Value function: 0.0520875
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2850
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.0510458
New value of Value function: 0.0510458
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 0.900376
New value of Value function: 0.900376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 713
New value of Q matrix: 0.922369
New value of Value function: 0.922369
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2853
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.0500249
New value of Value function: 0.0500249
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2854
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.0490244
New value of Value function: 0.0490244
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 0.903921
New value of Value function: 0.903921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 715
New value of Q matrix: 0.925843
New value of Value function: 0.925843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2857
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2858
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.0480439
New value of Value function: 0.0480439
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2859
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.047083
New value of Value function: 0.047083
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2860
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.047083
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2861
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 716
New value of Q matrix: 0.947326
New value of Value function: 0.947326
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2862
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.0461413
New value of Value function: 0.0461413
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2863
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.0452185
New value of Value function: 0.0452185
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 0.92838
New value of Value function: 0.92838
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0.92838
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 0.909812
New value of Value function: 0.909812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0.909812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2868
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 0.891616
New value of Value function: 0.891616
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 720
New value of Q matrix: 0.913784
New value of Value function: 0.913784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2870
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2871
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2872
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0.913784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2873
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 0.895508
New value of Value function: 0.895508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0.895508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 0.877598
New value of Value function: 0.877598
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 0.860046
New value of Value function: 0.860046
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0.860046
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2878
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 0.842845
New value of Value function: 0.842845
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2879
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 0.825988
New value of Value function: 0.825988
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 726
New value of Q matrix: 0.849468
New value of Value function: 0.849468
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2881
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.0443141
New value of Value function: 0.0443141
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2882
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.0443141
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0.849468
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 727
New value of Q matrix: 0.872479
New value of Value function: 0.872479
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2885
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2886
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 728
New value of Q matrix: 0.895029
New value of Value function: 0.895029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2888
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2889
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2890
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 729
New value of Q matrix: 0.877129
New value of Value function: 0.877129
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2891
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 730
New value of Q matrix: 0.899586
New value of Value function: 0.899586
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2892
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2893
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 731
New value of Q matrix: 0.881594
New value of Value function: 0.881594
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 732
New value of Q matrix: 0.903962
New value of Value function: 0.903962
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2896
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2897
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 733
New value of Q matrix: 0.885883
New value of Value function: 0.885883
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 734
New value of Q matrix: 0.908166
New value of Value function: 0.908166
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2900
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2901
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 735
New value of Q matrix: 0.930002
New value of Value function: 0.930002
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2903
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.0434279
New value of Value function: 0.0434279
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2904
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.0434279
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2905
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.0425593
New value of Value function: 0.0425593
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2906
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.0417081
New value of Value function: 0.0417081
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2907
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 736
New value of Q matrix: 0.911402
New value of Value function: 0.911402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 737
New value of Q matrix: 0.933174
New value of Value function: 0.933174
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2909
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.040874
New value of Value function: 0.040874
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2910
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.0400565
New value of Value function: 0.0400565
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 0.914511
New value of Value function: 0.914511
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 739
New value of Q matrix: 0.93622
New value of Value function: 0.93622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2913
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.0392553
New value of Value function: 0.0392553
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2914
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.0392553
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2915
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.0384702
New value of Value function: 0.0384702
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2916
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0384702
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2917
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.0377008
New value of Value function: 0.0377008
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2918
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.0369468
New value of Value function: 0.0369468
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0.93622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 0.917496
New value of Value function: 0.917496
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2921
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 96
New value of Q matrix: 0.371388
New value of Value function: 0.917496
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2922
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.0362079
New value of Value function: 0.0362079
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2923
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0.0354837
New value of Value function: 0.0354837
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 0.899146
New value of Value function: 0.899146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2925
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0.899146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0.899146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.363961
New value of Value function: 0.899146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 742
New value of Q matrix: 0.881163
New value of Value function: 0.881163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0.881163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 743
New value of Q matrix: 0.86354
New value of Value function: 0.86354
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 744
New value of Q matrix: 0.886269
New value of Value function: 0.886269
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2932
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0.0347741
New value of Value function: 0.0347741
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2933
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.0347741
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 745
New value of Q matrix: 0.868544
New value of Value function: 0.868544
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 746
New value of Q matrix: 0.891173
New value of Value function: 0.891173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2936
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.0340786
New value of Value function: 0.0340786
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2937
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0.033397
New value of Value function: 0.033397
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 747
New value of Q matrix: 0.873349
New value of Value function: 0.873349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 748
New value of Q matrix: 0.895882
New value of Value function: 0.895882
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2940
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.0327291
New value of Value function: 0.0327291
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2941
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.0320745
New value of Value function: 0.0320745
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 749
New value of Q matrix: 0.877965
New value of Value function: 0.877965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2943
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 750
New value of Q matrix: 0.900405
New value of Value function: 0.900405
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2944
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0.031433
New value of Value function: 0.031433
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2945
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.0308043
New value of Value function: 0.0308043
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 0.882397
New value of Value function: 0.882397
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2947
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 752
New value of Q matrix: 0.904749
New value of Value function: 0.904749
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2948
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.0301882
New value of Value function: 0.0301882
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2949
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.0295845
New value of Value function: 0.0295845
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 753
New value of Q matrix: 0.886654
New value of Value function: 0.886654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2951
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0.886654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 754
New value of Q matrix: 0.868921
New value of Value function: 0.868921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 755
New value of Q matrix: 0.891543
New value of Value function: 0.891543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2954
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2955
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2956
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 0.873712
New value of Value function: 0.873712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 757
New value of Q matrix: 0.896238
New value of Value function: 0.896238
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2958
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2959
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2960
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 758
New value of Q matrix: 0.878313
New value of Value function: 0.878313
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 759
New value of Q matrix: 0.900747
New value of Value function: 0.900747
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2962
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2963
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 0.222862
New value of Value function: 0.222862
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2964
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2965
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2966
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2967
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2968
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2969
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2970
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0.900747
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 760
New value of Q matrix: 0.922732
New value of Value function: 0.922732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2973
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2974
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2975
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0.922732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0.922732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0.922732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0.922732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2980
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 761
New value of Q matrix: 0.904277
New value of Value function: 0.904277
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 762
New value of Q matrix: 0.886192
New value of Value function: 0.886192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 763
New value of Q matrix: 0.868468
New value of Value function: 0.868468
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 764
New value of Q matrix: 0.851098
New value of Value function: 0.851098
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0.851098
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 98
New value of Q matrix: 0.396681
New value of Value function: 0.851098
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2986
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2987
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 765
New value of Q matrix: 0.834077
New value of Value function: 0.834077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2989
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 766
New value of Q matrix: 0.857395
New value of Value function: 0.857395
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2990
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2991
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0.388748
New value of Value function: 0.857395
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0.857395
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2994
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 767
New value of Q matrix: 0.840247
New value of Value function: 0.840247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0.840247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 768
New value of Q matrix: 0.823442
New value of Value function: 0.823442
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0
New value of Value function: 0.823442
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 769
New value of Q matrix: 0.846973
New value of Value function: 0.846973
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 2999
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3000
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3001
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3002
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3003
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3004
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3005
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3006
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0.846973
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0.846973
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0
New value of Value function: 0.846973
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3009
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 770
New value of Q matrix: 0.830034
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3010
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3011
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.380973
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3012
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3013
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3014
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0.830034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3015
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 771
New value of Q matrix: 0.813433
New value of Value function: 0.813433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3016
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 772
New value of Q matrix: 0.797165
New value of Value function: 0.797165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3017
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0.373353
New value of Value function: 0.797165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3018
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 773
New value of Q matrix: 0.781221
New value of Value function: 0.781221
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3019
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 774
New value of Q matrix: 0.765597
New value of Value function: 0.765597
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3020
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 775
New value of Q matrix: 0.790285
New value of Value function: 0.790285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3021
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3022
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3023
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 776
New value of Q matrix: 0.774479
New value of Value function: 0.774479
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3024
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 777
New value of Q matrix: 0.79899
New value of Value function: 0.79899
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3025
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3026
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3027
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 778
New value of Q matrix: 0.82301
New value of Value function: 0.82301
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3028
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3029
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3030
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0
New value of Value function: 0.82301
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3031
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 779
New value of Q matrix: 0.80655
New value of Value function: 0.80655
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3032
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 780
New value of Q matrix: 0.830419
New value of Value function: 0.830419
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3033
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3034
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3035
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 0.81381
New value of Value function: 0.81381
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3036
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 782
New value of Q matrix: 0.837534
New value of Value function: 0.837534
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3037
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3038
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3039
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 783
New value of Q matrix: 0.820783
New value of Value function: 0.820783
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3040
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 784
New value of Q matrix: 0.844368
New value of Value function: 0.844368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3041
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3042
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3043
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 785
New value of Q matrix: 0.82748
New value of Value function: 0.82748
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3044
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 786
New value of Q matrix: 0.850931
New value of Value function: 0.850931
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3045
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3046
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3047
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 787
New value of Q matrix: 0.833912
New value of Value function: 0.833912
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3048
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 788
New value of Q matrix: 0.857234
New value of Value function: 0.857234
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3049
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3050
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3051
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.365886
New value of Value function: 0.857234
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3052
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 789
New value of Q matrix: 0.880089
New value of Value function: 0.880089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3053
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3054
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3055
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3056
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 790
New value of Q matrix: 0.862487
New value of Value function: 0.862487
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3057
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 791
New value of Q matrix: 0.885238
New value of Value function: 0.885238
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3058
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3059
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0.885238
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3061
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 792
New value of Q matrix: 0.867533
New value of Value function: 0.867533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 793
New value of Q matrix: 0.850182
New value of Value function: 0.850182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3063
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0.850182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3064
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0
New value of Value function: 0.850182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3065
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 794
New value of Q matrix: 0.833179
New value of Value function: 0.833179
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3066
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 795
New value of Q matrix: 0.816515
New value of Value function: 0.816515
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0.816515
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3068
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 796
New value of Q matrix: 0.800185
New value of Value function: 0.800185
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3069
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 797
New value of Q matrix: 0.824181
New value of Value function: 0.824181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3070
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3071
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3072
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3073
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3074
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0.824181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3075
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 798
New value of Q matrix: 0.807697
New value of Value function: 0.807697
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3076
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 799
New value of Q matrix: 0.791543
New value of Value function: 0.791543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3077
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 800
New value of Q matrix: 0.815713
New value of Value function: 0.815713
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3078
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3079
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 0.799398
New value of Value function: 0.799398
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3081
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0
New value of Value function: 0.799398
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3082
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 802
New value of Q matrix: 0.82341
New value of Value function: 0.82341
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3083
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3084
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 0.806942
New value of Value function: 0.806942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3086
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 804
New value of Q matrix: 0.830803
New value of Value function: 0.830803
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3087
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3088
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0.830803
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 805
New value of Q matrix: 0.814187
New value of Value function: 0.814187
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0.814187
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0.814187
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.358569
New value of Value function: 0.814187
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3094
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 0.797904
New value of Value function: 0.797904
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3095
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 807
New value of Q matrix: 0.821945
New value of Value function: 0.821945
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3096
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3097
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3098
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 808
New value of Q matrix: 0.845507
New value of Value function: 0.845507
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3099
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3100
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 0.828596
New value of Value function: 0.828596
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 0.391397
New value of Value function: 0.828596
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3103
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3104
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3105
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3106
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 0.812024
New value of Value function: 0.812024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0
New value of Value function: 0.812024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0.812024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 0.795784
New value of Value function: 0.795784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 812
New value of Q matrix: 0.819868
New value of Value function: 0.819868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3112
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3113
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 105
New value of Q matrix: 0.423569
New value of Value function: 0.819868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3115
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3116
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0.819868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 0.803471
New value of Value function: 0.803471
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 814
New value of Q matrix: 0.787402
New value of Value function: 0.787402
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 815
New value of Q matrix: 0.811653
New value of Value function: 0.811653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3121
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3122
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 816
New value of Q matrix: 0.79542
New value of Value function: 0.79542
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0.79542
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 817
New value of Q matrix: 0.779512
New value of Value function: 0.779512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0
New value of Value function: 0.779512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0.779512
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 818
New value of Q matrix: 0.763922
New value of Value function: 0.763922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0
New value of Value function: 0.763922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 819
New value of Q matrix: 0.748643
New value of Value function: 0.748643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 820
New value of Q matrix: 0.77367
New value of Value function: 0.77367
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3132
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3133
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 821
New value of Q matrix: 0.758197
New value of Value function: 0.758197
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 822
New value of Q matrix: 0.783033
New value of Value function: 0.783033
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3136
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3137
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 823
New value of Q matrix: 0.767372
New value of Value function: 0.767372
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0.767372
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 824
New value of Q matrix: 0.792025
New value of Value function: 0.792025
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3141
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3142
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3143
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3144
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 825
New value of Q matrix: 0.776185
New value of Value function: 0.776185
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 826
New value of Q matrix: 0.800661
New value of Value function: 0.800661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3147
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3148
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 827
New value of Q matrix: 0.784648
New value of Value function: 0.784648
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 828
New value of Q matrix: 0.808955
New value of Value function: 0.808955
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3151
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3152
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3153
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3154
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3155
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3156
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 829
New value of Q matrix: 0.792776
New value of Value function: 0.792776
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 830
New value of Q matrix: 0.81692
New value of Value function: 0.81692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3159
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3160
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 831
New value of Q matrix: 0.800582
New value of Value function: 0.800582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 832
New value of Q matrix: 0.82457
New value of Value function: 0.82457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3163
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3164
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 833
New value of Q matrix: 0.808079
New value of Value function: 0.808079
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0.808079
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 834
New value of Q matrix: 0.791917
New value of Value function: 0.791917
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0
New value of Value function: 0.791917
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 835
New value of Q matrix: 0.816079
New value of Value function: 0.816079
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3170
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3171
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 836
New value of Q matrix: 0.799757
New value of Value function: 0.799757
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 837
New value of Q matrix: 0.823762
New value of Value function: 0.823762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3174
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3175
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0
New value of Value function: 0.823762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0.823762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.415098
New value of Value function: 0.823762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0
New value of Value function: 0.823762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 838
New value of Q matrix: 0.807287
New value of Value function: 0.807287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 107
New value of Q matrix: 0.446796
New value of Value function: 0.807287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3182
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3183
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 839
New value of Q matrix: 0.791141
New value of Value function: 0.791141
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 840
New value of Q matrix: 0.815318
New value of Value function: 0.815318
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3186
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3187
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0.815318
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 841
New value of Q matrix: 0.799012
New value of Value function: 0.799012
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 842
New value of Q matrix: 0.783032
New value of Value function: 0.783032
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0
New value of Value function: 0.783032
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 843
New value of Q matrix: 0.767371
New value of Value function: 0.767371
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0.767371
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 844
New value of Q matrix: 0.792024
New value of Value function: 0.792024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3195
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3196
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 845
New value of Q matrix: 0.776183
New value of Value function: 0.776183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 846
New value of Q matrix: 0.800659
New value of Value function: 0.800659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3199
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3200
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0.800659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 0.784646
New value of Value function: 0.784646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 848
New value of Q matrix: 0.808953
New value of Value function: 0.808953
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3204
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3205
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 0.792774
New value of Value function: 0.792774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 850
New value of Q matrix: 0.816919
New value of Value function: 0.816919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3208
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3209
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3210
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3211
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3212
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3213
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0.816919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0
New value of Value function: 0.816919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 851
New value of Q matrix: 0.80058
New value of Value function: 0.80058
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 852
New value of Q matrix: 0.824569
New value of Value function: 0.824569
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3218
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3219
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0.824569
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 853
New value of Q matrix: 0.808077
New value of Value function: 0.808077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0
New value of Value function: 0.808077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0
New value of Value function: 0.808077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 0.791916
New value of Value function: 0.791916
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 855
New value of Q matrix: 0.816078
New value of Value function: 0.816078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3226
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3227
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3228
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3229
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3230
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3231
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 856
New value of Q matrix: 0.839756
New value of Value function: 0.839756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3233
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3234
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 857
New value of Q matrix: 0.822961
New value of Value function: 0.822961
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 858
New value of Q matrix: 0.846502
New value of Value function: 0.846502
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3237
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3238
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 0.829572
New value of Value function: 0.829572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 860
New value of Q matrix: 0.85298
New value of Value function: 0.85298
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3241
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3242
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3243
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3244
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3245
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 0.835921
New value of Value function: 0.835921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0
New value of Value function: 0.835921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 862
New value of Q matrix: 0.819202
New value of Value function: 0.819202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 863
New value of Q matrix: 0.842818
New value of Value function: 0.842818
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3250
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3251
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.43786
New value of Value function: 0.842818
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 864
New value of Q matrix: 0.865962
New value of Value function: 0.865962
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3254
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3255
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 865
New value of Q matrix: 0.848643
New value of Value function: 0.848643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 866
New value of Q matrix: 0.87167
New value of Value function: 0.87167
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3258
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3259
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 867
New value of Q matrix: 0.854236
New value of Value function: 0.854236
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 868
New value of Q matrix: 0.877152
New value of Value function: 0.877152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3262
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3263
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0
New value of Value function: 0.877152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0
New value of Value function: 0.877152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 869
New value of Q matrix: 0.859609
New value of Value function: 0.859609
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 0.842416
New value of Value function: 0.842416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 0.825568
New value of Value function: 0.825568
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 0.809057
New value of Value function: 0.809057
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 873
New value of Q matrix: 0.832876
New value of Value function: 0.832876
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3271
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3272
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 0.816218
New value of Value function: 0.816218
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 875
New value of Q matrix: 0.839894
New value of Value function: 0.839894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3275
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3276
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 876
New value of Q matrix: 0.823096
New value of Value function: 0.823096
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 877
New value of Q matrix: 0.846634
New value of Value function: 0.846634
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3279
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3280
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 878
New value of Q matrix: 0.869701
New value of Value function: 0.869701
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3282
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3283
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 0.852307
New value of Value function: 0.852307
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 880
New value of Q matrix: 0.875261
New value of Value function: 0.875261
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3286
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3287
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3288
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 881
New value of Q matrix: 0.857756
New value of Value function: 0.857756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 882
New value of Q matrix: 0.880601
New value of Value function: 0.880601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3291
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3292
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 883
New value of Q matrix: 0.902989
New value of Value function: 0.902989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3294
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3295
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3296
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3297
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3298
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3299
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3300
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3301
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3302
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 0.884929
New value of Value function: 0.884929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 885
New value of Q matrix: 0.90723
New value of Value function: 0.90723
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3305
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3306
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 0.889086
New value of Value function: 0.889086
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 887
New value of Q matrix: 0.911304
New value of Value function: 0.911304
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3309
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3310
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3311
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3312
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 0.893078
New value of Value function: 0.893078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0
New value of Value function: 0.893078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 0.875216
New value of Value function: 0.875216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 890
New value of Q matrix: 0.897712
New value of Value function: 0.897712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3317
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3318
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 0.879758
New value of Value function: 0.879758
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 892
New value of Q matrix: 0.902163
New value of Value function: 0.902163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3321
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3322
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 0.884119
New value of Value function: 0.884119
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 894
New value of Q matrix: 0.906437
New value of Value function: 0.906437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3325
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3326
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0
New value of Value function: 0.906437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 0.888308
New value of Value function: 0.888308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 896
New value of Q matrix: 0.910542
New value of Value function: 0.910542
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3330
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3331
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 0.892331
New value of Value function: 0.892331
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 898
New value of Q matrix: 0.914485
New value of Value function: 0.914485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3334
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3335
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 0.896195
New value of Value function: 0.896195
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 900
New value of Q matrix: 0.918271
New value of Value function: 0.918271
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3338
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3339
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0
New value of Value function: 0.918271
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0
New value of Value function: 0.918271
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 0.899906
New value of Value function: 0.899906
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 902
New value of Q matrix: 0.921907
New value of Value function: 0.921907
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3344
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3345
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 0.903469
New value of Value function: 0.903469
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 904
New value of Q matrix: 0.9254
New value of Value function: 0.9254
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3348
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3349
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 0.906892
New value of Value function: 0.906892
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 906
New value of Q matrix: 0.928754
New value of Value function: 0.928754
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3352
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3353
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 0.910179
New value of Value function: 0.910179
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 908
New value of Q matrix: 0.931975
New value of Value function: 0.931975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3356
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3357
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 0.913336
New value of Value function: 0.913336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 910
New value of Q matrix: 0.935069
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3360
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3361
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.429103
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.420521
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0
New value of Value function: 0.935069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 0.916368
New value of Value function: 0.916368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 0.89804
New value of Value function: 0.89804
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 913
New value of Q matrix: 0.92008
New value of Value function: 0.92008
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3370
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3371
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 0.901678
New value of Value function: 0.901678
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0
New value of Value function: 0.901678
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 0.883645
New value of Value function: 0.883645
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 916
New value of Q matrix: 0.905972
New value of Value function: 0.905972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3376
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3377
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0
New value of Value function: 0.905972
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 0.887852
New value of Value function: 0.887852
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 918
New value of Q matrix: 0.910095
New value of Value function: 0.910095
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3381
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3382
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3383
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3384
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0
New value of Value function: 0.910095
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 0.891893
New value of Value function: 0.891893
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 0.874055
New value of Value function: 0.874055
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 921
New value of Q matrix: 0.896574
New value of Value function: 0.896574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3389
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3390
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0
New value of Value function: 0.896574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.41211
New value of Value function: 0.896574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0
New value of Value function: 0.896574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 922
New value of Q matrix: 0.918643
New value of Value function: 0.918643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3395
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3396
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0
New value of Value function: 0.918643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 0.90027
New value of Value function: 0.90027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 0.882265
New value of Value function: 0.882265
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 0.864619
New value of Value function: 0.864619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 926
New value of Q matrix: 0.887327
New value of Value function: 0.887327
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3402
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3403
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 0.86958
New value of Value function: 0.86958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0
New value of Value function: 0.86958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 928
New value of Q matrix: 0.892189
New value of Value function: 0.892189
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3407
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3408
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3409
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 0.874345
New value of Value function: 0.874345
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0
New value of Value function: 0.874345
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 930
New value of Q matrix: 0.896858
New value of Value function: 0.896858
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3412
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3413
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 0.878921
New value of Value function: 0.878921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 932
New value of Q matrix: 0.901342
New value of Value function: 0.901342
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3416
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3417
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3418
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3419
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3420
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3421
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 0.883316
New value of Value function: 0.883316
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 934
New value of Q matrix: 0.905649
New value of Value function: 0.905649
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3424
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3425
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3426
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3427
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0
New value of Value function: 0.905649
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 0.887536
New value of Value function: 0.887536
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 0.869786
New value of Value function: 0.869786
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 937
New value of Q matrix: 0.89239
New value of Value function: 0.89239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3432
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3433
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3434
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3435
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3436
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 0.874542
New value of Value function: 0.874542
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 939
New value of Q matrix: 0.897051
New value of Value function: 0.897051
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3439
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3440
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 0.87911
New value of Value function: 0.87911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0
New value of Value function: 0.87911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 0.861528
New value of Value function: 0.861528
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 942
New value of Q matrix: 0.884297
New value of Value function: 0.884297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3445
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3446
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3447
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3448
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 943
New value of Q matrix: 0.866612
New value of Value function: 0.866612
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 944
New value of Q matrix: 0.889279
New value of Value function: 0.889279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3451
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3452
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 0.871494
New value of Value function: 0.871494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0
New value of Value function: 0.871494
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 946
New value of Q matrix: 0.894064
New value of Value function: 0.894064
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3456
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3457
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3458
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0
New value of Value function: 0.894064
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 0.876183
New value of Value function: 0.876183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0
New value of Value function: 0.876183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 0.858659
New value of Value function: 0.858659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0
New value of Value function: 0.858659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 949
New value of Q matrix: 0.881486
New value of Value function: 0.881486
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3465
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3466
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3467
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0
New value of Value function: 0.881486
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0
New value of Value function: 0.881486
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0
New value of Value function: 0.881486
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 0.863856
New value of Value function: 0.863856
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0
New value of Value function: 0.863856
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 0.846579
New value of Value function: 0.846579
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 0.829647
New value of Value function: 0.829647
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 953
New value of Q matrix: 0.853054
New value of Value function: 0.853054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3476
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3477
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0
New value of Value function: 0.853054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0
New value of Value function: 0.853054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0
New value of Value function: 0.853054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 0.835993
New value of Value function: 0.835993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.403868
New value of Value function: 0.835993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 955
New value of Q matrix: 0.859273
New value of Value function: 0.859273
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3484
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3485
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 0.842088
New value of Value function: 0.842088
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 957
New value of Q matrix: 0.865246
New value of Value function: 0.865246
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3488
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3489
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 0.847941
New value of Value function: 0.847941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0
New value of Value function: 0.847941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 959
New value of Q matrix: 0.870982
New value of Value function: 0.870982
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3493
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3494
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 960
New value of Q matrix: 0.853563
New value of Value function: 0.853563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0
New value of Value function: 0.853563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 113
New value of Q matrix: 0.435791
New value of Value function: 0.853563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3498
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3499
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3500
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3501
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 961
New value of Q matrix: 0.836492
New value of Value function: 0.836492
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0
New value of Value function: 0.836492
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 962
New value of Q matrix: 0.859762
New value of Value function: 0.859762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3505
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3506
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0
New value of Value function: 0.859762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.427075
New value of Value function: 0.859762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0
New value of Value function: 0.859762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 963
New value of Q matrix: 0.842566
New value of Value function: 0.842566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 964
New value of Q matrix: 0.865715
New value of Value function: 0.865715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3512
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3513
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 965
New value of Q matrix: 0.848401
New value of Value function: 0.848401
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 966
New value of Q matrix: 0.871433
New value of Value function: 0.871433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3516
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3517
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0
New value of Value function: 0.871433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 967
New value of Q matrix: 0.854004
New value of Value function: 0.854004
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 968
New value of Q matrix: 0.836924
New value of Value function: 0.836924
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0
New value of Value function: 0.836924
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0
New value of Value function: 0.836924
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 969
New value of Q matrix: 0.820186
New value of Value function: 0.820186
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 970
New value of Q matrix: 0.803782
New value of Value function: 0.803782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0
New value of Value function: 0.803782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0
New value of Value function: 0.803782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 971
New value of Q matrix: 0.787706
New value of Value function: 0.787706
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 972
New value of Q matrix: 0.811952
New value of Value function: 0.811952
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3529
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3530
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3531
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3532
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 973
New value of Q matrix: 0.795713
New value of Value function: 0.795713
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 974
New value of Q matrix: 0.819799
New value of Value function: 0.819799
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3535
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3536
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0
New value of Value function: 0.819799
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 975
New value of Q matrix: 0.803403
New value of Value function: 0.803403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 976
New value of Q matrix: 0.787335
New value of Value function: 0.787335
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 977
New value of Q matrix: 0.771588
New value of Value function: 0.771588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 978
New value of Q matrix: 0.796156
New value of Value function: 0.796156
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3542
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3543
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 979
New value of Q matrix: 0.780233
New value of Value function: 0.780233
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0
New value of Value function: 0.780233
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 980
New value of Q matrix: 0.764629
New value of Value function: 0.764629
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0
New value of Value function: 0.764629
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 981
New value of Q matrix: 0.789336
New value of Value function: 0.789336
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3549
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3550
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3551
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3552
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 982
New value of Q matrix: 0.773549
New value of Value function: 0.773549
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 983
New value of Q matrix: 0.798078
New value of Value function: 0.798078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3555
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3556
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 984
New value of Q matrix: 0.782117
New value of Value function: 0.782117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 985
New value of Q matrix: 0.806474
New value of Value function: 0.806474
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3559
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3560
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 986
New value of Q matrix: 0.790345
New value of Value function: 0.790345
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 987
New value of Q matrix: 0.814538
New value of Value function: 0.814538
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3563
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3564
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3565
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3566
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3567
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.418533
New value of Value function: 0.814538
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 988
New value of Q matrix: 0.838247
New value of Value function: 0.838247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3570
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3571
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 989
New value of Q matrix: 0.821482
New value of Value function: 0.821482
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 116
New value of Q matrix: 0.450163
New value of Value function: 0.821482
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3574
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3575
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 990
New value of Q matrix: 0.805053
New value of Value function: 0.805053
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 991
New value of Q matrix: 0.788952
New value of Value function: 0.788952
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 992
New value of Q matrix: 0.813173
New value of Value function: 0.813173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3579
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3580
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3581
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3582
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3583
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3584
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.222862
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3585
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.218405
New value of Value function: 0.218405
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3586
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.214037
New value of Value function: 0.214037
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3587
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 0.1188
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3588
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3589
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.1188
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3590
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.269756
New value of Value function: 0.269756
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3591
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3592
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3593
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3594
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 993
New value of Q matrix: 0.796909
New value of Value function: 0.796909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 994
New value of Q matrix: 0.820971
New value of Value function: 0.820971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3597
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3598
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.44116
New value of Value function: 0.820971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 995
New value of Q matrix: 0.844551
New value of Value function: 0.844551
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3601
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3602
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.432336
New value of Value function: 0.844551
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 996
New value of Q matrix: 0.86766
New value of Value function: 0.86766
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3605
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3606
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3607
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.42369
New value of Value function: 0.86766
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0
New value of Value function: 0.86766
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 997
New value of Q matrix: 0.890307
New value of Value function: 0.890307
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3611
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0.0289928
New value of Value function: 0.0289928
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3612
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.0284129
New value of Value function: 0.0284129
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 998
New value of Q matrix: 0.872501
New value of Value function: 0.872501
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 999
New value of Q matrix: 0.895051
New value of Value function: 0.895051
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3615
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.0278447
New value of Value function: 0.0278447
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3616
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.0272878
New value of Value function: 0.0272878
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1000
New value of Q matrix: 0.87715
New value of Value function: 0.87715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1001
New value of Q matrix: 0.899607
New value of Value function: 0.899607
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3619
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.0272878
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3620
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.026742
New value of Value function: 0.026742
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3621
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.0262072
New value of Value function: 0.0262072
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1002
New value of Q matrix: 0.881615
New value of Value function: 0.881615
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1003
New value of Q matrix: 0.903983
New value of Value function: 0.903983
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3624
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0262072
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3625
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.025683
New value of Value function: 0.025683
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3626
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.025683
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3627
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.025683
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3628
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.0251694
New value of Value function: 0.0251694
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3629
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.0251694
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1004
New value of Q matrix: 0.925903
New value of Value function: 0.925903
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3631
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0.024666
New value of Value function: 0.024666
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3632
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.0241727
New value of Value function: 0.0241727
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.415216
New value of Value function: 0.925903
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1005
New value of Q matrix: 0.947385
New value of Value function: 0.947385
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3635
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.0241727
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3636
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.0236892
New value of Value function: 0.0236892
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3637
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.0236892
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3638
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 0.928437
New value of Value function: 0.928437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3639
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1007
New value of Q matrix: 0.949868
New value of Value function: 0.949868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3640
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3641
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3642
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0
New value of Value function: 0.949868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3643
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0
New value of Value function: 0.949868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0
New value of Value function: 0.949868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 0.930871
New value of Value function: 0.930871
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 0.912254
New value of Value function: 0.912254
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1010
New value of Q matrix: 0.934009
New value of Value function: 0.934009
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3648
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3649
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3650
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 0.915328
New value of Value function: 0.915328
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1012
New value of Q matrix: 0.937022
New value of Value function: 0.937022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3653
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3654
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3655
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3656
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.0236892
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3657
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 0.324361
New value of Value function: 0.324361
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3658
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3659
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3660
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3661
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3662
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3663
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3664
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3665
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3666
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3667
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0
New value of Value function: 0.937022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 0.918281
New value of Value function: 0.918281
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1014
New value of Q matrix: 0.939916
New value of Value function: 0.939916
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3670
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3671
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3672
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 0.921117
New value of Value function: 0.921117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3673
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1016
New value of Q matrix: 0.942695
New value of Value function: 0.942695
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3674
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3675
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 0.923841
New value of Value function: 0.923841
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1018
New value of Q matrix: 0.945364
New value of Value function: 0.945364
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3678
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3679
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3680
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.406912
New value of Value function: 0.945364
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3681
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1019
New value of Q matrix: 0.966457
New value of Value function: 0.966457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3682
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.0232154
New value of Value function: 0.0232154
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3683
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0.0227511
New value of Value function: 0.0227511
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.398773
New value of Value function: 0.966457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1020
New value of Q matrix: 0.987128
New value of Value function: 0.987128
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3686
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0.0222961
New value of Value function: 0.0222961
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3687
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0.0218502
New value of Value function: 0.0218502
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3688
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1021
New value of Q matrix: 0.967385
New value of Value function: 0.967385
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3689
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1022
New value of Q matrix: 0.988038
New value of Value function: 0.988038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3690
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.0214132
New value of Value function: 0.0214132
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3691
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 0.0209849
New value of Value function: 0.0209849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1023
New value of Q matrix: 0.968277
New value of Value function: 0.968277
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1024
New value of Q matrix: 0.988911
New value of Value function: 0.988911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3694
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0.0209849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3695
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0.0209849
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3696
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.0205652
New value of Value function: 0.0205652
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3697
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 0.0201539
New value of Value function: 0.0201539
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 0.969133
New value of Value function: 0.969133
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1026
New value of Q matrix: 0.989751
New value of Value function: 0.989751
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3700
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.0201539
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3701
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.0197508
New value of Value function: 0.0197508
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3702
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0197508
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3703
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.0193558
New value of Value function: 0.0193558
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3704
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.0189687
New value of Value function: 0.0189687
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1027
New value of Q matrix: 0.969956
New value of Value function: 0.969956
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1028
New value of Q matrix: 0.990556
New value of Value function: 0.990556
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3707
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.0185893
New value of Value function: 0.0185893
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3708
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.0182175
New value of Value function: 0.0182175
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1029
New value of Q matrix: 0.970745
New value of Value function: 0.970745
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1030
New value of Q matrix: 0.99133
New value of Value function: 0.99133
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3711
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.0178532
New value of Value function: 0.0178532
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3712
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.0174961
New value of Value function: 0.0174961
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1031
New value of Q matrix: 0.971504
New value of Value function: 0.971504
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1032
New value of Q matrix: 0.992074
New value of Value function: 0.992074
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3715
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.0171462
New value of Value function: 0.0171462
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3716
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0.0171462
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3717
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1033
New value of Q matrix: 0.972232
New value of Value function: 0.972232
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1034
New value of Q matrix: 0.992788
New value of Value function: 0.992788
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3719
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.0168033
New value of Value function: 0.0168033
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3720
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.0164672
New value of Value function: 0.0164672
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 0.972932
New value of Value function: 0.972932
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1036
New value of Q matrix: 0.993473
New value of Value function: 0.993473
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3723
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.0161379
New value of Value function: 0.0161379
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3724
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0.0161379
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 0.973604
New value of Value function: 0.973604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0
New value of Value function: 0.973604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1038
New value of Q matrix: 0.994132
New value of Value function: 0.994132
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3728
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3729
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1039
New value of Q matrix: 0.974249
New value of Value function: 0.974249
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1040
New value of Q matrix: 0.994764
New value of Value function: 0.994764
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3732
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3733
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 132
New value of Q matrix: 0.0758151
New value of Value function: 0.0758151
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3734
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3735
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.390798
New value of Value function: 0.994764
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0
New value of Value function: 0.994764
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1041
New value of Q matrix: 1.01487
New value of Value function: 1.01487
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3739
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.0742988
New value of Value function: 0.0742988
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3740
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 0.0728128
New value of Value function: 0.0728128
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3741
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1042
New value of Q matrix: 0.994571
New value of Value function: 0.994571
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3742
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1043
New value of Q matrix: 1.01468
New value of Value function: 1.01468
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3743
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0.0713566
New value of Value function: 0.0713566
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3744
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0.0713566
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1044
New value of Q matrix: 1.03439
New value of Value function: 1.03439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3746
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.0699294
New value of Value function: 0.0699294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3747
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0699294
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1045
New value of Q matrix: 1.0537
New value of Value function: 1.0537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3749
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0.0685309
New value of Value function: 0.0685309
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3750
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.0671602
New value of Value function: 0.0671602
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 1.03262
New value of Value function: 1.03262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1047
New value of Q matrix: 1.05197
New value of Value function: 1.05197
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3753
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.0671602
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3754
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.065817
New value of Value function: 0.065817
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3755
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0.065817
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3756
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.0645007
New value of Value function: 0.0645007
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3757
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.0632107
New value of Value function: 0.0632107
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1048
New value of Q matrix: 1.03093
New value of Value function: 1.03093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1049
New value of Q matrix: 1.05031
New value of Value function: 1.05031
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3760
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0.0619465
New value of Value function: 0.0619465
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3761
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0.0607075
New value of Value function: 0.0607075
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 1.02931
New value of Value function: 1.02931
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1051
New value of Q matrix: 1.04872
New value of Value function: 1.04872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3764
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.0594934
New value of Value function: 0.0594934
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3765
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.0583035
New value of Value function: 0.0583035
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0
New value of Value function: 1.04872
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3767
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1052
New value of Q matrix: 1.02775
New value of Value function: 1.02775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3768
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 1.00719
New value of Value function: 1.00719
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0
New value of Value function: 1.00719
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 0
New value of Value function: 1.00719
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3771
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1054
New value of Q matrix: 1.02705
New value of Value function: 1.02705
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3772
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0.0583035
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3773
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.0571374
New value of Value function: 0.0571374
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3774
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.0571374
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3775
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.382982
New value of Value function: 1.02705
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3776
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1055
New value of Q matrix: 1.04651
New value of Value function: 1.04651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3777
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0.0559947
New value of Value function: 0.0559947
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3778
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.0548748
New value of Value function: 0.0548748
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1056
New value of Q matrix: 1.02558
New value of Value function: 1.02558
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1057
New value of Q matrix: 1.04507
New value of Value function: 1.04507
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3781
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.0537773
New value of Value function: 0.0537773
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3782
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.0537773
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1058
New value of Q matrix: 1.02416
New value of Value function: 1.02416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3784
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0
New value of Value function: 1.02416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3785
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0
New value of Value function: 1.02416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1059
New value of Q matrix: 1.00368
New value of Value function: 1.00368
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1060
New value of Q matrix: 1.02361
New value of Value function: 1.02361
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3788
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0.0527018
New value of Value function: 0.0527018
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3789
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0.0527018
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3790
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 0.06
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3791
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3792
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3793
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 125
New value of Q matrix: 0.415322
New value of Value function: 1.02361
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3794
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3795
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0.0588
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0
New value of Value function: 1.02361
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1061
New value of Q matrix: 1.04314
New value of Value function: 1.04314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3798
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3799
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3800
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3801
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.407016
New value of Value function: 1.04314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 0
New value of Value function: 1.04314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1062
New value of Q matrix: 1.02227
New value of Value function: 1.02227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.398875
New value of Value function: 1.02227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1063
New value of Q matrix: 1.04183
New value of Value function: 1.04183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3806
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 0.117624
New value of Value function: 0.117624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3807
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3808
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0
New value of Value function: 1.04183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0
New value of Value function: 1.04183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0
New value of Value function: 1.04183
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 1.02099
New value of Value function: 1.02099
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 1.00057
New value of Value function: 1.00057
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1066
New value of Q matrix: 1.02056
New value of Value function: 1.02056
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3815
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3816
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 1.00015
New value of Value function: 1.00015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.390898
New value of Value function: 1.00015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1068
New value of Q matrix: 1.02015
New value of Value function: 1.02015
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3820
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 0.175272
New value of Value function: 0.175272
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3821
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3822
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 0.999742
New value of Value function: 0.999742
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1070
New value of Q matrix: 1.01975
New value of Value function: 1.01975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3825
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3826
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1071
New value of Q matrix: 1.03935
New value of Value function: 1.03935
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3828
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.171766
New value of Value function: 0.171766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3829
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.168331
New value of Value function: 0.168331
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3830
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.164964
New value of Value function: 0.164964
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 0.38308
New value of Value function: 1.03935
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1072
New value of Q matrix: 1.05857
New value of Value function: 1.05857
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3833
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3834
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1073
New value of Q matrix: 1.03739
New value of Value function: 1.03739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1074
New value of Q matrix: 1.05665
New value of Value function: 1.05665
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3837
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3838
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3839
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1075
New value of Q matrix: 1.03551
New value of Value function: 1.03551
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3840
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1076
New value of Q matrix: 1.0548
New value of Value function: 1.0548
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3841
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3842
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 1.03371
New value of Value function: 1.03371
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1078
New value of Q matrix: 1.05303
New value of Value function: 1.05303
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3845
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3846
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1079
New value of Q matrix: 1.03197
New value of Value function: 1.03197
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0
New value of Value function: 1.03197
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 1.01133
New value of Value function: 1.01133
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1081
New value of Q matrix: 1.03111
New value of Value function: 1.03111
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3851
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3852
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3853
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3854
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 1.01048
New value of Value function: 1.01048
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0
New value of Value function: 1.01048
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.375418
New value of Value function: 1.01048
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0
New value of Value function: 1.01048
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1083
New value of Q matrix: 1.03027
New value of Value function: 1.03027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3860
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3861
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 1.00967
New value of Value function: 1.00967
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0
New value of Value function: 1.00967
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3864
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1085
New value of Q matrix: 0.989475
New value of Value function: 0.989475
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3865
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 0.36791
New value of Value function: 0.989475
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1086
New value of Q matrix: 1.00969
New value of Value function: 1.00969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3867
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3868
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 0.360552
New value of Value function: 1.00969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 133
New value of Q matrix: 0.393341
New value of Value function: 1.00969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3871
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0.164964
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3872
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.161665
New value of Value function: 0.161665
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3873
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0.161665
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3874
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.158432
New value of Value function: 0.158432
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3875
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.155263
New value of Value function: 0.155263
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 3876
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 0.989492
New value of Value function: 0.989492
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3877
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1088
New value of Q matrix: 1.0097
New value of Value function: 1.0097
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3878
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3879
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3880
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3881
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3882
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 0.989508
New value of Value function: 0.989508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0
New value of Value function: 0.989508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 0.969718
New value of Value function: 0.969718
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1091
New value of Q matrix: 0.990324
New value of Value function: 0.990324
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3887
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3888
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3889
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3890
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3891
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3892
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 0.970517
New value of Value function: 0.970517
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3893
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1093
New value of Q matrix: 0.991107
New value of Value function: 0.991107
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3894
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3895
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0
New value of Value function: 0.991107
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3897
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 0.971285
New value of Value function: 0.971285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1095
New value of Q matrix: 0.991859
New value of Value function: 0.991859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3899
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3900
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3901
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 0.972022
New value of Value function: 0.972022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1097
New value of Q matrix: 0.992582
New value of Value function: 0.992582
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3904
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3905
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 0.97273
New value of Value function: 0.97273
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3907
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1099
New value of Q matrix: 0.993275
New value of Value function: 0.993275
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3908
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3909
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3910
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3911
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1100
New value of Q matrix: 1.01341
New value of Value function: 1.01341
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3913
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3914
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3915
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3916
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3917
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 0.993142
New value of Value function: 0.993142
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3918
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0
New value of Value function: 0.993142
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 0.973279
New value of Value function: 0.973279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1103
New value of Q matrix: 0.993813
New value of Value function: 0.993813
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3921
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3922
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3923
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 0.973937
New value of Value function: 0.973937
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3924
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 134
New value of Q matrix: 0.425474
New value of Value function: 0.973937
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3925
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3926
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 0.954458
New value of Value function: 0.954458
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1106
New value of Q matrix: 0.975369
New value of Value function: 0.975369
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3929
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3930
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 0.955862
New value of Value function: 0.955862
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1108
New value of Q matrix: 0.976744
New value of Value function: 0.976744
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3933
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3934
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 0.95721
New value of Value function: 0.95721
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1110
New value of Q matrix: 0.978065
New value of Value function: 0.978065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3937
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3938
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0
New value of Value function: 0.978065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0
New value of Value function: 0.978065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 0.958504
New value of Value function: 0.958504
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1112
New value of Q matrix: 0.979334
New value of Value function: 0.979334
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3943
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3944
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 0.959747
New value of Value function: 0.959747
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1114
New value of Q matrix: 0.980552
New value of Value function: 0.980552
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3947
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3948
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3949
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3950
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3951
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3952
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1115
New value of Q matrix: 0.960941
New value of Value function: 0.960941
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1116
New value of Q matrix: 0.981722
New value of Value function: 0.981722
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3954
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3955
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3956
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3957
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 0.962088
New value of Value function: 0.962088
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3959
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1118
New value of Q matrix: 0.982846
New value of Value function: 0.982846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3960
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3961
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0
New value of Value function: 0.982846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3963
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1119
New value of Q matrix: 1.00319
New value of Value function: 1.00319
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3964
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3965
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1120
New value of Q matrix: 0.983126
New value of Value function: 0.983126
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1121
New value of Q matrix: 1.00346
New value of Value function: 1.00346
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3968
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3969
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 0.983394
New value of Value function: 0.983394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1123
New value of Q matrix: 1.00373
New value of Value function: 1.00373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3972
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3973
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0
New value of Value function: 1.00373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1124
New value of Q matrix: 0.983651
New value of Value function: 0.983651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3976
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1125
New value of Q matrix: 1.00398
New value of Value function: 1.00398
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3977
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3978
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3979
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1126
New value of Q matrix: 1.0239
New value of Value function: 1.0239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3980
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3981
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1127
New value of Q matrix: 1.00342
New value of Value function: 1.00342
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0
New value of Value function: 1.00342
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1128
New value of Q matrix: 0.983352
New value of Value function: 0.983352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 135
New value of Q matrix: 0.456965
New value of Value function: 0.983352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3986
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3987
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3988
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3989
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3990
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3991
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 0.447825
New value of Value function: 0.983352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3993
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1129
New value of Q matrix: 1.00369
New value of Value function: 1.00369
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3994
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3995
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3996
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1130
New value of Q matrix: 0.983612
New value of Value function: 0.983612
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3997
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1131
New value of Q matrix: 1.00394
New value of Value function: 1.00394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 3998
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3999
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1132
New value of Q matrix: 0.983861
New value of Value function: 0.983861
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4001
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1133
New value of Q matrix: 1.00418
New value of Value function: 1.00418
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4002
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4003
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4004
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1134
New value of Q matrix: 0.9841
New value of Value function: 0.9841
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4005
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1135
New value of Q matrix: 1.00442
New value of Value function: 1.00442
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4006
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4007
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1136
New value of Q matrix: 0.984329
New value of Value function: 0.984329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4009
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1137
New value of Q matrix: 1.00464
New value of Value function: 1.00464
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4010
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4011
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4012
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4013
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4014
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1138
New value of Q matrix: 0.98455
New value of Value function: 0.98455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4015
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1139
New value of Q matrix: 1.00486
New value of Value function: 1.00486
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4016
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4017
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 0.212158
New value of Value function: 0.212158
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4018
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4019
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4020
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1140
New value of Q matrix: 0.984762
New value of Value function: 0.984762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4021
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1141
New value of Q matrix: 1.00507
New value of Value function: 1.00507
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4022
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4023
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4024
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1142
New value of Q matrix: 0.984965
New value of Value function: 0.984965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4025
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 137
New value of Q matrix: 0.478869
New value of Value function: 0.984965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4026
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4027
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4028
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4029
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4030
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4031
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4032
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4033
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4034
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1143
New value of Q matrix: 0.965266
New value of Value function: 0.965266
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4035
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1144
New value of Q matrix: 0.985961
New value of Value function: 0.985961
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4036
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4037
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4038
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4039
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4040
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1145
New value of Q matrix: 0.966241
New value of Value function: 0.966241
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4041
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1146
New value of Q matrix: 0.986917
New value of Value function: 0.986917
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4042
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4043
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4044
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1147
New value of Q matrix: 0.967178
New value of Value function: 0.967178
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0
New value of Value function: 0.967178
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4046
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 0.469291
New value of Value function: 0.967178
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4047
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1148
New value of Q matrix: 0.987835
New value of Value function: 0.987835
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4048
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4049
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4050
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0
New value of Value function: 0.987835
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4051
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 0.459906
New value of Value function: 0.987835
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4052
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1149
New value of Q matrix: 0.968078
New value of Value function: 0.968078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4053
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1150
New value of Q matrix: 0.988716
New value of Value function: 0.988716
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4054
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4055
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4056
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4057
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0
New value of Value function: 0.988716
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4059
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1151
New value of Q matrix: 0.968942
New value of Value function: 0.968942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0
New value of Value function: 0.968942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4061
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 0.949563
New value of Value function: 0.949563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 0.930572
New value of Value function: 0.930572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4063
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1154
New value of Q matrix: 0.951961
New value of Value function: 0.951961
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4064
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4065
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4066
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 0.932921
New value of Value function: 0.932921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1156
New value of Q matrix: 0.954263
New value of Value function: 0.954263
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4068
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4069
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4070
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 0.935178
New value of Value function: 0.935178
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4071
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1158
New value of Q matrix: 0.956474
New value of Value function: 0.956474
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4072
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4073
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4074
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 0.450707
New value of Value function: 0.956474
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4075
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0
New value of Value function: 0.956474
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4076
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1159
New value of Q matrix: 0.977345
New value of Value function: 0.977345
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4077
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4078
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 0.957798
New value of Value function: 0.957798
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1161
New value of Q matrix: 0.978642
New value of Value function: 0.978642
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4081
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4082
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4083
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 0.959069
New value of Value function: 0.959069
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1163
New value of Q matrix: 0.979888
New value of Value function: 0.979888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4085
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4086
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4087
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4088
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 0.96029
New value of Value function: 0.96029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0
New value of Value function: 0.96029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4091
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 0.441693
New value of Value function: 0.96029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1165
New value of Q matrix: 0.981084
New value of Value function: 0.981084
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4093
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4094
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4095
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0
New value of Value function: 0.981084
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 0.961462
New value of Value function: 0.961462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4097
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 0
New value of Value function: 0.961462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4098
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 0.942233
New value of Value function: 0.942233
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4099
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0
New value of Value function: 0.942233
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 0.923388
New value of Value function: 0.923388
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 0.904921
New value of Value function: 0.904921
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1170
New value of Q matrix: 0.926822
New value of Value function: 0.926822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4103
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4104
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4105
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4106
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 0.908286
New value of Value function: 0.908286
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1172
New value of Q matrix: 0.93012
New value of Value function: 0.93012
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4109
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4110
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 0.911518
New value of Value function: 0.911518
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1174
New value of Q matrix: 0.933287
New value of Value function: 0.933287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4113
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4114
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4115
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4116
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1175
New value of Q matrix: 0.914622
New value of Value function: 0.914622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1176
New value of Q matrix: 0.936329
New value of Value function: 0.936329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4119
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4120
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1177
New value of Q matrix: 0.917603
New value of Value function: 0.917603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1178
New value of Q matrix: 0.93925
New value of Value function: 0.93925
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4123
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4124
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1179
New value of Q matrix: 0.920465
New value of Value function: 0.920465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1180
New value of Q matrix: 0.942056
New value of Value function: 0.942056
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4127
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4128
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1181
New value of Q matrix: 0.963215
New value of Value function: 0.963215
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4130
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4131
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1182
New value of Q matrix: 0.943951
New value of Value function: 0.943951
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 142
New value of Q matrix: 0.472859
New value of Value function: 0.943951
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4134
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4135
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1183
New value of Q matrix: 0.925072
New value of Value function: 0.925072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 143
New value of Q matrix: 0.503402
New value of Value function: 0.925072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4138
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4139
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1184
New value of Q matrix: 0.90657
New value of Value function: 0.90657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1185
New value of Q matrix: 0.888439
New value of Value function: 0.888439
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1186
New value of Q matrix: 0.91067
New value of Value function: 0.91067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4143
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4144
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4145
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4146
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 0.267915
New value of Value function: 0.267915
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4147
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4148
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0
New value of Value function: 0.91067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1187
New value of Q matrix: 0.892457
New value of Value function: 0.892457
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1188
New value of Q matrix: 0.914608
New value of Value function: 0.914608
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4152
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4153
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1189
New value of Q matrix: 0.896315
New value of Value function: 0.896315
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1190
New value of Q matrix: 0.918389
New value of Value function: 0.918389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4156
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4157
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.0516477
New value of Value function: 0.267915
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4158
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.06
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4159
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.06
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 4160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0
New value of Value function: 0.918389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1191
New value of Q matrix: 0.900021
New value of Value function: 0.900021
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1192
New value of Q matrix: 0.882021
New value of Value function: 0.882021
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 0
New value of Value function: 0.882021
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1193
New value of Q matrix: 0.86438
New value of Value function: 0.86438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1194
New value of Q matrix: 0.887093
New value of Value function: 0.887093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4166
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4167
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1195
New value of Q matrix: 0.869351
New value of Value function: 0.869351
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1196
New value of Q matrix: 0.891964
New value of Value function: 0.891964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4170
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4171
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1197
New value of Q matrix: 0.874125
New value of Value function: 0.874125
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1198
New value of Q matrix: 0.896642
New value of Value function: 0.896642
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4174
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4175
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4176
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4177
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4178
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1199
New value of Q matrix: 0.878709
New value of Value function: 0.878709
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0
New value of Value function: 0.878709
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1200
New value of Q matrix: 0.901135
New value of Value function: 0.901135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4182
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4183
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0
New value of Value function: 0.901135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 0.493334
New value of Value function: 0.901135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1201
New value of Q matrix: 0.883112
New value of Value function: 0.883112
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1202
New value of Q matrix: 0.90545
New value of Value function: 0.90545
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4188
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4189
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1203
New value of Q matrix: 0.887341
New value of Value function: 0.887341
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1204
New value of Q matrix: 0.909594
New value of Value function: 0.909594
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4192
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4193
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1205
New value of Q matrix: 0.891403
New value of Value function: 0.891403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1206
New value of Q matrix: 0.913574
New value of Value function: 0.913574
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4196
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4197
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4198
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4199
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4200
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4201
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4202
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4203
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1207
New value of Q matrix: 0.895303
New value of Value function: 0.895303
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1208
New value of Q matrix: 0.917397
New value of Value function: 0.917397
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4206
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4207
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0
New value of Value function: 0.917397
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1209
New value of Q matrix: 0.899049
New value of Value function: 0.899049
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1210
New value of Q matrix: 0.881068
New value of Value function: 0.881068
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1211
New value of Q matrix: 0.903447
New value of Value function: 0.903447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4212
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4213
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 0.885378
New value of Value function: 0.885378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1213
New value of Q matrix: 0.90767
New value of Value function: 0.90767
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4216
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4217
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4218
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4219
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 0.889517
New value of Value function: 0.889517
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1215
New value of Q matrix: 0.911726
New value of Value function: 0.911726
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4222
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4223
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4224
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 0.893492
New value of Value function: 0.893492
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1217
New value of Q matrix: 0.915622
New value of Value function: 0.915622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4227
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4228
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4229
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4230
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 0.322556
New value of Value function: 0.322556
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4231
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4232
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0
New value of Value function: 0.915622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 0.89731
New value of Value function: 0.89731
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 0.879363
New value of Value function: 0.879363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0
New value of Value function: 0.879363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0
New value of Value function: 0.879363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0
New value of Value function: 0.879363
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 0.861776
New value of Value function: 0.861776
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0
New value of Value function: 0.861776
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 0.844541
New value of Value function: 0.844541
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1222
New value of Q matrix: 0.86765
New value of Value function: 0.86765
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4243
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4244
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 0.850297
New value of Value function: 0.850297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1224
New value of Q matrix: 0.873291
New value of Value function: 0.873291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4247
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4248
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 0.855825
New value of Value function: 0.855825
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0
New value of Value function: 0.855825
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 0
New value of Value function: 0.855825
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 0.838709
New value of Value function: 0.838709
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1227
New value of Q matrix: 0.861934
New value of Value function: 0.861934
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4254
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4255
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 0.844696
New value of Value function: 0.844696
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1229
New value of Q matrix: 0.867802
New value of Value function: 0.867802
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4258
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4259
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0
New value of Value function: 0.867802
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1230
New value of Q matrix: 0.850446
New value of Value function: 0.850446
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 0.833437
New value of Value function: 0.833437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0
New value of Value function: 0.833437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0
New value of Value function: 0.833437
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 0.816768
New value of Value function: 0.816768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0
New value of Value function: 0.816768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 0.800433
New value of Value function: 0.800433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0
New value of Value function: 0.800433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1234
New value of Q matrix: 0.824424
New value of Value function: 0.824424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4270
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4271
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1235
New value of Q matrix: 0.807936
New value of Value function: 0.807936
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1236
New value of Q matrix: 0.831777
New value of Value function: 0.831777
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4274
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4275
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1237
New value of Q matrix: 0.815141
New value of Value function: 0.815141
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1238
New value of Q matrix: 0.838839
New value of Value function: 0.838839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4278
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4279
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 0.822062
New value of Value function: 0.822062
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0
New value of Value function: 0.822062
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0
New value of Value function: 0.822062
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1240
New value of Q matrix: 0.805621
New value of Value function: 0.805621
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1241
New value of Q matrix: 0.829508
New value of Value function: 0.829508
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4285
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4286
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1242
New value of Q matrix: 0.812918
New value of Value function: 0.812918
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1243
New value of Q matrix: 0.83666
New value of Value function: 0.83666
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4289
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4290
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4291
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4292
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4293
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 0.819926
New value of Value function: 0.819926
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1245
New value of Q matrix: 0.843528
New value of Value function: 0.843528
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4296
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4297
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 0.483467
New value of Value function: 0.843528
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1246
New value of Q matrix: 0.866657
New value of Value function: 0.866657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4300
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4301
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0
New value of Value function: 0.866657
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 0.849324
New value of Value function: 0.849324
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1248
New value of Q matrix: 0.872338
New value of Value function: 0.872338
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4305
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4306
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 0.854891
New value of Value function: 0.854891
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 0.837793
New value of Value function: 0.837793
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1251
New value of Q matrix: 0.861037
New value of Value function: 0.861037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4310
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4311
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 0.843817
New value of Value function: 0.843817
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1253
New value of Q matrix: 0.86694
New value of Value function: 0.86694
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4314
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4315
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4316
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4317
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 0.849601
New value of Value function: 0.849601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1255
New value of Q matrix: 0.872609
New value of Value function: 0.872609
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4320
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4321
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 0.376105
New value of Value function: 0.376105
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4322
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4323
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 0.855157
New value of Value function: 0.855157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1257
New value of Q matrix: 0.878054
New value of Value function: 0.878054
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4326
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4327
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 0.860493
New value of Value function: 0.860493
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1259
New value of Q matrix: 0.883283
New value of Value function: 0.883283
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4330
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4331
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4332
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4333
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4334
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 0.473798
New value of Value function: 0.883283
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1260
New value of Q matrix: 0.905617
New value of Value function: 0.905617
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4337
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4338
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1261
New value of Q matrix: 0.887505
New value of Value function: 0.887505
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1262
New value of Q matrix: 0.909755
New value of Value function: 0.909755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4341
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4342
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1263
New value of Q matrix: 0.89156
New value of Value function: 0.89156
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1264
New value of Q matrix: 0.913729
New value of Value function: 0.913729
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4345
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4346
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0
New value of Value function: 0.913729
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1265
New value of Q matrix: 0.895454
New value of Value function: 0.895454
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1266
New value of Q matrix: 0.917545
New value of Value function: 0.917545
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4350
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4351
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1267
New value of Q matrix: 0.899194
New value of Value function: 0.899194
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1268
New value of Q matrix: 0.92121
New value of Value function: 0.92121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4354
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4355
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4356
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4357
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4358
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0
New value of Value function: 0.92121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1269
New value of Q matrix: 0.902786
New value of Value function: 0.902786
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0
New value of Value function: 0.902786
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1270
New value of Q matrix: 0.88473
New value of Value function: 0.88473
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1271
New value of Q matrix: 0.907036
New value of Value function: 0.907036
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4364
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4365
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 147
New value of Q matrix: 0.504322
New value of Value function: 0.907036
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4367
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4368
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4369
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1272
New value of Q matrix: 0.888895
New value of Value function: 0.888895
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1273
New value of Q matrix: 0.911117
New value of Value function: 0.911117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4372
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4373
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1274
New value of Q matrix: 0.892895
New value of Value function: 0.892895
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1275
New value of Q matrix: 0.915037
New value of Value function: 0.915037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4376
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4377
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4378
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4379
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0
New value of Value function: 0.915037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 0
New value of Value function: 0.915037
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1276
New value of Q matrix: 0.896736
New value of Value function: 0.896736
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1277
New value of Q matrix: 0.878801
New value of Value function: 0.878801
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1278
New value of Q matrix: 0.901225
New value of Value function: 0.901225
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4385
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4386
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1279
New value of Q matrix: 0.883201
New value of Value function: 0.883201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0
New value of Value function: 0.883201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0
New value of Value function: 0.883201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0
New value of Value function: 0.883201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1280
New value of Q matrix: 0.865537
New value of Value function: 0.865537
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1281
New value of Q matrix: 0.848226
New value of Value function: 0.848226
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1282
New value of Q matrix: 0.871262
New value of Value function: 0.871262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4394
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4395
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 0.494236
New value of Value function: 0.871262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1283
New value of Q matrix: 0.893836
New value of Value function: 0.893836
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4398
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4399
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0
New value of Value function: 0.893836
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1284
New value of Q matrix: 0.87596
New value of Value function: 0.87596
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1285
New value of Q matrix: 0.85844
New value of Value function: 0.85844
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1286
New value of Q matrix: 0.881272
New value of Value function: 0.881272
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4404
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 548
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4405
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1287
New value of Q matrix: 0.863646
New value of Value function: 0.863646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1288
New value of Q matrix: 0.886373
New value of Value function: 0.886373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4408
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4409
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1289
New value of Q matrix: 0.868646
New value of Value function: 0.868646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0
New value of Value function: 0.868646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1290
New value of Q matrix: 0.851273
New value of Value function: 0.851273
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1291
New value of Q matrix: 0.834247
New value of Value function: 0.834247
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1292
New value of Q matrix: 0.857562
New value of Value function: 0.857562
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4415
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4416
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1293
New value of Q matrix: 0.840411
New value of Value function: 0.840411
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1294
New value of Q matrix: 0.863603
New value of Value function: 0.863603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4419
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4420
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0
New value of Value function: 0.863603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1295
New value of Q matrix: 0.846331
New value of Value function: 0.846331
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1296
New value of Q matrix: 0.829404
New value of Value function: 0.829404
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1297
New value of Q matrix: 0.852816
New value of Value function: 0.852816
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4425
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4426
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1298
New value of Q matrix: 0.83576
New value of Value function: 0.83576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1299
New value of Q matrix: 0.859045
New value of Value function: 0.859045
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4429
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4430
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1300
New value of Q matrix: 0.841864
New value of Value function: 0.841864
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0
New value of Value function: 0.841864
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1301
New value of Q matrix: 0.865027
New value of Value function: 0.865027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4434
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4435
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1302
New value of Q matrix: 0.847726
New value of Value function: 0.847726
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1303
New value of Q matrix: 0.870771
New value of Value function: 0.870771
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4438
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4439
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4440
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4441
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1304
New value of Q matrix: 0.853356
New value of Value function: 0.853356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0
New value of Value function: 0.853356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0
New value of Value function: 0.853356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1305
New value of Q matrix: 0.836289
New value of Value function: 0.836289
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1306
New value of Q matrix: 0.819563
New value of Value function: 0.819563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0
New value of Value function: 0.819563
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1307
New value of Q matrix: 0.803172
New value of Value function: 0.803172
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1308
New value of Q matrix: 0.827108
New value of Value function: 0.827108
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4450
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4451
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1309
New value of Q matrix: 0.850566
New value of Value function: 0.850566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4453
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4454
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0
New value of Value function: 0.850566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1310
New value of Q matrix: 0.833555
New value of Value function: 0.833555
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0
New value of Value function: 0.833555
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1311
New value of Q matrix: 0.856884
New value of Value function: 0.856884
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4459
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4460
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1312
New value of Q matrix: 0.839746
New value of Value function: 0.839746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1313
New value of Q matrix: 0.862951
New value of Value function: 0.862951
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4463
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4464
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1314
New value of Q matrix: 0.845692
New value of Value function: 0.845692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1315
New value of Q matrix: 0.868778
New value of Value function: 0.868778
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4467
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4468
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4469
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4470
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4471
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4472
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4473
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4474
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4475
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4476
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1316
New value of Q matrix: 0.851403
New value of Value function: 0.851403
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1317
New value of Q matrix: 0.874375
New value of Value function: 0.874375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4479
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4480
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1318
New value of Q matrix: 0.856887
New value of Value function: 0.856887
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1319
New value of Q matrix: 0.87975
New value of Value function: 0.87975
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4483
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4484
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1320
New value of Q matrix: 0.862155
New value of Value function: 0.862155
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1321
New value of Q matrix: 0.844911
New value of Value function: 0.844911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0
New value of Value function: 0.844911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1322
New value of Q matrix: 0.868013
New value of Value function: 0.868013
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4489
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4490
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4491
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4492
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4493
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4494
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4495
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4496
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4497
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4498
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1323
New value of Q matrix: 0.850653
New value of Value function: 0.850653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0
New value of Value function: 0.850653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 0.484351
New value of Value function: 0.850653
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1324
New value of Q matrix: 0.87364
New value of Value function: 0.87364
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4503
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4504
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0
New value of Value function: 0.87364
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1325
New value of Q matrix: 0.856167
New value of Value function: 0.856167
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1326
New value of Q matrix: 0.839044
New value of Value function: 0.839044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4508
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0
New value of Value function: 0.839044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1327
New value of Q matrix: 0.862263
New value of Value function: 0.862263
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4510
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4511
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1328
New value of Q matrix: 0.885018
New value of Value function: 0.885018
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4513
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4514
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4515
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4516
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4517
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1329
New value of Q matrix: 0.867317
New value of Value function: 0.867317
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4518
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1330
New value of Q matrix: 0.889971
New value of Value function: 0.889971
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4519
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4520
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4521
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1331
New value of Q matrix: 0.872172
New value of Value function: 0.872172
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4522
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1332
New value of Q matrix: 0.894728
New value of Value function: 0.894728
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4523
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4524
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4525
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4526
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1333
New value of Q matrix: 0.876834
New value of Value function: 0.876834
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1334
New value of Q matrix: 0.899297
New value of Value function: 0.899297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4529
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4530
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0
New value of Value function: 0.899297
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1335
New value of Q matrix: 0.881311
New value of Value function: 0.881311
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1336
New value of Q matrix: 0.863685
New value of Value function: 0.863685
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1337
New value of Q matrix: 0.886411
New value of Value function: 0.886411
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4535
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4536
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1338
New value of Q matrix: 0.868683
New value of Value function: 0.868683
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1339
New value of Q matrix: 0.891309
New value of Value function: 0.891309
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4539
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4540
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1340
New value of Q matrix: 0.873483
New value of Value function: 0.873483
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1341
New value of Q matrix: 0.896013
New value of Value function: 0.896013
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4543
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4544
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1342
New value of Q matrix: 0.878093
New value of Value function: 0.878093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1343
New value of Q matrix: 0.900531
New value of Value function: 0.900531
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4547
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4548
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1344
New value of Q matrix: 0.922521
New value of Value function: 0.922521
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4550
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4551
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 603
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1345
New value of Q matrix: 0.90407
New value of Value function: 0.90407
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0
New value of Value function: 0.90407
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0
New value of Value function: 0.90407
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1346
New value of Q matrix: 0.885989
New value of Value function: 0.885989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 150
New value of Q matrix: 0.514664
New value of Value function: 0.885989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4557
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4558
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 605
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4559
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1347
New value of Q matrix: 0.868269
New value of Value function: 0.868269
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1348
New value of Q matrix: 0.890904
New value of Value function: 0.890904
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4561
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4562
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 607
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 0.504371
New value of Value function: 0.890904
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0
New value of Value function: 0.890904
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1349
New value of Q matrix: 0.913085
New value of Value function: 0.913085
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4566
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4567
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 609
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1350
New value of Q matrix: 0.894824
New value of Value function: 0.894824
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1351
New value of Q matrix: 0.916927
New value of Value function: 0.916927
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4570
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4571
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1352
New value of Q matrix: 0.898589
New value of Value function: 0.898589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1353
New value of Q matrix: 0.920617
New value of Value function: 0.920617
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4574
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4575
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4576
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4577
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1354
New value of Q matrix: 0.902205
New value of Value function: 0.902205
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 0
New value of Value function: 0.902205
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1355
New value of Q matrix: 0.884161
New value of Value function: 0.884161
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0
New value of Value function: 0.884161
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1356
New value of Q matrix: 0.866477
New value of Value function: 0.866477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4583
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 152
New value of Q matrix: 0.534283
New value of Value function: 0.866477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4584
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4585
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0
New value of Value function: 0.866477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4587
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0
New value of Value function: 0.866477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1357
New value of Q matrix: 0.849148
New value of Value function: 0.849148
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1358
New value of Q matrix: 0.872165
New value of Value function: 0.872165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4590
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4591
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 615
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4592
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4593
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 617
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.523598
New value of Value function: 0.872165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1359
New value of Q matrix: 0.894722
New value of Value function: 0.894722
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4596
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.368583
New value of Value function: 0.368583
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4597
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.361211
New value of Value function: 0.361211
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0
New value of Value function: 0.894722
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1360
New value of Q matrix: 0.876827
New value of Value function: 0.876827
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1361
New value of Q matrix: 0.859291
New value of Value function: 0.859291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1362
New value of Q matrix: 0.882105
New value of Value function: 0.882105
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4602
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 618
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4603
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4604
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4605
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4606
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 620
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1363
New value of Q matrix: 0.864463
New value of Value function: 0.864463
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1364
New value of Q matrix: 0.887173
New value of Value function: 0.887173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4609
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 621
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4610
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4611
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1365
New value of Q matrix: 0.86943
New value of Value function: 0.86943
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4612
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1366
New value of Q matrix: 0.892041
New value of Value function: 0.892041
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4613
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 623
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4614
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4615
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1367
New value of Q matrix: 0.874201
New value of Value function: 0.874201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4616
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1368
New value of Q matrix: 0.896717
New value of Value function: 0.896717
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4617
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4618
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 0.413987
New value of Value function: 0.413987
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4619
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 625
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4620
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1369
New value of Q matrix: 0.878782
New value of Value function: 0.878782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4622
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0
New value of Value function: 0.878782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4623
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 154
New value of Q matrix: 0.553126
New value of Value function: 0.878782
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4624
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4625
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 0.465707
New value of Value function: 0.465707
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4626
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4627
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4628
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1370
New value of Q matrix: 0.861207
New value of Value function: 0.861207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0
New value of Value function: 0.861207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1371
New value of Q matrix: 0.843982
New value of Value function: 0.843982
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1372
New value of Q matrix: 0.867103
New value of Value function: 0.867103
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4632
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 627
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4633
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 0.542063
New value of Value function: 0.867103
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1373
New value of Q matrix: 0.889761
New value of Value function: 0.889761
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4636
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4637
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.456393
New value of Value function: 0.456393
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4638
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 0.0506148
New value of Value function: 0.456393
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4639
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.447265
New value of Value function: 0.447265
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1374
New value of Q matrix: 0.871965
New value of Value function: 0.871965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1375
New value of Q matrix: 0.894526
New value of Value function: 0.894526
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4642
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 629
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4643
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 630
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4644
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1376
New value of Q matrix: 0.876636
New value of Value function: 0.876636
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4645
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 0.531222
New value of Value function: 0.876636
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1377
New value of Q matrix: 0.899103
New value of Value function: 0.899103
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4647
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 0.49832
New value of Value function: 0.49832
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4648
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4649
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4650
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1378
New value of Q matrix: 0.881121
New value of Value function: 0.881121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1379
New value of Q matrix: 0.903498
New value of Value function: 0.903498
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4652
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4653
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4654
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1380
New value of Q matrix: 0.885428
New value of Value function: 0.885428
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4655
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1381
New value of Q matrix: 0.90772
New value of Value function: 0.90772
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4656
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 635
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4657
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1382
New value of Q matrix: 0.889566
New value of Value function: 0.889566
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1383
New value of Q matrix: 0.911774
New value of Value function: 0.911774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4660
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4661
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1384
New value of Q matrix: 0.933539
New value of Value function: 0.933539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4663
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 638
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4664
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1385
New value of Q matrix: 0.914868
New value of Value function: 0.914868
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4666
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1386
New value of Q matrix: 0.936571
New value of Value function: 0.936571
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4667
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4668
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 641
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1387
New value of Q matrix: 0.917839
New value of Value function: 0.917839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1388
New value of Q matrix: 0.939482
New value of Value function: 0.939482
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4671
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4672
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4673
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 643
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4674
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4675
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1389
New value of Q matrix: 0.920693
New value of Value function: 0.920693
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0
New value of Value function: 0.920693
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1390
New value of Q matrix: 0.942279
New value of Value function: 0.942279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4678
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4679
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0.49832
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4680
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 0.377874
New value of Value function: 0.377874
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4681
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4682
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176424
New value of Value function: 0.176424
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4683
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 645
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4684
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4685
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4686
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1391
New value of Q matrix: 0.923433
New value of Value function: 0.923433
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4687
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1392
New value of Q matrix: 0.944965
New value of Value function: 0.944965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4688
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4689
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4690
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 649
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4691
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1393
New value of Q matrix: 0.926065
New value of Value function: 0.926065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4693
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 157
New value of Q matrix: 0.560597
New value of Value function: 0.926065
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4694
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4695
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4696
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1394
New value of Q matrix: 0.907544
New value of Value function: 0.907544
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1395
New value of Q matrix: 0.929393
New value of Value function: 0.929393
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4698
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4699
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1396
New value of Q matrix: 0.910805
New value of Value function: 0.910805
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1397
New value of Q matrix: 0.932589
New value of Value function: 0.932589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4702
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4703
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4704
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0
New value of Value function: 0.932589
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1398
New value of Q matrix: 0.913937
New value of Value function: 0.913937
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0
New value of Value function: 0.913937
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1399
New value of Q matrix: 0.895659
New value of Value function: 0.895659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0
New value of Value function: 0.895659
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1400
New value of Q matrix: 0.877745
New value of Value function: 0.877745
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1401
New value of Q matrix: 0.900191
New value of Value function: 0.900191
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4711
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4712
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 652
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4713
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1402
New value of Q matrix: 0.882187
New value of Value function: 0.882187
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4714
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1403
New value of Q matrix: 0.904543
New value of Value function: 0.904543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4715
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4716
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4717
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4718
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0
New value of Value function: 0.904543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1404
New value of Q matrix: 0.886452
New value of Value function: 0.886452
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1405
New value of Q matrix: 0.908723
New value of Value function: 0.908723
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4722
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 656
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4723
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 657
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0
New value of Value function: 0.908723
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1406
New value of Q matrix: 0.890549
New value of Value function: 0.890549
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1407
New value of Q matrix: 0.872738
New value of Value function: 0.872738
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1408
New value of Q matrix: 0.855283
New value of Value function: 0.855283
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1409
New value of Q matrix: 0.878177
New value of Value function: 0.878177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4729
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4730
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 659
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 0.549386
New value of Value function: 0.878177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4732
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1410
New value of Q matrix: 0.900614
New value of Value function: 0.900614
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4733
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4734
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4735
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1411
New value of Q matrix: 0.882601
New value of Value function: 0.882601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1412
New value of Q matrix: 0.904949
New value of Value function: 0.904949
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4737
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 662
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4738
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4739
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1413
New value of Q matrix: 0.88685
New value of Value function: 0.88685
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4740
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1414
New value of Q matrix: 0.909113
New value of Value function: 0.909113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4741
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4742
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 0
New value of Value function: 0.909113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1415
New value of Q matrix: 0.890931
New value of Value function: 0.890931
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4745
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1416
New value of Q matrix: 0.913113
New value of Value function: 0.913113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4746
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4747
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 666
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 0.538398
New value of Value function: 0.913113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4749
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0
New value of Value function: 0.913113
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1417
New value of Q matrix: 0.93485
New value of Value function: 0.93485
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4751
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.488354
New value of Value function: 0.488354
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4752
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.478587
New value of Value function: 0.478587
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1418
New value of Q matrix: 0.916153
New value of Value function: 0.916153
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1419
New value of Q matrix: 0.93783
New value of Value function: 0.93783
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4755
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4756
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1420
New value of Q matrix: 0.919074
New value of Value function: 0.919074
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1421
New value of Q matrix: 0.940692
New value of Value function: 0.940692
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4759
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 668
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4760
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1422
New value of Q matrix: 0.921878
New value of Value function: 0.921878
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1423
New value of Q matrix: 0.943441
New value of Value function: 0.943441
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4763
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 670
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4764
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4765
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1424
New value of Q matrix: 0.924572
New value of Value function: 0.924572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4766
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1425
New value of Q matrix: 0.94608
New value of Value function: 0.94608
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4767
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4768
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4769
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 0.52763
New value of Value function: 0.94608
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4770
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1426
New value of Q matrix: 0.967159
New value of Value function: 0.967159
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4771
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 674
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4772
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1427
New value of Q matrix: 0.947816
New value of Value function: 0.947816
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1428
New value of Q matrix: 0.968859
New value of Value function: 0.968859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4775
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 676
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4776
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 677
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4777
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1429
New value of Q matrix: 0.949482
New value of Value function: 0.949482
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1430
New value of Q matrix: 0.970493
New value of Value function: 0.970493
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4779
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 678
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4780
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 679
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4781
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1431
New value of Q matrix: 0.951083
New value of Value function: 0.951083
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4782
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0
New value of Value function: 0.951083
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4783
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1432
New value of Q matrix: 0.972061
New value of Value function: 0.972061
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4784
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 680
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4785
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 681
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1433
New value of Q matrix: 0.95262
New value of Value function: 0.95262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0
New value of Value function: 0.95262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4788
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1434
New value of Q matrix: 0.973567
New value of Value function: 0.973567
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4789
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4790
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4791
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4792
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0588
New value of Value function: 0.0588
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4793
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.117624
New value of Value function: 0.117624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4794
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4795
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 684
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1435
New value of Q matrix: 0.954096
New value of Value function: 0.954096
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 161
New value of Q matrix: 0.557077
New value of Value function: 0.954096
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4798
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.117624
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4799
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 0.529015
New value of Value function: 0.529015
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4800
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4801
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 686
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4802
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1436
New value of Q matrix: 0.935014
New value of Value function: 0.935014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4803
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0
New value of Value function: 0.935014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0
New value of Value function: 0.935014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1437
New value of Q matrix: 0.916314
New value of Value function: 0.916314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4806
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1438
New value of Q matrix: 0.937988
New value of Value function: 0.937988
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4807
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4808
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1439
New value of Q matrix: 0.919228
New value of Value function: 0.919228
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1440
New value of Q matrix: 0.940843
New value of Value function: 0.940843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4811
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 689
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4812
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4813
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1441
New value of Q matrix: 0.922026
New value of Value function: 0.922026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4814
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1442
New value of Q matrix: 0.943586
New value of Value function: 0.943586
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4815
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 691
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4816
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4817
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4818
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 693
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1443
New value of Q matrix: 0.924714
New value of Value function: 0.924714
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1444
New value of Q matrix: 0.94622
New value of Value function: 0.94622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4821
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4822
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4823
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 695
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4824
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0
New value of Value function: 0.94622
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1445
New value of Q matrix: 0.927295
New value of Value function: 0.927295
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4827
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1446
New value of Q matrix: 0.94875
New value of Value function: 0.94875
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4828
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4829
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 697
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4830
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1447
New value of Q matrix: 0.929775
New value of Value function: 0.929775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4831
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 162
New value of Q matrix: 0.585936
New value of Value function: 0.929775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4832
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4833
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4834
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 699
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4835
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1448
New value of Q matrix: 0.911179
New value of Value function: 0.911179
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 0
New value of Value function: 0.911179
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1449
New value of Q matrix: 0.892956
New value of Value function: 0.892956
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1450
New value of Q matrix: 0.915096
New value of Value function: 0.915096
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4839
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4840
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 701
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0
New value of Value function: 0.915096
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1451
New value of Q matrix: 0.896794
New value of Value function: 0.896794
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0
New value of Value function: 0.896794
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1452
New value of Q matrix: 0.878859
New value of Value function: 0.878859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4845
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1453
New value of Q matrix: 0.901281
New value of Value function: 0.901281
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4846
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4847
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4848
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1454
New value of Q matrix: 0.883256
New value of Value function: 0.883256
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4849
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1455
New value of Q matrix: 0.865591
New value of Value function: 0.865591
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1456
New value of Q matrix: 0.888279
New value of Value function: 0.888279
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4851
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4852
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 703
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4853
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4854
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1457
New value of Q matrix: 0.870513
New value of Value function: 0.870513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4855
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0
New value of Value function: 0.870513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4856
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0
New value of Value function: 0.870513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4857
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0
New value of Value function: 0.870513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1458
New value of Q matrix: 0.853103
New value of Value function: 0.853103
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1459
New value of Q matrix: 0.876041
New value of Value function: 0.876041
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4860
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 705
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4861
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 706
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1460
New value of Q matrix: 0.85852
New value of Value function: 0.85852
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1461
New value of Q matrix: 0.88135
New value of Value function: 0.88135
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4864
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4865
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1462
New value of Q matrix: 0.903723
New value of Value function: 0.903723
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4867
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4868
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 709
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4869
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1463
New value of Q matrix: 0.885648
New value of Value function: 0.885648
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0
New value of Value function: 0.885648
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1464
New value of Q matrix: 0.907935
New value of Value function: 0.907935
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4872
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4873
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1465
New value of Q matrix: 0.929777
New value of Value function: 0.929777
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4875
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4876
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4877
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 711
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4878
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4879
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4880
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 713
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4881
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1466
New value of Q matrix: 0.951181
New value of Value function: 0.951181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4883
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4884
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4885
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 715
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4886
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 716
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0
New value of Value function: 0.951181
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1467
New value of Q matrix: 0.932157
New value of Value function: 0.932157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1468
New value of Q matrix: 0.953514
New value of Value function: 0.953514
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4890
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4891
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4892
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4893
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4894
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1469
New value of Q matrix: 0.934444
New value of Value function: 0.934444
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1470
New value of Q matrix: 0.955755
New value of Value function: 0.955755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4896
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 720
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4897
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4898
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1471
New value of Q matrix: 0.93664
New value of Value function: 0.93664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1472
New value of Q matrix: 0.957907
New value of Value function: 0.957907
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4900
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4901
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4902
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4903
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4904
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4905
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4906
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4907
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 726
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4908
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1473
New value of Q matrix: 0.938749
New value of Value function: 0.938749
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4909
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1474
New value of Q matrix: 0.959974
New value of Value function: 0.959974
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4910
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4911
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 727
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4912
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 728
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4913
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1475
New value of Q matrix: 0.940775
New value of Value function: 0.940775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4914
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 163
New value of Q matrix: 0.614217
New value of Value function: 0.940775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4915
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4916
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 0.578435
New value of Value function: 0.578435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4917
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 729
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4918
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 730
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4919
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1476
New value of Q matrix: 0.921959
New value of Value function: 0.921959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4920
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1477
New value of Q matrix: 0.94352
New value of Value function: 0.94352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4921
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 731
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4922
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4923
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0.578435
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4924
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.566866
New value of Value function: 0.566866
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4925
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.555529
New value of Value function: 0.555529
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4926
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1478
New value of Q matrix: 0.92465
New value of Value function: 0.92465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4927
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1479
New value of Q matrix: 0.946157
New value of Value function: 0.946157
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4928
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 732
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4929
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4930
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 733
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4931
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 734
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4932
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1480
New value of Q matrix: 0.927233
New value of Value function: 0.927233
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4933
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1481
New value of Q matrix: 0.948689
New value of Value function: 0.948689
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4934
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 735
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4935
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 736
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4936
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1482
New value of Q matrix: 0.929715
New value of Value function: 0.929715
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4937
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1483
New value of Q matrix: 0.951121
New value of Value function: 0.951121
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4938
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 737
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4939
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1484
New value of Q matrix: 0.932098
New value of Value function: 0.932098
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1485
New value of Q matrix: 0.953456
New value of Value function: 0.953456
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4942
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 739
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4943
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4944
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1486
New value of Q matrix: 0.934387
New value of Value function: 0.934387
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 164
New value of Q matrix: 0.641933
New value of Value function: 0.934387
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4946
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4947
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4948
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1487
New value of Q matrix: 0.915699
New value of Value function: 0.915699
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1488
New value of Q matrix: 0.937385
New value of Value function: 0.937385
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4950
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4951
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4952
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.544418
New value of Value function: 0.544418
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4953
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.53353
New value of Value function: 0.53353
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1489
New value of Q matrix: 0.918638
New value of Value function: 0.918638
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4955
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1490
New value of Q matrix: 0.940265
New value of Value function: 0.940265
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4956
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4957
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4958
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4959
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4960
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1491
New value of Q matrix: 0.92146
New value of Value function: 0.92146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1492
New value of Q matrix: 0.94303
New value of Value function: 0.94303
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4963
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4964
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4965
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1493
New value of Q matrix: 0.92417
New value of Value function: 0.92417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4966
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0.629094
New value of Value function: 0.92417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1494
New value of Q matrix: 0.945686
New value of Value function: 0.945686
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4968
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 0.582859
New value of Value function: 0.582859
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 4969
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4970
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1495
New value of Q matrix: 0.926773
New value of Value function: 0.926773
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0
New value of Value function: 0.926773
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4973
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1496
New value of Q matrix: 0.908237
New value of Value function: 0.908237
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4974
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0
New value of Value function: 0.908237
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4975
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1497
New value of Q matrix: 0.930073
New value of Value function: 0.930073
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4976
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 742
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4977
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4978
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4979
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4980
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0.616512
New value of Value function: 0.930073
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1498
New value of Q matrix: 0.911471
New value of Value function: 0.911471
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4983
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0
New value of Value function: 0.911471
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4984
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1499
New value of Q matrix: 0.933242
New value of Value function: 0.933242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4985
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4986
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4987
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1500
New value of Q matrix: 0.914577
New value of Value function: 0.914577
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4988
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1501
New value of Q matrix: 0.936285
New value of Value function: 0.936285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4989
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4990
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1502
New value of Q matrix: 0.91756
New value of Value function: 0.91756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1503
New value of Q matrix: 0.939208
New value of Value function: 0.939208
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4993
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4994
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4995
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1504
New value of Q matrix: 0.960424
New value of Value function: 0.960424
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4996
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4997
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1505
New value of Q matrix: 0.941216
New value of Value function: 0.941216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 4999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 0
New value of Value function: 0.941216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5000
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 0
New value of Value function: 0.941216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5001
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1506
New value of Q matrix: 0.922391
New value of Value function: 0.922391
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5002
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1507
New value of Q matrix: 0.903944
New value of Value function: 0.903944
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1508
New value of Q matrix: 0.925865
New value of Value function: 0.925865
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5004
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5005
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5006
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1509
New value of Q matrix: 0.907347
New value of Value function: 0.907347
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5007
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 0
New value of Value function: 0.907347
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5008
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1510
New value of Q matrix: 0.889201
New value of Value function: 0.889201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5009
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1511
New value of Q matrix: 0.911416
New value of Value function: 0.911416
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5010
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5011
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5012
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1512
New value of Q matrix: 0.893188
New value of Value function: 0.893188
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5013
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1513
New value of Q matrix: 0.915324
New value of Value function: 0.915324
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5014
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5015
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5016
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1514
New value of Q matrix: 0.897018
New value of Value function: 0.897018
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5017
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1515
New value of Q matrix: 0.919078
New value of Value function: 0.919078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5018
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5019
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5020
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1516
New value of Q matrix: 0.940696
New value of Value function: 0.940696
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5021
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5022
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5023
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1517
New value of Q matrix: 0.961882
New value of Value function: 0.961882
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5024
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 0.631202
New value of Value function: 0.631202
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5025
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5026
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5027
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1518
New value of Q matrix: 0.942644
New value of Value function: 0.942644
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5028
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1519
New value of Q matrix: 0.963792
New value of Value function: 0.963792
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5029
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5030
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5031
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1520
New value of Q matrix: 0.944516
New value of Value function: 0.944516
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5032
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1521
New value of Q matrix: 0.965625
New value of Value function: 0.965625
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5033
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5034
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5035
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0
New value of Value function: 0.965625
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5036
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1522
New value of Q matrix: 0.946313
New value of Value function: 0.946313
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5037
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1523
New value of Q matrix: 0.967387
New value of Value function: 0.967387
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5038
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5039
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5040
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5041
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1524
New value of Q matrix: 0.948039
New value of Value function: 0.948039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5042
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1525
New value of Q matrix: 0.969078
New value of Value function: 0.969078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5043
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5044
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5045
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1526
New value of Q matrix: 0.949697
New value of Value function: 0.949697
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5046
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1527
New value of Q matrix: 0.970703
New value of Value function: 0.970703
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5047
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5048
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5049
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0.604182
New value of Value function: 0.970703
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5050
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1528
New value of Q matrix: 0.991289
New value of Value function: 0.991289
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5051
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5052
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5053
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 0
New value of Value function: 0.991289
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5054
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1529
New value of Q matrix: 0.971463
New value of Value function: 0.971463
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5055
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1530
New value of Q matrix: 0.952034
New value of Value function: 0.952034
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5056
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1531
New value of Q matrix: 0.972993
New value of Value function: 0.972993
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5057
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 743
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5058
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5059
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1532
New value of Q matrix: 0.953533
New value of Value function: 0.953533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5060
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1533
New value of Q matrix: 0.974462
New value of Value function: 0.974462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5061
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 744
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5062
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 745
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5063
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1534
New value of Q matrix: 0.954973
New value of Value function: 0.954973
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5064
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1535
New value of Q matrix: 0.975874
New value of Value function: 0.975874
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5065
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 746
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5066
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 747
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5067
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1536
New value of Q matrix: 0.956356
New value of Value function: 0.956356
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5068
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1537
New value of Q matrix: 0.977229
New value of Value function: 0.977229
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5069
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5070
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 748
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5071
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1538
New value of Q matrix: 0.957684
New value of Value function: 0.957684
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5072
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1539
New value of Q matrix: 0.938531
New value of Value function: 0.938531
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5073
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1540
New value of Q matrix: 0.95976
New value of Value function: 0.95976
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5074
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 749
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5075
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 750
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5076
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0
New value of Value function: 0.95976
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5077
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 0
New value of Value function: 0.95976
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5078
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1541
New value of Q matrix: 0.940565
New value of Value function: 0.940565
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0
New value of Value function: 0.940565
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1542
New value of Q matrix: 0.921754
New value of Value function: 0.921754
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5081
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1543
New value of Q matrix: 0.943319
New value of Value function: 0.943319
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5082
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5083
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 752
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1544
New value of Q matrix: 0.924452
New value of Value function: 0.924452
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1545
New value of Q matrix: 0.945963
New value of Value function: 0.945963
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5086
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 753
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5087
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 754
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5088
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1546
New value of Q matrix: 0.927044
New value of Value function: 0.927044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1547
New value of Q matrix: 0.948503
New value of Value function: 0.948503
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5090
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 755
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5091
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5092
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1548
New value of Q matrix: 0.929533
New value of Value function: 0.929533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5093
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1549
New value of Q matrix: 0.950942
New value of Value function: 0.950942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5094
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 757
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5095
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 758
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1550
New value of Q matrix: 0.931923
New value of Value function: 0.931923
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5097
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1551
New value of Q matrix: 0.953285
New value of Value function: 0.953285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5098
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 759
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5099
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 760
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1552
New value of Q matrix: 0.934219
New value of Value function: 0.934219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0
New value of Value function: 0.934219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1553
New value of Q matrix: 0.915535
New value of Value function: 0.915535
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1554
New value of Q matrix: 0.937224
New value of Value function: 0.937224
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5104
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5105
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1555
New value of Q matrix: 0.95848
New value of Value function: 0.95848
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5107
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 761
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5108
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1556
New value of Q matrix: 0.97931
New value of Value function: 0.97931
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5110
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 762
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5111
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 763
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1557
New value of Q matrix: 0.959724
New value of Value function: 0.959724
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1558
New value of Q matrix: 0.980529
New value of Value function: 0.980529
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5114
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 764
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5115
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 765
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0
New value of Value function: 0.980529
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1559
New value of Q matrix: 0.960919
New value of Value function: 0.960919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 0
New value of Value function: 0.960919
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1560
New value of Q matrix: 0.9417
New value of Value function: 0.9417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0
New value of Value function: 0.9417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0
New value of Value function: 0.9417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1561
New value of Q matrix: 0.922866
New value of Value function: 0.922866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1562
New value of Q matrix: 0.944409
New value of Value function: 0.944409
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5124
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 766
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5125
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 767
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1563
New value of Q matrix: 0.925521
New value of Value function: 0.925521
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1564
New value of Q matrix: 0.947011
New value of Value function: 0.947011
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5128
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5129
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 768
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5130
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 769
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1565
New value of Q matrix: 0.92807
New value of Value function: 0.92807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0
New value of Value function: 0.92807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1566
New value of Q matrix: 0.949509
New value of Value function: 0.949509
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5134
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 770
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5135
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 771
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 0
New value of Value function: 0.949509
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1567
New value of Q matrix: 0.930519
New value of Value function: 0.930519
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1568
New value of Q matrix: 0.911908
New value of Value function: 0.911908
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1569
New value of Q matrix: 0.93367
New value of Value function: 0.93367
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5140
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 772
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5141
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 773
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 0.592098
New value of Value function: 0.93367
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1570
New value of Q matrix: 0.954997
New value of Value function: 0.954997
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5144
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 774
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5145
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 775
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1571
New value of Q matrix: 0.935897
New value of Value function: 0.935897
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1572
New value of Q matrix: 0.957179
New value of Value function: 0.957179
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5148
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 776
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5149
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 777
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1573
New value of Q matrix: 0.938035
New value of Value function: 0.938035
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1574
New value of Q matrix: 0.959275
New value of Value function: 0.959275
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5152
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 778
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5153
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5154
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 779
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5155
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 780
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5156
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1575
New value of Q matrix: 0.940089
New value of Value function: 0.940089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1576
New value of Q matrix: 0.961287
New value of Value function: 0.961287
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5159
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 782
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5160
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 783
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1577
New value of Q matrix: 0.942062
New value of Value function: 0.942062
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1578
New value of Q matrix: 0.96322
New value of Value function: 0.96322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5163
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5164
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 784
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5165
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 785
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1579
New value of Q matrix: 0.943956
New value of Value function: 0.943956
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1580
New value of Q matrix: 0.965077
New value of Value function: 0.965077
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5168
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 786
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5169
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 787
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1581
New value of Q matrix: 0.945775
New value of Value function: 0.945775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1582
New value of Q matrix: 0.96686
New value of Value function: 0.96686
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5172
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 788
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5173
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 789
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1583
New value of Q matrix: 0.947523
New value of Value function: 0.947523
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1584
New value of Q matrix: 0.968572
New value of Value function: 0.968572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5176
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 790
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5177
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 791
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1585
New value of Q matrix: 0.949201
New value of Value function: 0.949201
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1586
New value of Q matrix: 0.970217
New value of Value function: 0.970217
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5180
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 792
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5181
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 793
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1587
New value of Q matrix: 0.950812
New value of Value function: 0.950812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1588
New value of Q matrix: 0.971796
New value of Value function: 0.971796
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5184
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5185
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 794
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1589
New value of Q matrix: 0.95236
New value of Value function: 0.95236
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1590
New value of Q matrix: 0.973313
New value of Value function: 0.973313
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5188
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 795
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5189
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 796
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1591
New value of Q matrix: 0.953847
New value of Value function: 0.953847
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1592
New value of Q matrix: 0.97477
New value of Value function: 0.97477
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5192
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 797
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5193
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 798
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1593
New value of Q matrix: 0.955274
New value of Value function: 0.955274
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1594
New value of Q matrix: 0.976169
New value of Value function: 0.976169
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5196
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 799
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5197
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5198
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5199
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5200
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5201
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 0.678578
New value of Value function: 0.678578
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5202
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 800
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5203
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1595
New value of Q matrix: 0.956646
New value of Value function: 0.956646
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1596
New value of Q matrix: 0.977513
New value of Value function: 0.977513
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5206
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 802
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5207
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1597
New value of Q matrix: 0.957962
New value of Value function: 0.957962
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1598
New value of Q matrix: 0.978803
New value of Value function: 0.978803
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5210
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 804
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5211
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 805
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0
New value of Value function: 0.978803
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1599
New value of Q matrix: 0.959227
New value of Value function: 0.959227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1600
New value of Q matrix: 0.940043
New value of Value function: 0.940043
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1601
New value of Q matrix: 0.961242
New value of Value function: 0.961242
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5216
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5217
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5218
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 807
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5219
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 808
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1602
New value of Q matrix: 0.942017
New value of Value function: 0.942017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0
New value of Value function: 0.942017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0
New value of Value function: 0.942017
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1603
New value of Q matrix: 0.923177
New value of Value function: 0.923177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0
New value of Value function: 0.923177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1604
New value of Q matrix: 0.904713
New value of Value function: 0.904713
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1605
New value of Q matrix: 0.926619
New value of Value function: 0.926619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5227
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5228
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5229
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5230
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1606
New value of Q matrix: 0.908086
New value of Value function: 0.908086
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0
New value of Value function: 0.908086
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1607
New value of Q matrix: 0.929925
New value of Value function: 0.929925
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5234
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 812
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5235
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1608
New value of Q matrix: 0.911326
New value of Value function: 0.911326
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1609
New value of Q matrix: 0.9331
New value of Value function: 0.9331
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5238
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 814
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5239
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5240
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.665006
New value of Value function: 0.665006
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5241
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.651706
New value of Value function: 0.651706
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1610
New value of Q matrix: 0.914438
New value of Value function: 0.914438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 169
New value of Q matrix: 0.620256
New value of Value function: 0.914438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5244
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 815
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5245
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1611
New value of Q matrix: 0.896149
New value of Value function: 0.896149
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1612
New value of Q matrix: 0.918226
New value of Value function: 0.918226
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5248
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 816
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5249
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 817
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0
New value of Value function: 0.918226
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1613
New value of Q matrix: 0.899861
New value of Value function: 0.899861
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1614
New value of Q matrix: 0.881864
New value of Value function: 0.881864
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1615
New value of Q matrix: 0.904227
New value of Value function: 0.904227
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5254
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 818
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5255
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5256
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 819
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5257
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 820
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1616
New value of Q matrix: 0.886142
New value of Value function: 0.886142
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1617
New value of Q matrix: 0.908419
New value of Value function: 0.908419
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5260
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 821
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5261
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5262
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5263
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1618
New value of Q matrix: 0.890251
New value of Value function: 0.890251
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1619
New value of Q matrix: 0.912446
New value of Value function: 0.912446
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5266
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 822
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5267
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 823
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1620
New value of Q matrix: 0.894197
New value of Value function: 0.894197
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1621
New value of Q matrix: 0.916313
New value of Value function: 0.916313
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5270
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5271
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.175272
New value of Value function: 0.175272
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5272
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 824
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5273
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 825
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1622
New value of Q matrix: 0.897987
New value of Value function: 0.897987
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1623
New value of Q matrix: 0.920027
New value of Value function: 0.920027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5276
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5277
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5278
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 0.232896
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5279
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5280
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5281
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 0.430316
New value of Value function: 0.430316
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5282
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5283
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 826
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5284
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 827
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5285
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0
New value of Value function: 0.920027
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1624
New value of Q matrix: 0.901627
New value of Value function: 0.901627
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1625
New value of Q matrix: 0.883594
New value of Value function: 0.883594
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1626
New value of Q matrix: 0.865922
New value of Value function: 0.865922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1627
New value of Q matrix: 0.888604
New value of Value function: 0.888604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5291
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 828
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5292
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 829
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 0
New value of Value function: 0.888604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1628
New value of Q matrix: 0.870832
New value of Value function: 0.870832
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1629
New value of Q matrix: 0.853415
New value of Value function: 0.853415
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1630
New value of Q matrix: 0.876347
New value of Value function: 0.876347
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5297
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 830
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5298
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 831
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 170
New value of Q matrix: 0.647851
New value of Value function: 0.876347
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5300
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5301
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 832
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5302
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 833
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1631
New value of Q matrix: 0.85882
New value of Value function: 0.85882
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1632
New value of Q matrix: 0.881643
New value of Value function: 0.881643
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5305
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 834
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5306
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 835
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1633
New value of Q matrix: 0.864011
New value of Value function: 0.864011
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1634
New value of Q matrix: 0.88673
New value of Value function: 0.88673
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5309
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 836
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5310
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 837
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1635
New value of Q matrix: 0.868996
New value of Value function: 0.868996
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1636
New value of Q matrix: 0.891616
New value of Value function: 0.891616
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5313
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5314
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5315
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 838
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5316
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 839
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5317
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 840
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1637
New value of Q matrix: 0.873784
New value of Value function: 0.873784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0
New value of Value function: 0.873784
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1638
New value of Q matrix: 0.896308
New value of Value function: 0.896308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5321
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 841
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5322
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 842
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1639
New value of Q matrix: 0.878382
New value of Value function: 0.878382
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1640
New value of Q matrix: 0.900814
New value of Value function: 0.900814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5325
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 843
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5326
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 844
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1641
New value of Q matrix: 0.882798
New value of Value function: 0.882798
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1642
New value of Q matrix: 0.905142
New value of Value function: 0.905142
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5329
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5330
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1643
New value of Q matrix: 0.887039
New value of Value function: 0.887039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1644
New value of Q matrix: 0.909298
New value of Value function: 0.909298
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5333
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 845
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5334
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 846
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1645
New value of Q matrix: 0.891112
New value of Value function: 0.891112
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1646
New value of Q matrix: 0.91329
New value of Value function: 0.91329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5337
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5338
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 848
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0
New value of Value function: 0.91329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1647
New value of Q matrix: 0.895024
New value of Value function: 0.895024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1648
New value of Q matrix: 0.917124
New value of Value function: 0.917124
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5342
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5343
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 850
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1649
New value of Q matrix: 0.898781
New value of Value function: 0.898781
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1650
New value of Q matrix: 0.920806
New value of Value function: 0.920806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5346
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 851
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5347
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 852
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0
New value of Value function: 0.920806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0
New value of Value function: 0.920806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0
New value of Value function: 0.920806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0
New value of Value function: 0.920806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1651
New value of Q matrix: 0.90239
New value of Value function: 0.90239
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1652
New value of Q matrix: 0.884342
New value of Value function: 0.884342
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1653
New value of Q matrix: 0.866655
New value of Value function: 0.866655
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1654
New value of Q matrix: 0.889322
New value of Value function: 0.889322
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5356
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 853
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5357
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1655
New value of Q matrix: 0.871535
New value of Value function: 0.871535
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1656
New value of Q matrix: 0.894105
New value of Value function: 0.894105
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5360
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5361
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1657
New value of Q matrix: 0.916223
New value of Value function: 0.916223
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5363
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 855
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5364
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 856
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1658
New value of Q matrix: 0.897898
New value of Value function: 0.897898
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0
New value of Value function: 0.897898
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1659
New value of Q matrix: 0.91994
New value of Value function: 0.91994
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5368
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 857
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5369
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 858
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1660
New value of Q matrix: 0.901541
New value of Value function: 0.901541
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1661
New value of Q matrix: 0.923511
New value of Value function: 0.923511
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5372
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5373
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 860
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 0.634894
New value of Value function: 0.923511
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1662
New value of Q matrix: 0.94504
New value of Value function: 0.94504
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5376
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5377
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 862
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1663
New value of Q matrix: 0.926139
New value of Value function: 0.926139
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1664
New value of Q matrix: 0.947617
New value of Value function: 0.947617
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5380
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5381
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 863
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5382
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5383
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 864
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5384
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 865
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1665
New value of Q matrix: 0.928664
New value of Value function: 0.928664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1666
New value of Q matrix: 0.950091
New value of Value function: 0.950091
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5387
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 866
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5388
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 867
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1667
New value of Q matrix: 0.931089
New value of Value function: 0.931089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 0
New value of Value function: 0.931089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 0.622196
New value of Value function: 0.931089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1668
New value of Q matrix: 0.952467
New value of Value function: 0.952467
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5393
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 868
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5394
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 869
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1669
New value of Q matrix: 0.933418
New value of Value function: 0.933418
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1670
New value of Q matrix: 0.95475
New value of Value function: 0.95475
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5397
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5398
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5399
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1671
New value of Q matrix: 0.935655
New value of Value function: 0.935655
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0
New value of Value function: 0.935655
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1672
New value of Q matrix: 0.916942
New value of Value function: 0.916942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5403
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0
New value of Value function: 0.916942
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5404
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1673
New value of Q matrix: 0.898603
New value of Value function: 0.898603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5405
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 0
New value of Value function: 0.898603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1674
New value of Q matrix: 0.880631
New value of Value function: 0.880631
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1675
New value of Q matrix: 0.903018
New value of Value function: 0.903018
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5408
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5409
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1676
New value of Q matrix: 0.924958
New value of Value function: 0.924958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5411
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 873
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5412
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1677
New value of Q matrix: 0.906459
New value of Value function: 0.906459
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1678
New value of Q matrix: 0.928329
New value of Value function: 0.928329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5415
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 875
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5416
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 876
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 0
New value of Value function: 0.928329
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1679
New value of Q matrix: 0.909763
New value of Value function: 0.909763
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0
New value of Value function: 0.909763
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1680
New value of Q matrix: 0.891568
New value of Value function: 0.891568
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0
New value of Value function: 0.891568
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1681
New value of Q matrix: 0.873736
New value of Value function: 0.873736
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1682
New value of Q matrix: 0.856262
New value of Value function: 0.856262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0
New value of Value function: 0.856262
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1683
New value of Q matrix: 0.839136
New value of Value function: 0.839136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1684
New value of Q matrix: 0.862354
New value of Value function: 0.862354
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5427
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 877
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5428
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 878
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0
New value of Value function: 0.862354
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0
New value of Value function: 0.862354
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1685
New value of Q matrix: 0.845107
New value of Value function: 0.845107
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0
New value of Value function: 0.845107
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1686
New value of Q matrix: 0.828204
New value of Value function: 0.828204
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1687
New value of Q matrix: 0.85164
New value of Value function: 0.85164
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5435
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5436
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 880
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0
New value of Value function: 0.85164
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1688
New value of Q matrix: 0.834607
New value of Value function: 0.834607
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1689
New value of Q matrix: 0.817915
New value of Value function: 0.817915
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1690
New value of Q matrix: 0.841557
New value of Value function: 0.841557
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5441
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 881
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5442
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 882
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1691
New value of Q matrix: 0.824726
New value of Value function: 0.824726
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0
New value of Value function: 0.824726
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1692
New value of Q matrix: 0.808231
New value of Value function: 0.808231
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1693
New value of Q matrix: 0.832067
New value of Value function: 0.832067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5447
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5448
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5449
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 883
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5450
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5451
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 885
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1694
New value of Q matrix: 0.815425
New value of Value function: 0.815425
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1695
New value of Q matrix: 0.839117
New value of Value function: 0.839117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5454
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5455
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 887
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 0.609752
New value of Value function: 0.839117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1696
New value of Q matrix: 0.862335
New value of Value function: 0.862335
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5458
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5459
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5460
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5461
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1697
New value of Q matrix: 0.845088
New value of Value function: 0.845088
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 174
New value of Q matrix: 0.637557
New value of Value function: 0.845088
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5464
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 890
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5465
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5466
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 892
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 0.624806
New value of Value function: 0.845088
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1698
New value of Q matrix: 0.868186
New value of Value function: 0.868186
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5469
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5470
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 894
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0
New value of Value function: 0.868186
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0
New value of Value function: 0.868186
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1699
New value of Q matrix: 0.850822
New value of Value function: 0.850822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1700
New value of Q matrix: 0.833806
New value of Value function: 0.833806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1701
New value of Q matrix: 0.81713
New value of Value function: 0.81713
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 176
New value of Q matrix: 0.65231
New value of Value function: 0.81713
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5477
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5478
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 896
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1702
New value of Q matrix: 0.800787
New value of Value function: 0.800787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 177
New value of Q matrix: 0.679264
New value of Value function: 0.800787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5481
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5482
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1703
New value of Q matrix: 0.784771
New value of Value function: 0.784771
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 178
New value of Q matrix: 0.705679
New value of Value function: 0.784771
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5485
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5486
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 0.698672
New value of Value function: 0.698672
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5487
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 898
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5488
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1704
New value of Q matrix: 0.769076
New value of Value function: 0.769076
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1705
New value of Q matrix: 0.793695
New value of Value function: 0.793695
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5491
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5492
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.684699
New value of Value function: 0.684699
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5493
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.671005
New value of Value function: 0.671005
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1706
New value of Q matrix: 0.777821
New value of Value function: 0.777821
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1707
New value of Q matrix: 0.802264
New value of Value function: 0.802264
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5496
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 900
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5497
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5498
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5499
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 902
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1708
New value of Q matrix: 0.786219
New value of Value function: 0.786219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1709
New value of Q matrix: 0.810495
New value of Value function: 0.810495
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5502
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5503
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 904
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1710
New value of Q matrix: 0.794285
New value of Value function: 0.794285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0
New value of Value function: 0.794285
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1711
New value of Q matrix: 0.778399
New value of Value function: 0.778399
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1712
New value of Q matrix: 0.802831
New value of Value function: 0.802831
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5508
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5509
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5510
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 906
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5511
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1713
New value of Q matrix: 0.786774
New value of Value function: 0.786774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5512
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0
New value of Value function: 0.786774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0
New value of Value function: 0.786774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5514
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1714
New value of Q matrix: 0.771039
New value of Value function: 0.771039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5515
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1715
New value of Q matrix: 0.755618
New value of Value function: 0.755618
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5516
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1716
New value of Q matrix: 0.780506
New value of Value function: 0.780506
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5517
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5518
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5519
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0
New value of Value function: 0.780506
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5520
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1717
New value of Q matrix: 0.804896
New value of Value function: 0.804896
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5521
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 908
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5522
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5523
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1718
New value of Q matrix: 0.788798
New value of Value function: 0.788798
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5524
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1719
New value of Q matrix: 0.813022
New value of Value function: 0.813022
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5525
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 910
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5526
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1720
New value of Q matrix: 0.836761
New value of Value function: 0.836761
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5528
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5529
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1721
New value of Q matrix: 0.860026
New value of Value function: 0.860026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5531
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5532
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 913
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 0
New value of Value function: 0.860026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1722
New value of Q matrix: 0.842826
New value of Value function: 0.842826
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1723
New value of Q matrix: 0.825969
New value of Value function: 0.825969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1724
New value of Q matrix: 0.84945
New value of Value function: 0.84945
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5537
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5538
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5539
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5540
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 916
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 0.691565
New value of Value function: 0.84945
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1725
New value of Q matrix: 0.872461
New value of Value function: 0.872461
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5543
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5544
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5545
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 918
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5546
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0
New value of Value function: 0.872461
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1726
New value of Q matrix: 0.855011
New value of Value function: 0.855011
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 0.677734
New value of Value function: 0.855011
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1727
New value of Q matrix: 0.877911
New value of Value function: 0.877911
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5551
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5552
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 921
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1728
New value of Q matrix: 0.860353
New value of Value function: 0.860353
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1729
New value of Q matrix: 0.883146
New value of Value function: 0.883146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5555
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5556
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 922
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5557
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5558
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5559
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0
New value of Value function: 0.883146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 0.664179
New value of Value function: 0.883146
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1730
New value of Q matrix: 0.865483
New value of Value function: 0.865483
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1731
New value of Q matrix: 0.888173
New value of Value function: 0.888173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5564
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5565
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 926
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5566
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 0.650895
New value of Value function: 0.888173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1732
New value of Q matrix: 0.91041
New value of Value function: 0.91041
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5568
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.657585
New value of Value function: 0.657585
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5569
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.644433
New value of Value function: 0.644433
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1733
New value of Q matrix: 0.892202
New value of Value function: 0.892202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0
New value of Value function: 0.892202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 0
New value of Value function: 0.892202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0
New value of Value function: 0.892202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0
New value of Value function: 0.892202
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1734
New value of Q matrix: 0.874358
New value of Value function: 0.874358
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0
New value of Value function: 0.874358
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1735
New value of Q matrix: 0.856871
New value of Value function: 0.856871
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 0
New value of Value function: 0.856871
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 0.637877
New value of Value function: 0.856871
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1736
New value of Q matrix: 0.839733
New value of Value function: 0.839733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1737
New value of Q matrix: 0.822938
New value of Value function: 0.822938
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1738
New value of Q matrix: 0.84648
New value of Value function: 0.84648
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5583
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5584
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5585
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5586
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5587
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 928
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5588
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1739
New value of Q matrix: 0.82955
New value of Value function: 0.82955
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5590
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1740
New value of Q matrix: 0.852959
New value of Value function: 0.852959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5591
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5592
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 930
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5593
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5594
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 932
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1741
New value of Q matrix: 0.8359
New value of Value function: 0.8359
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1742
New value of Q matrix: 0.859182
New value of Value function: 0.859182
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5597
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5598
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 934
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5599
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1743
New value of Q matrix: 0.841998
New value of Value function: 0.841998
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5600
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1744
New value of Q matrix: 0.865158
New value of Value function: 0.865158
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5601
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5602
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1745
New value of Q matrix: 0.847855
New value of Value function: 0.847855
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1746
New value of Q matrix: 0.870898
New value of Value function: 0.870898
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5605
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 937
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5606
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5607
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1747
New value of Q matrix: 0.85348
New value of Value function: 0.85348
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5608
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0
New value of Value function: 0.85348
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5609
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1748
New value of Q matrix: 0.83641
New value of Value function: 0.83641
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5610
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1749
New value of Q matrix: 0.859682
New value of Value function: 0.859682
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5611
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5612
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 939
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5613
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1750
New value of Q matrix: 0.842489
New value of Value function: 0.842489
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5614
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1751
New value of Q matrix: 0.865639
New value of Value function: 0.865639
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5615
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5616
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5617
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1752
New value of Q matrix: 0.848326
New value of Value function: 0.848326
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5618
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1753
New value of Q matrix: 0.83136
New value of Value function: 0.83136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5619
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0
New value of Value function: 0.83136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5620
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0
New value of Value function: 0.83136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5621
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 184
New value of Q matrix: 0.66512
New value of Value function: 0.83136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5622
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5623
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5624
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 942
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5625
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5626
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 943
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5627
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 944
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5628
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5629
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0
New value of Value function: 0.83136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5630
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1754
New value of Q matrix: 0.814732
New value of Value function: 0.814732
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5631
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1755
New value of Q matrix: 0.798438
New value of Value function: 0.798438
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5632
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1756
New value of Q matrix: 0.782469
New value of Value function: 0.782469
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5633
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0
New value of Value function: 0.782469
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5634
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1757
New value of Q matrix: 0.76682
New value of Value function: 0.76682
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5635
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1758
New value of Q matrix: 0.791483
New value of Value function: 0.791483
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5636
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5637
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5638
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5639
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 946
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5640
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1759
New value of Q matrix: 0.775654
New value of Value function: 0.775654
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5641
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1760
New value of Q matrix: 0.80014
New value of Value function: 0.80014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5642
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5643
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5644
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5645
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 949
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5646
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0
New value of Value function: 0.80014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5647
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1761
New value of Q matrix: 0.784138
New value of Value function: 0.784138
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5648
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1762
New value of Q matrix: 0.808455
New value of Value function: 0.808455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5649
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5650
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5651
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0
New value of Value function: 0.808455
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1763
New value of Q matrix: 0.792286
New value of Value function: 0.792286
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5653
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1764
New value of Q matrix: 0.81644
New value of Value function: 0.81644
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5654
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5655
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5656
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5657
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 953
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5658
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1765
New value of Q matrix: 0.800111
New value of Value function: 0.800111
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5659
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1766
New value of Q matrix: 0.824109
New value of Value function: 0.824109
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5660
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5661
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 955
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5662
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1767
New value of Q matrix: 0.807627
New value of Value function: 0.807627
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5663
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 0
New value of Value function: 0.807627
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5664
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1768
New value of Q matrix: 0.791474
New value of Value function: 0.791474
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5665
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1769
New value of Q matrix: 0.815645
New value of Value function: 0.815645
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5666
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5667
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 957
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5668
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0
New value of Value function: 0.815645
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5669
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1770
New value of Q matrix: 0.799332
New value of Value function: 0.799332
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5670
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1771
New value of Q matrix: 0.823345
New value of Value function: 0.823345
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5671
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5672
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5673
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 959
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5674
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 960
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5675
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 961
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5676
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1772
New value of Q matrix: 0.806878
New value of Value function: 0.806878
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5677
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1773
New value of Q matrix: 0.830741
New value of Value function: 0.830741
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5678
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5679
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5680
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5681
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 962
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5682
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 963
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5683
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 964
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5684
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1774
New value of Q matrix: 0.814126
New value of Value function: 0.814126
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5685
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1775
New value of Q matrix: 0.837844
New value of Value function: 0.837844
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5686
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5687
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5688
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5689
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5690
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1776
New value of Q matrix: 0.821087
New value of Value function: 0.821087
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5691
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1777
New value of Q matrix: 0.804665
New value of Value function: 0.804665
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5692
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1778
New value of Q matrix: 0.828572
New value of Value function: 0.828572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5693
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5694
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 965
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5695
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5696
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 966
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5697
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 967
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5698
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5699
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 968
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5700
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 969
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5701
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1779
New value of Q matrix: 0.812
New value of Value function: 0.812
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5702
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1780
New value of Q matrix: 0.83576
New value of Value function: 0.83576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5703
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 970
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5704
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 971
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5705
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0
New value of Value function: 0.83576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5706
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 0
New value of Value function: 0.83576
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5707
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1781
New value of Q matrix: 0.819045
New value of Value function: 0.819045
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5708
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1782
New value of Q matrix: 0.802664
New value of Value function: 0.802664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5709
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1783
New value of Q matrix: 0.786611
New value of Value function: 0.786611
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5710
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1784
New value of Q matrix: 0.810879
New value of Value function: 0.810879
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5711
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5712
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 972
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5713
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5714
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 973
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5715
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5716
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 974
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5717
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 975
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5718
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 0
New value of Value function: 0.810879
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5719
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1785
New value of Q matrix: 0.794661
New value of Value function: 0.794661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5720
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1786
New value of Q matrix: 0.778768
New value of Value function: 0.778768
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1787
New value of Q matrix: 0.803192
New value of Value function: 0.803192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5722
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5723
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 976
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5724
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0
New value of Value function: 0.803192
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5725
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1788
New value of Q matrix: 0.787129
New value of Value function: 0.787129
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1789
New value of Q matrix: 0.771386
New value of Value function: 0.771386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0
New value of Value function: 0.771386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5728
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1790
New value of Q matrix: 0.755958
New value of Value function: 0.755958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5729
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 0.651818
New value of Value function: 0.755958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1791
New value of Q matrix: 0.780839
New value of Value function: 0.780839
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5731
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 977
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5732
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 978
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1792
New value of Q matrix: 0.765222
New value of Value function: 0.765222
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1793
New value of Q matrix: 0.789918
New value of Value function: 0.789918
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5735
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 979
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5736
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 980
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5737
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1794
New value of Q matrix: 0.77412
New value of Value function: 0.77412
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5738
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1795
New value of Q matrix: 0.798637
New value of Value function: 0.798637
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5739
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 981
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5740
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5741
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5742
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 982
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5743
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1796
New value of Q matrix: 0.782664
New value of Value function: 0.782664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5744
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 186
New value of Q matrix: 0.678781
New value of Value function: 0.782664
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5745
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 983
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5746
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5747
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1797
New value of Q matrix: 0.767011
New value of Value function: 0.767011
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5748
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1798
New value of Q matrix: 0.791671
New value of Value function: 0.791671
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5749
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 984
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5750
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 985
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1799
New value of Q matrix: 0.775837
New value of Value function: 0.775837
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5752
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1800
New value of Q matrix: 0.800321
New value of Value function: 0.800321
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5753
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 986
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5754
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 987
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1801
New value of Q matrix: 0.784314
New value of Value function: 0.784314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0
New value of Value function: 0.784314
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1802
New value of Q matrix: 0.768628
New value of Value function: 0.768628
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1803
New value of Q matrix: 0.793255
New value of Value function: 0.793255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5759
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 988
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5760
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 989
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 0.665206
New value of Value function: 0.793255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0
New value of Value function: 0.793255
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1804
New value of Q matrix: 0.77739
New value of Value function: 0.77739
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1805
New value of Q matrix: 0.801843
New value of Value function: 0.801843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5765
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 990
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5766
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5767
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5768
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5769
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5770
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.232896
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5771
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.228238
New value of Value function: 0.228238
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5772
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 0.176424
New value of Value function: 0.228238
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5773
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5774
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 991
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5775
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5776
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 992
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5777
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 993
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1806
New value of Q matrix: 0.785806
New value of Value function: 0.785806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1807
New value of Q matrix: 0.81009
New value of Value function: 0.81009
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5780
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5781
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5782
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5783
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 994
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5784
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 995
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5785
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 996
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5786
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1808
New value of Q matrix: 0.793888
New value of Value function: 0.793888
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5787
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1809
New value of Q matrix: 0.81801
New value of Value function: 0.81801
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5788
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 997
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5789
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5790
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1810
New value of Q matrix: 0.80165
New value of Value function: 0.80165
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5791
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1811
New value of Q matrix: 0.825617
New value of Value function: 0.825617
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5792
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5793
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5794
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5795
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 998
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5796
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5797
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 999
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5798
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5799
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5800
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0.430316
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5801
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.42171
New value of Value function: 0.42171
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5802
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0.228238
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5803
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 0.283673
New value of Value function: 0.283673
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5804
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5805
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 0.337999
New value of Value function: 0.337999
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5806
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5807
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 0.473276
New value of Value function: 0.473276
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5808
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1000
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5809
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1001
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5810
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1002
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1812
New value of Q matrix: 0.809104
New value of Value function: 0.809104
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1813
New value of Q matrix: 0.832922
New value of Value function: 0.832922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5813
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1003
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5814
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1004
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0
New value of Value function: 0.832922
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5816
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1814
New value of Q matrix: 0.816264
New value of Value function: 0.816264
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1815
New value of Q matrix: 0.799939
New value of Value function: 0.799939
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 188
New value of Q matrix: 0.691901
New value of Value function: 0.799939
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5819
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5820
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5821
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1005
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1816
New value of Q matrix: 0.78394
New value of Value function: 0.78394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5823
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0
New value of Value function: 0.78394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5824
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0
New value of Value function: 0.78394
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5825
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1817
New value of Q matrix: 0.768261
New value of Value function: 0.768261
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5826
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1818
New value of Q matrix: 0.792896
New value of Value function: 0.792896
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5827
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5828
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5829
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5830
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5831
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1819
New value of Q matrix: 0.777038
New value of Value function: 0.777038
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5833
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1820
New value of Q matrix: 0.801497
New value of Value function: 0.801497
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5834
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5835
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5836
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1007
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5837
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5838
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1821
New value of Q matrix: 0.825467
New value of Value function: 0.825467
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5839
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5840
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5841
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1822
New value of Q matrix: 0.808958
New value of Value function: 0.808958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5842
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0
New value of Value function: 0.808958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5843
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1823
New value of Q matrix: 0.792779
New value of Value function: 0.792779
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5844
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1824
New value of Q matrix: 0.816923
New value of Value function: 0.816923
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5845
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1010
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5846
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5847
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1825
New value of Q matrix: 0.840585
New value of Value function: 0.840585
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5848
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5849
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1012
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5850
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 0
New value of Value function: 0.840585
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5851
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1826
New value of Q matrix: 0.823773
New value of Value function: 0.823773
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5852
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1827
New value of Q matrix: 0.807298
New value of Value function: 0.807298
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5853
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1828
New value of Q matrix: 0.831152
New value of Value function: 0.831152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5854
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5855
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5856
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1014
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5857
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5858
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1829
New value of Q matrix: 0.814529
New value of Value function: 0.814529
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5859
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1830
New value of Q matrix: 0.838238
New value of Value function: 0.838238
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5860
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1016
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5861
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5862
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1831
New value of Q matrix: 0.821473
New value of Value function: 0.821473
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5863
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1832
New value of Q matrix: 0.845044
New value of Value function: 0.845044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5864
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1018
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5865
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1019
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5866
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 0.678063
New value of Value function: 0.845044
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5867
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1833
New value of Q matrix: 0.868143
New value of Value function: 0.868143
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5868
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1020
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5869
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1021
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5870
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1834
New value of Q matrix: 0.85078
New value of Value function: 0.85078
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5871
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1835
New value of Q matrix: 0.873764
New value of Value function: 0.873764
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5872
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1022
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5873
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1023
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5874
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1836
New value of Q matrix: 0.856289
New value of Value function: 0.856289
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5875
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1837
New value of Q matrix: 0.879163
New value of Value function: 0.879163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5876
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5877
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1024
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5878
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5879
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1026
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5880
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1838
New value of Q matrix: 0.86158
New value of Value function: 0.86158
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5881
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0
New value of Value function: 0.86158
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5882
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 0
New value of Value function: 0.86158
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1839
New value of Q matrix: 0.844349
New value of Value function: 0.844349
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1840
New value of Q matrix: 0.827462
New value of Value function: 0.827462
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1841
New value of Q matrix: 0.850912
New value of Value function: 0.850912
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5886
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1027
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5887
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1028
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5888
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1842
New value of Q matrix: 0.833894
New value of Value function: 0.833894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1843
New value of Q matrix: 0.857216
New value of Value function: 0.857216
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5890
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5891
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1029
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5892
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5893
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1030
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5894
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1031
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5895
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1844
New value of Q matrix: 0.840072
New value of Value function: 0.840072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5896
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 190
New value of Q matrix: 0.704502
New value of Value function: 0.840072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5897
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1032
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5898
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5899
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 191
New value of Q matrix: 0.730412
New value of Value function: 0.840072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5900
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.631544
New value of Value function: 0.631544
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5901
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.618913
New value of Value function: 0.618913
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5902
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0
New value of Value function: 0.840072
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5903
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1845
New value of Q matrix: 0.82327
New value of Value function: 0.82327
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5904
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1846
New value of Q matrix: 0.806805
New value of Value function: 0.806805
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5905
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0
New value of Value function: 0.806805
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5906
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1847
New value of Q matrix: 0.830669
New value of Value function: 0.830669
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5907
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1033
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5908
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5909
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1034
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5910
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5911
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1848
New value of Q matrix: 0.814056
New value of Value function: 0.814056
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5912
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1849
New value of Q matrix: 0.837774
New value of Value function: 0.837774
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5913
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1036
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5914
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5915
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1850
New value of Q matrix: 0.821019
New value of Value function: 0.821019
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5916
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1851
New value of Q matrix: 0.844599
New value of Value function: 0.844599
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5917
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5918
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1038
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5919
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5920
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5921
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1039
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5922
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5923
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1040
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5924
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5925
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5926
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5927
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5928
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1852
New value of Q matrix: 0.827707
New value of Value function: 0.827707
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5929
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0
New value of Value function: 0.827707
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5930
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1853
New value of Q matrix: 0.811152
New value of Value function: 0.811152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5931
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1854
New value of Q matrix: 0.834929
New value of Value function: 0.834929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5932
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1041
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5933
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1042
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5934
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1855
New value of Q matrix: 0.818231
New value of Value function: 0.818231
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5935
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1856
New value of Q matrix: 0.841866
New value of Value function: 0.841866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5936
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1043
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5937
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5938
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0
New value of Value function: 0.841866
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5939
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1857
New value of Q matrix: 0.825029
New value of Value function: 0.825029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5940
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1858
New value of Q matrix: 0.808528
New value of Value function: 0.808528
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5941
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1859
New value of Q matrix: 0.792358
New value of Value function: 0.792358
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5942
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 192
New value of Q matrix: 0.755804
New value of Value function: 0.792358
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5943
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1044
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5944
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1045
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5945
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 0.740688
New value of Value function: 0.792358
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5946
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1860
New value of Q matrix: 0.816511
New value of Value function: 0.816511
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5947
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.606535
New value of Value function: 0.606535
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5948
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.594404
New value of Value function: 0.594404
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5949
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1861
New value of Q matrix: 0.80018
New value of Value function: 0.80018
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5950
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1862
New value of Q matrix: 0.824177
New value of Value function: 0.824177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5951
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5952
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1047
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5953
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1863
New value of Q matrix: 0.807693
New value of Value function: 0.807693
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5954
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1864
New value of Q matrix: 0.831539
New value of Value function: 0.831539
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5955
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1048
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5956
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1049
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5957
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1865
New value of Q matrix: 0.814909
New value of Value function: 0.814909
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5958
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1866
New value of Q matrix: 0.83861
New value of Value function: 0.83861
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5959
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5960
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1051
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5961
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1867
New value of Q matrix: 0.821838
New value of Value function: 0.821838
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5962
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1868
New value of Q matrix: 0.845401
New value of Value function: 0.845401
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5963
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1052
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5964
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5965
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.171766
New value of Value function: 0.171766
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5966
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.168331
New value of Value function: 0.168331
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 5967
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0
New value of Value function: 0.845401
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5968
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1869
New value of Q matrix: 0.828493
New value of Value function: 0.828493
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5969
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1870
New value of Q matrix: 0.811924
New value of Value function: 0.811924
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5970
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0
New value of Value function: 0.811924
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5971
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1871
New value of Q matrix: 0.795685
New value of Value function: 0.795685
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5972
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1872
New value of Q matrix: 0.819771
New value of Value function: 0.819771
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5973
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5974
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5975
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5976
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1054
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5977
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1873
New value of Q matrix: 0.803376
New value of Value function: 0.803376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5978
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1874
New value of Q matrix: 0.827308
New value of Value function: 0.827308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5979
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1055
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5980
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1056
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5981
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1875
New value of Q matrix: 0.810762
New value of Value function: 0.810762
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5982
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1876
New value of Q matrix: 0.834547
New value of Value function: 0.834547
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5983
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1057
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5984
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1058
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5985
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1877
New value of Q matrix: 0.817856
New value of Value function: 0.817856
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5986
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1878
New value of Q matrix: 0.841499
New value of Value function: 0.841499
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5987
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5988
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5989
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1059
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5990
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1060
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5991
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1879
New value of Q matrix: 0.824669
New value of Value function: 0.824669
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5992
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1880
New value of Q matrix: 0.848176
New value of Value function: 0.848176
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5993
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5994
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5995
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5996
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1061
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5997
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1062
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5998
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1881
New value of Q matrix: 0.831212
New value of Value function: 0.831212
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 5999
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1882
New value of Q matrix: 0.854588
New value of Value function: 0.854588
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6000
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1063
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6001
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6002
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1883
New value of Q matrix: 0.837496
New value of Value function: 0.837496
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6003
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1884
New value of Q matrix: 0.860746
New value of Value function: 0.860746
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6004
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6005
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6006
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1066
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6007
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6008
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6009
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1068
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6010
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1885
New value of Q matrix: 0.843531
New value of Value function: 0.843531
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6011
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1886
New value of Q matrix: 0.866661
New value of Value function: 0.866661
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6012
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6013
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1070
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6014
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1887
New value of Q matrix: 0.849327
New value of Value function: 0.849327
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6015
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1888
New value of Q matrix: 0.872341
New value of Value function: 0.872341
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6016
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1071
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6017
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1072
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6018
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1889
New value of Q matrix: 0.854894
New value of Value function: 0.854894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6019
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1890
New value of Q matrix: 0.877796
New value of Value function: 0.877796
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6020
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1073
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6021
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1074
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6022
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1891
New value of Q matrix: 0.86024
New value of Value function: 0.86024
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6023
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1892
New value of Q matrix: 0.883035
New value of Value function: 0.883035
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6024
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1075
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6025
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1076
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6026
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1893
New value of Q matrix: 0.865375
New value of Value function: 0.865375
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6027
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1894
New value of Q matrix: 0.888067
New value of Value function: 0.888067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6028
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6029
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1078
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6030
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1895
New value of Q matrix: 0.870306
New value of Value function: 0.870306
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6031
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1896
New value of Q matrix: 0.8929
New value of Value function: 0.8929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6032
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1079
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6033
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6034
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 194
New value of Q matrix: 0.765874
New value of Value function: 0.8929
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6035
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1081
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6036
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6037
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1897
New value of Q matrix: 0.875042
New value of Value function: 0.875042
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6038
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1898
New value of Q matrix: 0.897541
New value of Value function: 0.897541
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6039
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1083
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6040
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6041
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1899
New value of Q matrix: 0.87959
New value of Value function: 0.87959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6042
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 0
New value of Value function: 0.87959
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6043
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1900
New value of Q matrix: 0.861998
New value of Value function: 0.861998
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6044
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1901
New value of Q matrix: 0.884758
New value of Value function: 0.884758
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6045
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1085
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6046
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1086
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6047
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1902
New value of Q matrix: 0.867063
New value of Value function: 0.867063
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6048
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1903
New value of Q matrix: 0.889722
New value of Value function: 0.889722
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6049
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6050
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1088
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6051
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1904
New value of Q matrix: 0.871927
New value of Value function: 0.871927
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6052
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1905
New value of Q matrix: 0.894489
New value of Value function: 0.894489
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6053
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6054
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6055
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6056
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1091
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6057
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1906
New value of Q matrix: 0.876599
New value of Value function: 0.876599
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6058
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1907
New value of Q matrix: 0.899067
New value of Value function: 0.899067
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6059
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6060
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1093
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6061
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1908
New value of Q matrix: 0.881086
New value of Value function: 0.881086
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6062
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1909
New value of Q matrix: 0.903464
New value of Value function: 0.903464
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6063
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6064
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1095
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6065
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1910
New value of Q matrix: 0.885395
New value of Value function: 0.885395
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6066
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1911
New value of Q matrix: 0.907687
New value of Value function: 0.907687
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6067
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6068
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6069
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1912
New value of Q matrix: 0.889533
New value of Value function: 0.889533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6070
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0
New value of Value function: 0.889533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6071
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1913
New value of Q matrix: 0.871743
New value of Value function: 0.871743
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6072
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1914
New value of Q matrix: 0.894308
New value of Value function: 0.894308
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6073
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1097
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6074
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6075
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1915
New value of Q matrix: 0.916422
New value of Value function: 0.916422
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6076
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6077
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1099
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6078
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1916
New value of Q matrix: 0.898093
New value of Value function: 0.898093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6079
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0
New value of Value function: 0.898093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6080
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 195
New value of Q matrix: 0.790557
New value of Value function: 0.898093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6081
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1100
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6082
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6083
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0
New value of Value function: 0.898093
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6084
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1917
New value of Q matrix: 0.880131
New value of Value function: 0.880131
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6085
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 0.774745
New value of Value function: 0.880131
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6086
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 197
New value of Q matrix: 0.799251
New value of Value function: 0.880131
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6087
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.582516
New value of Value function: 0.582516
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6088
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.570866
New value of Value function: 0.570866
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6089
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1918
New value of Q matrix: 0.862529
New value of Value function: 0.862529
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6090
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1919
New value of Q matrix: 0.885278
New value of Value function: 0.885278
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6091
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6092
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6093
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6094
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1103
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6095
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1920
New value of Q matrix: 0.867572
New value of Value function: 0.867572
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6096
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1921
New value of Q matrix: 0.890221
New value of Value function: 0.890221
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6097
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6098
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6099
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0
New value of Value function: 0.890221
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0
New value of Value function: 0.890221
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1922
New value of Q matrix: 0.872417
New value of Value function: 0.872417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0
New value of Value function: 0.872417
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1923
New value of Q matrix: 0.854968
New value of Value function: 0.854968
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1924
New value of Q matrix: 0.877869
New value of Value function: 0.877869
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6105
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1106
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6106
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1925
New value of Q matrix: 0.860312
New value of Value function: 0.860312
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1926
New value of Q matrix: 0.883105
New value of Value function: 0.883105
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6109
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1108
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6110
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1927
New value of Q matrix: 0.865443
New value of Value function: 0.865443
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1928
New value of Q matrix: 0.888134
New value of Value function: 0.888134
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6113
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1110
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6114
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1929
New value of Q matrix: 0.870372
New value of Value function: 0.870372
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1930
New value of Q matrix: 0.892964
New value of Value function: 0.892964
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6117
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6118
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1112
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6119
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6120
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1114
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1931
New value of Q matrix: 0.875105
New value of Value function: 0.875105
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1932
New value of Q matrix: 0.897603
New value of Value function: 0.897603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6123
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1115
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6124
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1116
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0
New value of Value function: 0.897603
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1933
New value of Q matrix: 0.879651
New value of Value function: 0.879651
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1934
New value of Q matrix: 0.862058
New value of Value function: 0.862058
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1935
New value of Q matrix: 0.884817
New value of Value function: 0.884817
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6129
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6130
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1118
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1936
New value of Q matrix: 0.86712
New value of Value function: 0.86712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1937
New value of Q matrix: 0.889778
New value of Value function: 0.889778
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6133
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1119
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6134
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1938
New value of Q matrix: 0.871982
New value of Value function: 0.871982
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1939
New value of Q matrix: 0.894543
New value of Value function: 0.894543
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6137
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1120
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6138
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1121
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1940
New value of Q matrix: 0.876652
New value of Value function: 0.876652
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1941
New value of Q matrix: 0.899119
New value of Value function: 0.899119
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6141
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6142
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6143
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1123
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6144
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1124
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1942
New value of Q matrix: 0.881136
New value of Value function: 0.881136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1943
New value of Q matrix: 0.903514
New value of Value function: 0.903514
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6147
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6148
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1125
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6149
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6150
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1126
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6151
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1127
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1944
New value of Q matrix: 0.885443
New value of Value function: 0.885443
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1945
New value of Q matrix: 0.907735
New value of Value function: 0.907735
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6154
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1128
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6155
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1129
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1946
New value of Q matrix: 0.88958
New value of Value function: 0.88958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0
New value of Value function: 0.88958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1947
New value of Q matrix: 0.871788
New value of Value function: 0.871788
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1948
New value of Q matrix: 0.894352
New value of Value function: 0.894352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6160
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1130
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6161
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1131
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 0.783266
New value of Value function: 0.894352
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1949
New value of Q matrix: 0.916465
New value of Value function: 0.916465
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6164
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.164964
New value of Value function: 0.164964
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6165
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.161665
New value of Value function: 0.161665
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1950
New value of Q matrix: 0.898136
New value of Value function: 0.898136
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1951
New value of Q matrix: 0.920173
New value of Value function: 0.920173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6168
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1132
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6169
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1133
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0.7676
New value of Value function: 0.920173
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1952
New value of Q matrix: 0.94177
New value of Value function: 0.94177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6172
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1134
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6173
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1135
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 0
New value of Value function: 0.94177
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1953
New value of Q matrix: 0.922935
New value of Value function: 0.922935
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1954
New value of Q matrix: 0.904476
New value of Value function: 0.904476
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1955
New value of Q matrix: 0.926386
New value of Value function: 0.926386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6178
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6179
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1136
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 0
New value of Value function: 0.926386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1956
New value of Q matrix: 0.907859
New value of Value function: 0.907859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0
New value of Value function: 0.907859
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1957
New value of Q matrix: 0.889701
New value of Value function: 0.889701
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1958
New value of Q matrix: 0.911907
New value of Value function: 0.911907
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6185
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1137
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6186
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1138
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1959
New value of Q matrix: 0.893669
New value of Value function: 0.893669
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1960
New value of Q matrix: 0.915796
New value of Value function: 0.915796
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6189
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1139
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6190
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1140
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1961
New value of Q matrix: 0.89748
New value of Value function: 0.89748
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1962
New value of Q matrix: 0.91953
New value of Value function: 0.91953
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6193
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1141
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6194
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1142
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1963
New value of Q matrix: 0.90114
New value of Value function: 0.90114
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1964
New value of Q matrix: 0.923117
New value of Value function: 0.923117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6197
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6198
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1143
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6199
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1144
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6200
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1145
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1965
New value of Q matrix: 0.904655
New value of Value function: 0.904655
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1966
New value of Q matrix: 0.926562
New value of Value function: 0.926562
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6203
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1146
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6204
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1147
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1967
New value of Q matrix: 0.90803
New value of Value function: 0.90803
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1968
New value of Q matrix: 0.92987
New value of Value function: 0.92987
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6207
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1148
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6208
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1149
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1969
New value of Q matrix: 0.911272
New value of Value function: 0.911272
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1970
New value of Q matrix: 0.933047
New value of Value function: 0.933047
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6211
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6212
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1150
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1971
New value of Q matrix: 0.914386
New value of Value function: 0.914386
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1972
New value of Q matrix: 0.936098
New value of Value function: 0.936098
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6215
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6216
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1151
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6217
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6218
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1973
New value of Q matrix: 0.917376
New value of Value function: 0.917376
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1974
New value of Q matrix: 0.939029
New value of Value function: 0.939029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6221
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1154
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6222
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6223
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6224
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1156
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 0
New value of Value function: 0.939029
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1975
New value of Q matrix: 0.920248
New value of Value function: 0.920248
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 0
New value of Value function: 0.920248
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1976
New value of Q matrix: 0.901843
New value of Value function: 0.901843
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1977
New value of Q matrix: 0.923806
New value of Value function: 0.923806
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6230
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6231
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1158
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1978
New value of Q matrix: 0.90533
New value of Value function: 0.90533
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1979
New value of Q matrix: 0.927224
New value of Value function: 0.927224
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6234
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1159
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6235
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1980
New value of Q matrix: 0.948679
New value of Value function: 0.948679
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6237
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6238
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1161
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1981
New value of Q matrix: 0.929706
New value of Value function: 0.929706
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1982
New value of Q matrix: 0.951111
New value of Value function: 0.951111
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6241
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6242
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1163
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1983
New value of Q matrix: 0.932089
New value of Value function: 0.932089
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1984
New value of Q matrix: 0.953447
New value of Value function: 0.953447
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6245
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6246
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1165
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1985
New value of Q matrix: 0.934378
New value of Value function: 0.934378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1986
New value of Q matrix: 0.955691
New value of Value function: 0.955691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6249
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6250
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1987
New value of Q matrix: 0.936577
New value of Value function: 0.936577
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1988
New value of Q matrix: 0.957846
New value of Value function: 0.957846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6253
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6254
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6255
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6256
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0
New value of Value function: 0.957846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0
New value of Value function: 0.957846
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1989
New value of Q matrix: 0.938689
New value of Value function: 0.938689
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1990
New value of Q matrix: 0.919915
New value of Value function: 0.919915
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1991
New value of Q matrix: 0.941517
New value of Value function: 0.941517
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6262
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1170
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6263
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0
New value of Value function: 0.941517
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1992
New value of Q matrix: 0.922686
New value of Value function: 0.922686
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1993
New value of Q matrix: 0.944232
New value of Value function: 0.944232
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6267
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1172
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6268
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1994
New value of Q matrix: 0.925348
New value of Value function: 0.925348
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1995
New value of Q matrix: 0.946841
New value of Value function: 0.946841
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6271
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1174
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6272
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1175
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 0
New value of Value function: 0.946841
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 0.752248
New value of Value function: 0.946841
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1996
New value of Q matrix: 0.967904
New value of Value function: 0.967904
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6276
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1176
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6277
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1997
New value of Q matrix: 0.988546
New value of Value function: 0.988546
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6279
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1177
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6280
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6281
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6282
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1178
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1998
New value of Q matrix: 0.968775
New value of Value function: 0.968775
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1999
New value of Q matrix: 0.9894
New value of Value function: 0.9894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6285
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1179
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6286
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1180
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0
New value of Value function: 0.9894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0
New value of Value function: 0.9894
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2000
New value of Q matrix: 0.969612
New value of Value function: 0.969612
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 201
New value of Q matrix: 0.777203
New value of Value function: 0.969612
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6291
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6292
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1181
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6293
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1182
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6294
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1183
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2001
New value of Q matrix: 0.950219
New value of Value function: 0.950219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 0
New value of Value function: 0.950219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 0
New value of Value function: 0.950219
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2002
New value of Q matrix: 0.971215
New value of Value function: 0.971215
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6299
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1184
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6300
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1185
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2003
New value of Q matrix: 0.951791
New value of Value function: 0.951791
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2004
New value of Q matrix: 0.972755
New value of Value function: 0.972755
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6303
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1186
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6304
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2005
New value of Q matrix: 0.9933
New value of Value function: 0.9933
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6306
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1187
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6307
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1188
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2006
New value of Q matrix: 0.973434
New value of Value function: 0.973434
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2007
New value of Q matrix: 0.993965
New value of Value function: 0.993965
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6310
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1189
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6311
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6312
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1190
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6313
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1191
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2008
New value of Q matrix: 0.974086
New value of Value function: 0.974086
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2009
New value of Q matrix: 0.994604
New value of Value function: 0.994604
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6316
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1192
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6317
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1193
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2010
New value of Q matrix: 0.974712
New value of Value function: 0.974712
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2011
New value of Q matrix: 0.995218
New value of Value function: 0.995218
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6320
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1194
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6321
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1195
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2012
New value of Q matrix: 0.975313
New value of Value function: 0.975313
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2013
New value of Q matrix: 0.995807
New value of Value function: 0.995807
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6324
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1196
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6325
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1197
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2014
New value of Q matrix: 0.975891
New value of Value function: 0.975891
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2015
New value of Q matrix: 0.996373
New value of Value function: 0.996373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6328
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1198
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6329
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1199
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 0.761659
New value of Value function: 0.996373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2016
New value of Q matrix: 1.01645
New value of Value function: 1.01645
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6332
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0.570866
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6333
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.559449
New value of Value function: 0.559449
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6334
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 0.0496025
New value of Value function: 0.559449
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2017
New value of Q matrix: 0.996117
New value of Value function: 0.996117
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2018
New value of Q matrix: 1.01619
New value of Value function: 1.01619
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6337
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6338
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1200
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2019
New value of Q matrix: 0.995871
New value of Value function: 0.995871
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2020
New value of Q matrix: 1.01595
New value of Value function: 1.01595
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6341
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1201
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6342
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1202
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2021
New value of Q matrix: 0.995634
New value of Value function: 0.995634
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 203
New value of Q matrix: 0.786426
New value of Value function: 0.995634
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6345
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1203
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6346
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1204
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2022
New value of Q matrix: 0.975721
New value of Value function: 0.975721
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2023
New value of Q matrix: 0.996207
New value of Value function: 0.996207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6349
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1205
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6350
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1206
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 0
New value of Value function: 0.996207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0.770697
New value of Value function: 0.996207
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2024
New value of Q matrix: 0.976283
New value of Value function: 0.976283
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2025
New value of Q matrix: 0.996757
New value of Value function: 0.996757
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6355
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.54826
New value of Value function: 0.54826
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6356
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.537294
New value of Value function: 0.537294
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2026
New value of Q matrix: 0.976822
New value of Value function: 0.976822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 205
New value of Q matrix: 0.795284
New value of Value function: 0.976822
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6359
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1207
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6360
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1208
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2027
New value of Q matrix: 0.957286
New value of Value function: 0.957286
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2028
New value of Q matrix: 0.97814
New value of Value function: 0.97814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6363
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1209
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6364
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1210
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 0
New value of Value function: 0.97814
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2029
New value of Q matrix: 0.958577
New value of Value function: 0.958577
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2030
New value of Q matrix: 0.979406
New value of Value function: 0.979406
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6368
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1211
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6369
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2031
New value of Q matrix: 0.959817
New value of Value function: 0.959817
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2032
New value of Q matrix: 0.980621
New value of Value function: 0.980621
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6372
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6373
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 0.586549
New value of Value function: 0.586549
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6374
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1213
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6375
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2033
New value of Q matrix: 0.961009
New value of Value function: 0.961009
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2034
New value of Q matrix: 0.981788
New value of Value function: 0.981788
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6378
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1215
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6379
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2035
New value of Q matrix: 0.962153
New value of Value function: 0.962153
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2036
New value of Q matrix: 0.98291
New value of Value function: 0.98291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6382
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1217
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6383
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6384
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.574818
New value of Value function: 0.574818
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6385
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 0.06
New value of Value function: 0.574818
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6386
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6387
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 0
New value of Value function: 0.98291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0.779378
New value of Value function: 0.98291
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2037
New value of Q matrix: 0.963251
New value of Value function: 0.963251
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2038
New value of Q matrix: 0.983986
New value of Value function: 0.983986
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6392
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6393
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6394
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 0.391239
New value of Value function: 0.391239
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6395
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6396
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6397
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.563321
New value of Value function: 0.563321
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6398
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.552055
New value of Value function: 0.552055
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2039
New value of Q matrix: 0.964307
New value of Value function: 0.964307
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 0
New value of Value function: 0.964307
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6401
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0.76379
New value of Value function: 0.964307
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6402
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2040
New value of Q matrix: 0.985021
New value of Value function: 0.985021
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6403
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6404
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6405
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1222
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6406
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2041
New value of Q matrix: 0.96532
New value of Value function: 0.96532
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6407
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2042
New value of Q matrix: 0.986014
New value of Value function: 0.986014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6408
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6409
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1224
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0.748514
New value of Value function: 0.986014
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2043
New value of Q matrix: 1.00629
New value of Value function: 1.00629
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6412
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6413
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 0.601014
New value of Value function: 0.601014
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6414
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6415
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 0
New value of Value function: 1.00629
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2044
New value of Q matrix: 0.986168
New value of Value function: 0.986168
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2045
New value of Q matrix: 0.966444
New value of Value function: 0.966444
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 0
New value of Value function: 0.966444
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2046
New value of Q matrix: 0.987115
New value of Value function: 0.987115
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6421
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1227
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6422
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2047
New value of Q matrix: 0.967373
New value of Value function: 0.967373
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2048
New value of Q matrix: 0.988026
New value of Value function: 0.988026
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6425
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1229
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6426
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2049
New value of Q matrix: 1.00827
New value of Value function: 1.00827
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6428
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1230
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6429
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2050
New value of Q matrix: 0.9881
New value of Value function: 0.9881
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2051
New value of Q matrix: 1.00834
New value of Value function: 1.00834
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6432
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6433
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 0
New value of Value function: 1.00834
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 0
New value of Value function: 1.00834
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2052
New value of Q matrix: 0.988171
New value of Value function: 0.988171
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2053
New value of Q matrix: 0.968408
New value of Value function: 0.968408
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2054
New value of Q matrix: 0.949039
New value of Value function: 0.949039
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2055
New value of Q matrix: 0.930059
New value of Value function: 0.930059
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2056
New value of Q matrix: 0.951458
New value of Value function: 0.951458
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6441
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1234
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6442
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1235
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2057
New value of Q matrix: 0.932428
New value of Value function: 0.932428
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2058
New value of Q matrix: 0.95378
New value of Value function: 0.95378
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6445
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1236
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6446
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1237
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2059
New value of Q matrix: 0.934704
New value of Value function: 0.934704
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2060
New value of Q matrix: 0.95601
New value of Value function: 0.95601
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6449
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1238
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6450
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2061
New value of Q matrix: 0.93689
New value of Value function: 0.93689
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2062
New value of Q matrix: 0.958152
New value of Value function: 0.958152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6453
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6454
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1240
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 0
New value of Value function: 0.958152
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2063
New value of Q matrix: 0.938989
New value of Value function: 0.938989
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2064
New value of Q matrix: 0.920209
New value of Value function: 0.920209
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2065
New value of Q matrix: 0.941805
New value of Value function: 0.941805
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6459
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1241
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6460
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1242
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2066
New value of Q matrix: 0.922969
New value of Value function: 0.922969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 0
New value of Value function: 0.922969
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2067
New value of Q matrix: 0.90451
New value of Value function: 0.90451
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2068
New value of Q matrix: 0.926419
New value of Value function: 0.926419
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6465
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1243
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6466
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2069
New value of Q matrix: 0.907891
New value of Value function: 0.907891
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2070
New value of Q matrix: 0.929733
New value of Value function: 0.929733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6469
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6470
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6471
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1245
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6472
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1246
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 0
New value of Value function: 0.929733
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2071
New value of Q matrix: 0.911139
New value of Value function: 0.911139
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2072
New value of Q matrix: 0.892916
New value of Value function: 0.892916
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2073
New value of Q matrix: 0.915057
New value of Value function: 0.915057
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6477
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6478
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1248
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2074
New value of Q matrix: 0.896756
New value of Value function: 0.896756
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2075
New value of Q matrix: 0.918821
New value of Value function: 0.918821
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6481
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6482
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6483
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6484
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6485
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1251
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 209
New value of Q matrix: 0.773544
New value of Value function: 0.918821
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6487
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6488
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1253
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0
New value of Value function: 0.918821
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2076
New value of Q matrix: 0.900445
New value of Value function: 0.900445
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2077
New value of Q matrix: 0.882436
New value of Value function: 0.882436
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2078
New value of Q matrix: 0.904787
New value of Value function: 0.904787
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6493
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6494
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1255
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2079
New value of Q matrix: 0.886691
New value of Value function: 0.886691
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2080
New value of Q matrix: 0.908958
New value of Value function: 0.908958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6497
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6498
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6499
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1257
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 0.758073
New value of Value function: 0.908958
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2081
New value of Q matrix: 0.930778
New value of Value function: 0.930778
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6502
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 0.0486104
New value of Value function: 0.601014
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6503
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.588993
New value of Value function: 0.588993
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 0
New value of Value function: 0.930778
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2082
New value of Q matrix: 0.912163
New value of Value function: 0.912163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 0.742912
New value of Value function: 0.912163
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6507
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2083
New value of Q matrix: 0.93392
New value of Value function: 0.93392
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6508
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.158432
New value of Value function: 0.158432
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6509
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.057624
New value of Value function: 0.158432
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 6510
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2084
New value of Q matrix: 0.955241
New value of Value function: 0.955241
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 6511
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6512
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1259
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6513
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 0
New value of Value function: 0.955241
New value of Policy matrix: 1

