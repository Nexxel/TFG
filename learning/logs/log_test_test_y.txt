=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 15
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0014256
New value of Value function: 0.04
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0398402
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000717123
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0014199
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00211421
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000717123
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00278905
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00345039
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0014199
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00210863
New value of Value function: 0.0398402
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0397605
New value of Value function: 0.0397605
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00409707
New value of Value function: 0.0397605
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00210719
New value of Value function: 0.0397605
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.039681
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000714257
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00277931
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00278071
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00141423
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00343936
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00408483
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00343798
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00472939
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00471739
New value of Value function: 0.039681
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0396016
New value of Value function: 0.0396016
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0395224
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00533444
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00209735
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00408062
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00471041
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0053462
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00532761
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00593916
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00653178
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0027668
New value of Value function: 0.0395224
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0394433
New value of Value function: 0.0394433
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0393645
New value of Value function: 0.0393645
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00592962
New value of Value function: 0.0393645
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00651958
New value of Value function: 0.0393645
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0392857
New value of Value function: 0.0392857
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0392072
New value of Value function: 0.0392072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00710687
New value of Value function: 0.0392072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0034172
New value of Value function: 0.0392072
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0391287
New value of Value function: 0.0391287
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0390505
New value of Value function: 0.0390505
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00405176
New value of Value function: 0.0390505
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0389724
New value of Value function: 0.0389724
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00467223
New value of Value function: 0.0389724
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00709069
New value of Value function: 0.0389724
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0388944
New value of Value function: 0.0388944
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 0.0781166
New value of Value function: 0.0781166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 68
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0385939
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00598488
New value of Value function: 0.0781166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00727128
New value of Value function: 0.0781166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0779603
New value of Value function: 0.0779603
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00836802
New value of Value function: 0.0779603
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00664257
New value of Value function: 0.0779603
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00835217
New value of Value function: 0.0779603
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0778044
New value of Value function: 0.0778044
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0776488
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00852354
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 0.0481851
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 79
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 87
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 92
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0764243
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.00959834
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00790739
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00975074
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0486191
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.010804
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0490444
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0494612
New value of Value function: 0.0776488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0774935
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0119828
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00914413
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0103561
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0498668
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0115439
New value of Value function: 0.0774935
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 0.0888695
New value of Value function: 0.0888695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0392
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 110
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0392
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 111
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.0768163
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0129127
New value of Value function: 0.0888695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0111554
New value of Value function: 0.0888695
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 0.127092
New value of Value function: 0.127092
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 116
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.112992
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0132199
New value of Value function: 0.127092
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0782313
New value of Value function: 0.127092
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0140309
New value of Value function: 0.127092
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.126838
New value of Value function: 0.126838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0160333
New value of Value function: 0.126838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0149375
New value of Value function: 0.126838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0789497
New value of Value function: 0.126838
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.126584
New value of Value function: 0.126584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0796493
New value of Value function: 0.126584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0803348
New value of Value function: 0.126584
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 0.164053
New value of Value function: 0.164053
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 129
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.14778
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0186656
New value of Value function: 0.164053
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0212452
New value of Value function: 0.164053
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.163724
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0237674
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0159026
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0262391
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0816751
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0286613
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0175858
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0201811
New value of Value function: 0.163724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.163397
New value of Value function: 0.163397
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0227186
New value of Value function: 0.163397
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0252054
New value of Value function: 0.163397
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.16307
New value of Value function: 0.16307
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0276366
New value of Value function: 0.16307
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0829769
New value of Value function: 0.16307
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0185198
New value of Value function: 0.16307
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0300191
New value of Value function: 0.16307
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.162744
New value of Value function: 0.162744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0842468
New value of Value function: 0.162744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0854912
New value of Value function: 0.162744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0323481
New value of Value function: 0.162744
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.162419
New value of Value function: 0.162419
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0867049
New value of Value function: 0.162419
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 0.19917
New value of Value function: 0.19917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.181239
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0217345
New value of Value function: 0.19917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 0.235187
New value of Value function: 0.235187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.038416
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 159
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.177614
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 160
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.209828
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0323215
New value of Value function: 0.235187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0359084
New value of Value function: 0.235187
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.234716
New value of Value function: 0.234716
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.234247
New value of Value function: 0.234247
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 0.269562
New value of Value function: 0.269562
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 167
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 168
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 169
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 170
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.0769277
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 171
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 172
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 173
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0407056
New value of Value function: 0.0407056
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 176
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0777617
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0399327
New value of Value function: 0.0407056
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 178
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 179
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 180
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: -0.24078
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0400423
New value of Value function: 0.269562
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.269023
New value of Value function: 0.269023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0440839
New value of Value function: 0.269023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0365436
New value of Value function: 0.269023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0261422
New value of Value function: 0.269023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.268485
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0898036
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0304521
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0346757
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0928402
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.048035
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.051907
New value of Value function: 0.268485
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.267948
New value of Value function: 0.267948
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.267412
New value of Value function: 0.267412
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 0.302064
New value of Value function: 0.302064
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: -0.270527
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 0.336023
New value of Value function: 0.336023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 199
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 200
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0753891
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 201
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 202
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 204
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0385744
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 205
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0413171
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 206
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0014256
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 207
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.117616
New value of Value function: 0.117616
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 208
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 209
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0738813
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 210
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0378829
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 211
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0426078
New value of Value function: 0.117616
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.079134
New value of Value function: 0.117616
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 214
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 215
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.265117
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 216
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 217
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0392
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 218
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: -0.293766
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0400306
New value of Value function: 0.336023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0970318
New value of Value function: 0.336023
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 0.369302
New value of Value function: 0.369302
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 222
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.111684
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 223
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 224
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 225
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 226
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.28789
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 227
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 228
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 229
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.038416
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 230
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.10945
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 231
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0371253
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 232
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0762065
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 233
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0746823
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 234
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0363827
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 235
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0731887
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 236
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 237
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 238
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 0.1
New value of Value function: 0.1
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 239
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0333526
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0424601
New value of Value function: 0.369302
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0482584
New value of Value function: 0.369302
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 0.401916
New value of Value function: 0.401916
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 244
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 245
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 246
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.065451
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0545277
New value of Value function: 0.401916
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0581033
New value of Value function: 0.401916
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.401112
New value of Value function: 0.401112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.04645
New value of Value function: 0.401112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.102311
New value of Value function: 0.401112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0606571
New value of Value function: 0.401112
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 46
New value of Q matrix: 0.43309
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 254
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 255
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 256
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0018
New value of Value function: 0.0018
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 257
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 0.198
New value of Value function: 0.198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 258
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.003564
New value of Value function: 0.003564
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0342389
New value of Value function: 0.198
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 260
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.19404
New value of Value function: 0.19404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 261
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.103768
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 262
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.190159
New value of Value function: 0.190159
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 263
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0392
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 264
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 265
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: -0.182069
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 266
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.4152e-05
New value of Value function: 0.003564
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 267
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.4152e-05
New value of Value function: 0.003564
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 268
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00691559
New value of Value function: 0.00691559
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 269
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.28648
New value of Value function: 0.28648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 270
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.2869e-05
New value of Value function: 0.00691559
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 271
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 272
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0376477
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 273
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.038416
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 274
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 275
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0368947
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 276
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0965363
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 277
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00515665
New value of Value function: 0.28648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 278
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.071437
New value of Value function: 0.28648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 279
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0465537
New value of Value function: 0.117616
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 280
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.073538
New value of Value function: 0.28648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 281
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.16042
New value of Value function: 0.16042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 282
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.280751
New value of Value function: 0.280751
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 283
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0895521
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 284
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0649548
New value of Value function: 0.280751
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 285
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0666714
New value of Value function: 0.280751
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.275136
New value of Value function: 0.275136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 287
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 288
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0376477
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 289
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 290
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0361568
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 291
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0354337
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 292
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.034725
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 293
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0368947
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 294
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 295
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 296
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0828086
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 297
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.100768
New value of Value function: 0.275136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 298
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0446432
New value of Value function: 0.16042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 299
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.197212
New value of Value function: 0.197212
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: -0.03928
New value of Value function: -0.034725
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 301
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0785749
New value of Value function: 0.0785749
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 302
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: -0.0770801
New value of Value function: -0.034725
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 303
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00141435
New value of Value function: 0.0785749
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 304
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.040761
New value of Value function: 0.0785749
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 305
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: -0.114124
New value of Value function: -0.034725
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 306
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0393749
New value of Value function: 0.0785749
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 307
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0762
New value of Value function: -0.034725
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 308
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: -0.137338
New value of Value function: 0.275136
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 309
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.00088055
New value of Value function: 0.0785749
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 310
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -0.112467
New value of Value function: -0.034725
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 311
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0346556
New value of Value function: -0.0346556
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 312
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0367806
New value of Value function: -0.0346556
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 313
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.0752998
New value of Value function: -0.0346556
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 314
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: -0.110244
New value of Value function: -0.0346556
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 315
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.232644
New value of Value function: 0.232644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 316
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.179051
New value of Value function: -0.0346556
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 317
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.0345863
New value of Value function: -0.0345863
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 318
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.108662
New value of Value function: -0.0345863
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 319
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.0345171
New value of Value function: -0.0345171
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 320
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0366663
New value of Value function: -0.0345171
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 321
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: -0.142301
New value of Value function: -0.0345171
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 322
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.081739
New value of Value function: 0.232644
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 323
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.26737
New value of Value function: 0.26737
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 324
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0344481
New value of Value function: -0.0344481
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 325
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.0343792
New value of Value function: -0.0343792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 326
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.0365518
New value of Value function: -0.0343792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 327
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: -0.174642
New value of Value function: -0.0343792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 328
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.048563
New value of Value function: 0.26737
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 329
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.301403
New value of Value function: 0.301403
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 330
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.0343104
New value of Value function: -0.0343104
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 331
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: -0.205724
New value of Value function: -0.0343104
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 332
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.334758
New value of Value function: 0.334758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 333
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: -0.110835
New value of Value function: -0.0343104
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 334
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.176088
New value of Value function: -0.0343104
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 335
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -0.0342418
New value of Value function: -0.0342418
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 336
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: -0.20477
New value of Value function: -0.0342418
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0533167
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0600459
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0666407
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0731035
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.108061
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.113695
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.079437
New value of Value function: 0.43309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 47
New value of Q matrix: 0.463812
New value of Value function: 0.463812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 345
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: -0.0341733
New value of Value function: -0.0341733
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 346
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: -0.202225
New value of Value function: -0.0341733
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 347
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: -0.109233
New value of Value function: -0.0341733
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 348
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: -0.0720755
New value of Value function: -0.0365518
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 349
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0841524
New value of Value function: 0.0841524
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 350
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 0.231148
New value of Value function: 0.231148
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0401022
New value of Value function: 0.0841524
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 352
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0792879
New value of Value function: 0.0841524
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 353
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.0364787
New value of Value function: -0.0364787
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 354
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.107705
New value of Value function: -0.0364787
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 355
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.201331
New value of Value function: -0.0364787
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 356
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0364058
New value of Value function: -0.0364058
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 357
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.036333
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 358
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: -0.198834
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 359
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.106205
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 360
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.197959
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 361
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.195511
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 362
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: -0.071288
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 363
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -0.194654
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 364
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: -0.222412
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0861969
New value of Value function: 0.463812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 0.493882
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 367
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.0705162
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 368
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: -0.0697599
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 369
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.0690187
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 370
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: -0.104735
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 371
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.103294
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 372
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: -0.249074
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.120311
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0933628
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.126795
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.133149
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0683339
New value of Value function: 0.493882
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 49
New value of Q matrix: 0.52335
New value of Value function: 0.52335
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 379
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: -0.0682923
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 380
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: -0.0675804
New value of Value function: -0.036333
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 381
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.0362603
New value of Value function: -0.0362603
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 382
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: -0.0361878
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 383
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.192253
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 384
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: -0.10188
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 385
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: -0.184247
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 386
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 0.18804
New value of Value function: 0.18804
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 387
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.125854
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 388
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.0289208
New value of Value function: 0.18804
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 389
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0861298
New value of Value function: 0.334758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.0909765
New value of Value function: 0.334758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 391
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.168566
New value of Value function: 0.18804
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0951826
New value of Value function: 0.334758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 393
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.330328
New value of Value function: 0.330328
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0402116
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 395
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: -0.0668802
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 396
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: -0.103277
New value of Value function: -0.0361878
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 397
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.116352
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: -0.0361154
New value of Value function: -0.0361154
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 399
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: -0.100492
New value of Value function: -0.0361154
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 400
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: -0.0360432
New value of Value function: -0.0360432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 401
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: -0.10186
New value of Value function: -0.0360432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 402
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.181211
New value of Value function: -0.0360432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 403
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: -0.0991313
New value of Value function: -0.0360432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 404
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: -0.100472
New value of Value function: -0.0360432
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 405
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: -0.0730569
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 406
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0779851
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 407
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: -0.134883
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 408
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.11629
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 409
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0780923
New value of Value function: 0.125854
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 410
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: -0.274672
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 411
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 0.551568
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 412
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: -0.215321
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 413
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.129283
New value of Value function: 0.129283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 414
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.326049
New value of Value function: 0.326049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 415
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.132566
New value of Value function: 0.132566
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 416
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00586887
New value of Value function: 0.326049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 417
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0991478
New value of Value function: 0.326049
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 418
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.325396
New value of Value function: 0.325396
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 419
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0902644
New value of Value function: 0.325396
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 420
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0943162
New value of Value function: 0.325396
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 421
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 0.357574
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: -0.244578
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 423
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.103601
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 424
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.0890074
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 425
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.182964
New value of Value function: 0.182964
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 426
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.270494
New value of Value function: -0.0730569
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 427
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: -0.0729108
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 428
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: -0.240999
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 429
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: -0.169799
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 430
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.136351
New value of Value function: 0.136351
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 431
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0936636
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 432
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0982266
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 433
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0121878
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 434
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0119441
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 435
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 436
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 437
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00643632
New value of Value function: 0.00643632
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 438
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0988662
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 439
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.102698
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 440
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.107081
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 441
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.103325
New value of Value function: 0.357574
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 442
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 0.393715
New value of Value function: 0.393715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 443
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.177992
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 444
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: -0.099775
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 445
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: -0.167716
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 446
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: -0.232975
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 447
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: -0.198108
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 448
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.108346
New value of Value function: 0.393715
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 449
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 0.424529
New value of Value function: 0.424529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 450
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: -0.0990919
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 451
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: -0.266396
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 452
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: -0.229628
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 453
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: -0.161158
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 454
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.0607009
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 455
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.011821
New value of Value function: 0.424529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 456
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0139491
New value of Value function: 0.0139491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 457
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.11382
New value of Value function: 0.424529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 458
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0118357
New value of Value function: 0.424529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 459
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000251084
New value of Value function: 0.0139491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000251084
New value of Value function: 0.0139491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000497146
New value of Value function: 0.0139491
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0213116
New value of Value function: 0.0213116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.112581
New value of Value function: 0.424529
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 464
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.42368
New value of Value function: 0.42368
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 0.453894
New value of Value function: 0.453894
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 466
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: -0.0984224
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 467
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: -0.256866
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 468
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 0.153533
New value of Value function: 0.453894
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 469
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0733796
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 470
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: -0.0977664
New value of Value function: -0.0729108
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 471
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: -0.072765
New value of Value function: -0.072765
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 472
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: -0.248524
New value of Value function: -0.072765
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 473
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: -0.225976
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 474
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 0.483506
New value of Value function: 0.483506
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 475
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.0726195
New value of Value function: -0.0726195
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 476
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: -0.0724742
New value of Value function: -0.0724742
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 477
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 34
New value of Q matrix: -0.19548
New value of Value function: -0.0724742
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 478
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 0.15266
New value of Value function: 0.15266
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 479
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: -0.0723293
New value of Value function: -0.0723293
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 480
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: -0.192872
New value of Value function: -0.0723293
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 481
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: -0.0721846
New value of Value function: -0.0721846
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 482
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: -0.0971104
New value of Value function: -0.0721846
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 483
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: -0.262367
New value of Value function: -0.0721846
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 484
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 0.0292591
New value of Value function: 0.0292591
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 485
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000526663
New value of Value function: 0.000526663
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 486
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: -0.0946415
New value of Value function: 0.0292591
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 487
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: -0.287192
New value of Value function: 0.0292591
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.101424
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.140414
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0668695
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.109324
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.147534
New value of Value function: 0.551568
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.550465
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0768756
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.154491
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 0.19415
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 497
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 0.174151
New value of Value function: 0.174151
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: -0.188488
New value of Value function: 0.0292591
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 499
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: -0.280921
New value of Value function: 0.0292591
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 500
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: -0.00141773
New value of Value function: -0.00141773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0754405
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 502
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0852464
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 503
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.08384
New value of Value function: 0.550465
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 504
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.549364
New value of Value function: 0.549364
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 505
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.548265
New value of Value function: 0.548265
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 506
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 54
New value of Q matrix: 0.577274
New value of Value function: 0.577274
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 507
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: -0.184744
New value of Value function: -0.00141773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 508
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: -0.304912
New value of Value function: -0.00141773
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 509
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 55
New value of Q matrix: 0.605703
New value of Value function: 0.605703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 510
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: -0.0014149
New value of Value function: -0.0014149
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 511
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: -0.24035
New value of Value function: -0.0014149
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 512
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.218252
New value of Value function: 0.177992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 513
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.174407
New value of Value function: 0.174407
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 514
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: -0.00141207
New value of Value function: -0.00141207
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 515
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: -0.00140925
New value of Value function: -0.00140925
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 516
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: -0.232404
New value of Value function: -0.00140925
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 517
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0563476
New value of Value function: 0.174407
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 518
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.174058
New value of Value function: 0.174058
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 519
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.170552
New value of Value function: 0.170552
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 520
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: -0.00140643
New value of Value function: -0.00140643
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 521
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 0.0986312
New value of Value function: 0.0986312
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 522
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00229149
New value of Value function: 0.00229149
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 523
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 0.1967
New value of Value function: 0.1967
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 524
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0290973
New value of Value function: 0.00229149
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 525
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0930659
New value of Value function: 0.605703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 526
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.604492
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 527
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.201147
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 528
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.208005
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 529
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0944223
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.102085
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.103415
New value of Value function: 0.604492
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.603283
New value of Value function: 0.603283
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 0.634758
New value of Value function: 0.634758
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 534
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: -0.081008
New value of Value function: 0.1967
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 535
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0570898
New value of Value function: 0.00229149
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.111469
New value of Value function: 0.634758
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.633488
New value of Value function: 0.633488
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 60
New value of Q matrix: 0.664359
New value of Value function: 0.664359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 539
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.196306
New value of Value function: 0.196306
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 540
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: -0.326855
New value of Value function: 0.196306
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.215804
New value of Value function: 0.664359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.121198
New value of Value function: 0.664359
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.66303
New value of Value function: 0.66303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 62
New value of Q matrix: 0.693303
New value of Value function: 0.693303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 545
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 0.292422
New value of Value function: 0.292422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 546
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00750925
New value of Value function: 0.00750925
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 547
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: -0.222492
New value of Value function: 0.292422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 548
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: -0.315055
New value of Value function: 0.292422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 549
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 0.0073865
New value of Value function: 0.292422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 550
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00526359
New value of Value function: 0.00750925
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 551
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: -0.0763179
New value of Value function: 0.292422
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 552
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.172404
New value of Value function: 0.172404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 553
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.291837
New value of Value function: 0.291837
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 554
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: -0.336274
New value of Value function: 0.291837
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.131254
New value of Value function: 0.693303
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.691917
New value of Value function: 0.691917
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 64
New value of Q matrix: 0.723331
New value of Value function: 0.723331
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 558
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: -0.0695385
New value of Value function: 0.291837
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 559
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 0.386135
New value of Value function: 0.386135
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 560
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00826159
New value of Value function: 0.00826159
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 561
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.175906
New value of Value function: 0.175906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 562
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 0.478561
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 563
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.082928
New value of Value function: 0.00826159
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.224508
New value of Value function: 0.723331
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 565
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 65
New value of Q matrix: 0.757479
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 566
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: -0.355914
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 567
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.233652
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 568
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.142263
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 569
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.120772
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 570
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.153053
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 571
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.114981
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 572
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.126316
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 573
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.137424
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 574
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.131991
New value of Value function: 0.757479
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 575
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.755964
New value of Value function: 0.755964
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.242586
New value of Value function: 0.755964
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 577
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.142958
New value of Value function: 0.755964
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 578
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.754452
New value of Value function: 0.754452
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 579
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.251315
New value of Value function: 0.754452
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 580
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.163572
New value of Value function: 0.754452
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 581
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.752943
New value of Value function: 0.752943
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 582
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 69
New value of Q matrix: 0.786498
New value of Value function: 0.786498
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 583
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: -0.0595336
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 584
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: -0.0497289
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 585
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 34
New value of Q matrix: -0.374639
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 586
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 70
New value of Q matrix: 0.819383
New value of Value function: 0.819383
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 587
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: -0.392397
New value of Value function: 0.478561
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 588
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.154848
New value of Value function: 0.819383
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 589
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 71
New value of Q matrix: 0.851609
New value of Value function: 0.851609
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 590
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.477604
New value of Value function: 0.477604
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 591
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.476649
New value of Value function: 0.476649
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 592
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: -0.40922
New value of Value function: 0.476649
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 593
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.175629
New value of Value function: 0.851609
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 594
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.261617
New value of Value function: 0.851609
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 595
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.849906
New value of Value function: 0.849906
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 596
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 73
New value of Q matrix: 0.881487
New value of Value function: 0.881487
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 597
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 37
New value of Q matrix: -0.425169
New value of Value function: 0.476649
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 598
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 74
New value of Q matrix: 0.912437
New value of Value function: 0.912437
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 599
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.475695
New value of Value function: 0.475695
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 600
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 38
New value of Q matrix: -0.440242
New value of Value function: 0.475695
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 601
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 75
New value of Q matrix: 0.942751
New value of Value function: 0.942751
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 602
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 39
New value of Q matrix: -0.454467
New value of Value function: 0.475695
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 603
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.189086
New value of Value function: 0.942751
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 604
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.940866
New value of Value function: 0.940866
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 605
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 77
New value of Q matrix: 0.970611
New value of Value function: 0.970611
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.474744
New value of Value function: 0.474744
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 607
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 0.565374
New value of Value function: 0.565374
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 608
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000124481
New value of Value function: 0.00691559
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 609
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.016954
New value of Value function: 0.016954
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 610
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: -0.214876
New value of Value function: 0.565374
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 611
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0520543
New value of Value function: 0.175906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 612
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.175555
New value of Value function: 0.175555
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 613
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0478532
New value of Value function: 0.175555
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 614
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.062178
New value of Value function: 0.175555
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 615
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0687521
New value of Value function: 0.175555
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 616
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.175204
New value of Value function: 0.175204
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 617
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0673446
New value of Value function: 0.175204
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 618
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 0.100305
New value of Value function: 0.100305
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 619
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0184204
New value of Value function: 0.0184204
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 620
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00491766
New value of Value function: 0.100305
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 621
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0641922
New value of Value function: 0.175204
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 622
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0982991
New value of Value function: 0.0982991
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 623
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 624
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 0.100332
New value of Value function: 0.100332
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 625
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00186758
New value of Value function: 0.0184204
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 626
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 0.100332
New value of Value function: 0.100332
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000453558
New value of Value function: 0.0184204
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 628
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.019858
New value of Value function: 0.019858
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 629
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 0.1
New value of Value function: 0.100332
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 630
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00176938
New value of Value function: 0.00176938
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 631
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00176938
New value of Value function: 0.0982991
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 632
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0982991
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 633
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 634
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00315366
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 635
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.173469
New value of Value function: 0.173469
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 636
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00312244
New value of Value function: 0.0982991
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 637
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.171769
New value of Value function: 0.171769
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 638
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 0.196691
New value of Value function: 0.196691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 639
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0230012
New value of Value function: 0.0230012
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 640
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00527443
New value of Value function: 0.196691
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 641
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 0.293171
New value of Value function: 0.293171
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 642
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0225731
New value of Value function: 0.0225731
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 643
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00527707
New value of Value function: 0.00527707
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 644
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00791115
New value of Value function: 0.293171
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 645
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.170139
New value of Value function: 0.170139
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 646
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 0.198731
New value of Value function: 0.198731
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 647
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0225279
New value of Value function: 0.0225279
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 648
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0637365
New value of Value function: 0.0225279
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 649
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000468372
New value of Value function: 0.0225279
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 650
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0224829
New value of Value function: 0.0224829
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 651
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0620571
New value of Value function: 0.0224829
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 652
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0224379
New value of Value function: 0.0224379
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 653
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0250517
New value of Value function: 0.0250517
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 654
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0438337
New value of Value function: 0.170139
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 655
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0429002
New value of Value function: 0.170139
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 656
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.67659e-05
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 657
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.67659e-05
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 658
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000112397
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 659
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.67659e-05
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 660
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000166915
New value of Value function: 0.00315366
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 661
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0061531
New value of Value function: 0.0061531
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 662
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.169799
New value of Value function: 0.169799
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 663
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 0.266854
New value of Value function: 0.266854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 664
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.029354
New value of Value function: 0.029354
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 665
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0372388
New value of Value function: 0.266854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 666
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0363833
New value of Value function: 0.266854
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 667
----------
State: 805
	Distance: 5
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0108334
New value of Value function: 0.0108334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 668
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.26632
New value of Value function: 0.26632
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 669
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 0.361522
New value of Value function: 0.361522
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 670
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0352743
New value of Value function: 0.0352743
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 671
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 0.454927
New value of Value function: 0.454927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 672
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.012007
New value of Value function: 0.0352743
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 673
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.557643
New value of Value function: 0.557643
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 674
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 0.19896
New value of Value function: 0.19896
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 675
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0398459
New value of Value function: 0.0398459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 676
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 0.388025
New value of Value function: 0.388025
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 677
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00404028
New value of Value function: 0.0398459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 678
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 0.295474
New value of Value function: 0.295474
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 679
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0046767
New value of Value function: 0.0398459
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 680
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0443675
New value of Value function: 0.0443675
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 681
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 0.390363
New value of Value function: 0.390363
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 682
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.0833449
New value of Value function: 0.0443675
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 683
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 78
New value of Q matrix: 0.991997
New value of Value function: 0.991997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 684
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0012431
New value of Value function: 0.0443675
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 685
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0505067
New value of Value function: 0.0505067
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 686
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00702653
New value of Value function: 0.390363
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 687
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.104984
New value of Value function: 0.390363
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 688
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.387291
New value of Value function: 0.387291
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 689
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00702653
New value of Value function: 0.390363
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 690
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 0.483465
New value of Value function: 0.483465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 691
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0126759
New value of Value function: 0.0505067
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 692
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00549229
New value of Value function: 0.0505067
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 693
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0581989
New value of Value function: 0.0581989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 694
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 0.574843
New value of Value function: 0.574843
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 695
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.01347
New value of Value function: 0.0581989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 696
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.103822
New value of Value function: 0.0581989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 697
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.274241
New value of Value function: 0.991997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 698
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.152532
New value of Value function: 0.991997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 699
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.167337
New value of Value function: 0.991997
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 700
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 79
New value of Q matrix: 1.0132
New value of Value function: 1.0132
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 701
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0673821
New value of Value function: 0.0673821
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 702
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.664559
New value of Value function: 0.664559
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 703
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0779966
New value of Value function: 0.0779966
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 704
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0169236
New value of Value function: 0.664559
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 705
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 0.647894
New value of Value function: 0.647894
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 706
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0846253
New value of Value function: 0.0846253
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 707
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0559372
New value of Value function: 0.454927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 708
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.481068
New value of Value function: 0.481068
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 709
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.091592
New value of Value function: 0.091592
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 710
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 0.100095
New value of Value function: 0.481068
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 711
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00865922
New value of Value function: 0.00865922
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 712
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0159416
New value of Value function: 0.481068
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 713
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.45749
New value of Value function: 0.45749
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 714
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0192008
New value of Value function: 0.647894
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 715
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 0.752917
New value of Value function: 0.752917
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 716
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0070311
New value of Value function: 0.091592
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 717
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0148493
New value of Value function: 0.091592
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 718
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.097995
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 719
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.461893
New value of Value function: 0.461893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 720
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 0.716096
New value of Value function: 0.716096
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 721
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.182228
New value of Value function: 1.0132
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 722
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 80
New value of Q matrix: 1.0347
New value of Value function: 1.0347
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 723
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00865439
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 724
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0163162
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 725
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: -0.123121
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 726
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.197208
New value of Value function: 1.0347
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 727
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 81
New value of Q matrix: 1.05577
New value of Value function: 1.05577
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 728
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0102452
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 729
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.141655
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 730
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.170755
New value of Value function: 1.05577
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 731
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 82
New value of Q matrix: 1.07642
New value of Value function: 1.07642
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 732
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: -0.159446
New value of Value function: 0.097995
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 733
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.288132
New value of Value function: 1.07642
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 734
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 83
New value of Q matrix: 1.10778
New value of Value function: 1.10778
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 735
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 0.681714
New value of Value function: 0.681714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 736
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 84
New value of Q matrix: 1.12739
New value of Value function: 1.12739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 737
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.104349
New value of Value function: 0.104349
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 738
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0431563
New value of Value function: 0.461893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 739
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 0.736815
New value of Value function: 0.736815
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 740
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0223112
New value of Value function: 0.104349
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 741
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.111199
New value of Value function: 0.681714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 742
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0273416
New value of Value function: 0.461893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 743
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.460969
New value of Value function: 0.460969
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 744
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.20559
New value of Value function: 0.460969
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 745
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.460047
New value of Value function: 0.460047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 746
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0526536
New value of Value function: 0.460047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 747
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.193197
New value of Value function: 0.460047
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 748
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 0.552725
New value of Value function: 0.552725
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 749
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: -0.175964
New value of Value function: 0.104349
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 750
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.187633
New value of Value function: 1.12739
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 751
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 85
New value of Q matrix: 1.15712
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 752
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 0.648908
New value of Value function: 0.648908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 753
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.206133
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 754
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.204708
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 755
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.303197
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 756
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.222838
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 757
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.239209
New value of Value function: 1.15712
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 758
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 1.1548
New value of Value function: 1.1548
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 759
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 1.15249
New value of Value function: 1.15249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 760
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.25517
New value of Value function: 1.15249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 761
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.214009
New value of Value function: 1.15249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 762
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 1.15019
New value of Value function: 1.15019
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 763
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 1.14789
New value of Value function: 1.14789
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 764
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 90
New value of Q matrix: 1.17661
New value of Value function: 1.17661
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 765
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0298478
New value of Value function: 0.648908
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 766
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: -0.0354716
New value of Value function: 0.736815
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 767
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.735341
New value of Value function: 0.735341
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 768
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.032053
New value of Value function: 0.735341
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 769
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: -0.200629
New value of Value function: 0.735341
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 770
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.554906
New value of Value function: 0.554906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 771
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 40
New value of Q matrix: -0.484658
New value of Value function: 0.735341
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 772
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.0937169
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 773
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.318312
New value of Value function: 1.17661
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 774
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 91
New value of Q matrix: 1.19323
New value of Value function: 1.19323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 775
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0132361
New value of Value function: 0.0132361
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 776
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.732315
New value of Value function: 0.732315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 777
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 0.617408
New value of Value function: 0.617408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 778
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.231207
New value of Value function: 1.19323
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 779
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 1.19084
New value of Value function: 1.19084
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 780
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 93
New value of Q matrix: 1.2202
New value of Value function: 1.2202
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 781
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: -0.186628
New value of Value function: 0.732315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 782
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0168064
New value of Value function: 0.554906
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 783
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.553797
New value of Value function: 0.553797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 784
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0416322
New value of Value function: 0.553797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 785
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.179365
New value of Value function: 0.553797
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 786
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.555902
New value of Value function: 0.555902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 787
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 41
New value of Q matrix: -0.514245
New value of Value function: 0.732315
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 788
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.109879
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 789
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 94
New value of Q matrix: 1.23652
New value of Value function: 1.23652
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 790
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0923817
New value of Value function: 0.0923817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 791
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 0.819547
New value of Value function: 0.819547
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 792
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.112268
New value of Value function: 0.112268
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 793
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 0.645022
New value of Value function: 0.645022
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 794
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.0990121
New value of Value function: 0.0132361
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 795
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.272324
New value of Value function: 1.23652
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 796
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.24884
New value of Value function: 1.23652
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 797
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.289135
New value of Value function: 1.23652
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 798
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 1.23405
New value of Value function: 1.23405
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 799
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 1.23158
New value of Value function: 1.23158
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 800
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 97
New value of Q matrix: 1.24897
New value of Value function: 1.24897
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 801
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.121633
New value of Value function: 0.121633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 802
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 0.734311
New value of Value function: 0.734311
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 803
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: -0.189963
New value of Value function: 0.121633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 804
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.223096
New value of Value function: 1.24897
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 805
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 98
New value of Q matrix: 1.26618
New value of Value function: 1.26618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 806
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0240543
New value of Value function: 0.121633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 807
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: -0.203373
New value of Value function: 0.121633
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 808
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.306143
New value of Value function: 1.26618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 809
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.241425
New value of Value function: 1.26618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 810
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.259388
New value of Value function: 1.26618
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 811
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 1.26365
New value of Value function: 1.26365
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 812
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 100
New value of Q matrix: 1.28949
New value of Value function: 1.28949
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 813
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0179993
New value of Value function: 0.617408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 814
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 0.58827
New value of Value function: 0.58827
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 815
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 101
New value of Q matrix: 1.31429
New value of Value function: 1.31429
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 816
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 0.560162
New value of Value function: 0.560162
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 817
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.323678
New value of Value function: 1.31429
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 818
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 1.31166
New value of Value function: 1.31166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 819
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.335556
New value of Value function: 1.31166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 820
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.340814
New value of Value function: 1.31166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 821
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 1.30903
New value of Value function: 1.30903
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 822
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 104
New value of Q matrix: 1.32309
New value of Value function: 1.32309
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 823
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0021894
New value of Value function: 0.0132361
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 824
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.132418
New value of Value function: 0.132418
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 825
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 0.822009
New value of Value function: 0.822009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 826
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.144566
New value of Value function: 0.144566
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 827
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 0.908171
New value of Value function: 0.908171
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 828
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0307417
New value of Value function: 0.144566
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 829
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 0.905758
New value of Value function: 0.905758
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 830
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0336562
New value of Value function: 0.144566
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 831
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 0.532775
New value of Value function: 0.532775
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 832
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 105
New value of Q matrix: 1.34622
New value of Value function: 1.34622
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 833
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 0.506351
New value of Value function: 0.506351
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 834
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 106
New value of Q matrix: 1.36841
New value of Value function: 1.36841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 835
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 0.480855
New value of Value function: 0.480855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 836
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.278831
New value of Value function: 1.36841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 837
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 57
New value of Q matrix: 0.370508
New value of Value function: 1.36841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 838
----------
State: 33
	Distance: 0
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0426022
New value of Value function: 0.0923817
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 839
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.157979
New value of Value function: 0.157979
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 840
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.903946
New value of Value function: 0.903946
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 841
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 0.988711
New value of Value function: 0.988711
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 842
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.171166
New value of Value function: 0.171166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 843
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 0.993088
New value of Value function: 0.993088
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 844
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00429923
New value of Value function: 0.171166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 845
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.036064
New value of Value function: 0.171166
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 846
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.176402
New value of Value function: 0.176402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 847
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0138282
New value of Value function: 0.481068
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 848
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 0.574622
New value of Value function: 0.574622
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 849
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0387823
New value of Value function: 0.176402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 850
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0262948
New value of Value function: 0.480855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 851
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.12685
New value of Value function: 0.480855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 852
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.981882
New value of Value function: 0.981882
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 853
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 0.298156
New value of Value function: 0.480855
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 854
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00738848
New value of Value function: 0.176402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 855
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0104159
New value of Value function: 0.176402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 856
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0133829
New value of Value function: 0.176402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 857
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.176049
New value of Value function: 0.176049
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 858
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.172684
New value of Value function: 0.172684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 859
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00188986
New value of Value function: 0.00865922
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 860
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0155147
New value of Value function: 0.0155147
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 861
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 0.663409
New value of Value function: 0.663409
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 862
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0137934
New value of Value function: 0.0155147
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 863
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 0.75042
New value of Value function: 0.75042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 864
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0219936
New value of Value function: 0.0219936
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 865
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 0.83852
New value of Value function: 0.83852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 866
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0384511
New value of Value function: 0.172684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 867
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0162235
New value of Value function: 0.172684
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 868
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.169626
New value of Value function: 0.169626
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 869
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000395885
New value of Value function: 0.0219936
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 870
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0219496
New value of Value function: 0.0219496
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 871
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.036604
New value of Value function: 0.036604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 872
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0307161
New value of Value function: 0.83852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 873
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0477757
New value of Value function: 0.83852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 874
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 1.0629
New value of Value function: 1.0629
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 875
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0154813
New value of Value function: 0.036604
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 876
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 0.201146
New value of Value function: 0.83852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 877
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.181327
New value of Value function: 0.181327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 878
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0619135
New value of Value function: 0.83852
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 879
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 0.922408
New value of Value function: 0.922408
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 880
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0550042
New value of Value function: 0.0550042
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 881
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 1.0503
New value of Value function: 1.0503
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 882
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 0.45587
New value of Value function: 0.45587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 883
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.297886
New value of Value function: 1.36841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 884
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.358629
New value of Value function: 1.36841
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 885
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 1.36567
New value of Value function: 1.36567
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 886
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.31651
New value of Value function: 1.36567
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 887
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 108
New value of Q matrix: 1.38162
New value of Value function: 1.38162
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 888
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: -0.214436
New value of Value function: 0.181327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 889
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 109
New value of Q matrix: 1.4022
New value of Value function: 1.4022
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 890
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.143219
New value of Value function: 0.45587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 891
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.156872
New value of Value function: 1.0503
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 892
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0218941
New value of Value function: 1.0503
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 893
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0233878
New value of Value function: 1.0503
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 894
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.134829
New value of Value function: 1.0503
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 895
----------
State: 781
	Distance: 5
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 1.12953
New value of Value function: 1.12953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 896
----------
State: 613
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0054095
New value of Value function: 0.0132361
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 897
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0558034
New value of Value function: 0.181327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 898
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: -0.0169654
New value of Value function: 0.988711
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 899
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.00117074
New value of Value function: 0.988711
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 900
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: -0.486163
New value of Value function: 0.988711
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 901
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 1.0722
New value of Value function: 1.0722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 902
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0191629
New value of Value function: 0.181327
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 903
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.197
New value of Value function: 0.197
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 904
----------
State: 757
	Distance: 5
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: -0.372894
New value of Value function: 1.0722
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 905
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.041228
New value of Value function: 0.197
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 906
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0439495
New value of Value function: 0.197
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 907
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.196606
New value of Value function: 0.196606
New value of Policy matrix: 0

