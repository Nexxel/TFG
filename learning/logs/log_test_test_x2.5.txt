=======================================
Simulation: 1
Iteration: 1
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 2
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 7
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 8
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0385744
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0407056
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 10
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.0763773
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 12
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 40
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 41
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 0.02
New value of Value function: 0.02
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 42
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 0.07956
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 45
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00036
New value of Value function: 0.02
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 46
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0007128
New value of Value function: 0.02
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 47
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00036
New value of Value function: 0.02
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 48
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.01996
New value of Value function: 0.01996
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 49
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.0777679
New value of Value function: 0.01996
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00143208
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00283552
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00143208
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00143208
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00421089
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00555875
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00687966
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00213768
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00283552
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00352701
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00488855
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00622286
New value of Value function: 0.07956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0794009
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00817128
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00283265
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00420522
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00752761
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00420802
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00555033
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00880628
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0100594
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00555308
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00686854
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00816038
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0112874
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0124909
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00943707
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0106775
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0118932
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0136703
New value of Value function: 0.0794009
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0792421
New value of Value function: 0.0792421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00942353
New value of Value function: 0.0792421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0106614
New value of Value function: 0.0792421
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0790836
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0130788
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0118717
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00686552
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0142408
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0130578
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0153795
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0164954
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.017589
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00815172
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0142201
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0186607
New value of Value function: 0.0790836
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0789254
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0153564
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0148175
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0197081
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00940934
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0106418
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0164699
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0207346
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0159418
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0170436
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0175612
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0186306
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0217406
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0181234
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0196786
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0191816
New value of Value function: 0.0789254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0787676
New value of Value function: 0.0787676
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0202158
New value of Value function: 0.0787676
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0212293
New value of Value function: 0.0787676
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.07861
New value of Value function: 0.07861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.011844
New value of Value function: 0.07861
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0784528
New value of Value function: 0.0784528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0222169
New value of Value function: 0.0784528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0782959
New value of Value function: 0.0782959
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0206944
New value of Value function: 0.0782959
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0781393
New value of Value function: 0.0781393
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.077983
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0130108
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0227095
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0231762
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0216842
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0226542
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.023659
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0241164
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0245895
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0255014
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.0141543
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0152749
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0163731
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0263951
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0236048
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0250378
New value of Value function: 0.077983
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0778271
New value of Value function: 0.0778271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0272681
New value of Value function: 0.0778271
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0776714
New value of Value function: 0.0776714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0259351
New value of Value function: 0.0776714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0268145
New value of Value function: 0.0776714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0281208
New value of Value function: 0.0776714
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0775161
New value of Value function: 0.0775161
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0289537
New value of Value function: 0.0775161
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.077361
New value of Value function: 0.077361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0276707
New value of Value function: 0.077361
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0772063
New value of Value function: 0.0772063
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0297643
New value of Value function: 0.0772063
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0770519
New value of Value function: 0.0770519
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 0.11587
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 151
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.04
New value of Value function: 0.01996
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 152
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0014256
New value of Value function: 0.0014256
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 153
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0413171
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 154
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0014256
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 155
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.0792
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 156
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 157
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 159
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 160
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0407056
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.07848
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 165
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 166
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 167
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014383
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 168
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014383
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 169
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000732701
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 170
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000732701
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 171
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00145075
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 172
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00214365
New value of Value function: 0.0407056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 173
----------
State: 105
	Distance: 0
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.0804907
New value of Value function: 0.0804907
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 174
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0392673
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0406242
New value of Value function: 0.0406242
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 176
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0405317
New value of Value function: 0.0405317
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 177
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0014256
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 178
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00213911
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 179
----------
State: 81
	Distance: 0
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0404411
New value of Value function: 0.0404411
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 180
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00211709
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 181
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 182
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.0792
New value of Value function: 0.0792
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 183
----------
State: 777
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0379143
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0181313
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0312547
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0198543
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0327153
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.0631327
New value of Value function: 0.11587
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 0.02
New value of Value function: 0.02
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 192
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00036
New value of Value function: 0.00036
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00036
New value of Value function: 0.02
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 194
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.01996
New value of Value function: 0.01996
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 195
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00035928
New value of Value function: 0.01996
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 196
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00035928
New value of Value function: 0.01996
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 197
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0382223
New value of Value function: 0.01996
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 198
----------
State: 57
	Distance: 0
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 0.117975
New value of Value function: 0.117975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 199
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 0.0203593
New value of Value function: 0.0203593
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 200
----------
State: 609
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.000366467
New value of Value function: 0.000366467
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 201
----------
State: 753
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.0179622
New value of Value function: 0.01996
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.115638
New value of Value function: 0.115638
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.115407
New value of Value function: 0.115407
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.115176
New value of Value function: 0.115176
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0215304
New value of Value function: 0.115176
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0639432
New value of Value function: 0.115176
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.114946
New value of Value function: 0.114946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.03413
New value of Value function: 0.114946
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.114716
New value of Value function: 0.114716
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.114487
New value of Value function: 0.114487
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.029178
New value of Value function: 0.114487
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0647251
New value of Value function: 0.114487
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0654914
New value of Value function: 0.114487
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0231605
New value of Value function: 0.114487
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.114258
New value of Value function: 0.114258
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.114029
New value of Value function: 0.114029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.113801
New value of Value function: 0.113801
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.113573
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0306388
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0320703
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0247416
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0262911
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0278096
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0334733
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0348481
New value of Value function: 0.113573
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.113346
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0354876
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0361914
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0292937
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0368181
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0662218
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0669376
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0676391
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.030748
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0683265
New value of Value function: 0.113346
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.11312
New value of Value function: 0.11312
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.112893
New value of Value function: 0.112893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0689921
New value of Value function: 0.112893
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.112668
New value of Value function: 0.112668
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0374956
New value of Value function: 0.112668
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.112442
New value of Value function: 0.112442
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.112217
New value of Value function: 0.112217
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0381016
New value of Value function: 0.112217
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0393595
New value of Value function: 0.112217
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.111993
New value of Value function: 0.111993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0696281
New value of Value function: 0.111993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.111769
New value of Value function: 0.111769
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0702474
New value of Value function: 0.111769
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0708543
New value of Value function: 0.111769
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.111545
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0321409
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0387535
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0399862
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0405801
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0417764
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0429487
New value of Value function: 0.111545
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.111322
New value of Value function: 0.111322
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.071441
New value of Value function: 0.111322
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.1111
New value of Value function: 0.1111
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0411863
New value of Value function: 0.1111
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0423624
New value of Value function: 0.1111
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.110878
New value of Value function: 0.110878
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.110656
New value of Value function: 0.110656
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.110434
New value of Value function: 0.110434
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0440775
New value of Value function: 0.110434
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.110214
New value of Value function: 0.110214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.071996
New value of Value function: 0.110214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0334819
New value of Value function: 0.110214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.07254
New value of Value function: 0.110214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.109993
New value of Value function: 0.109993
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.109773
New value of Value function: 0.109773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0451719
New value of Value function: 0.109773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.043491
New value of Value function: 0.109773
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.109554
New value of Value function: 0.109554
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.109335
New value of Value function: 0.109335
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0347803
New value of Value function: 0.109335
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.109116
New value of Value function: 0.109116
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.108898
New value of Value function: 0.108898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0360449
New value of Value function: 0.108898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0372841
New value of Value function: 0.108898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0462286
New value of Value function: 0.108898
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.10868
New value of Value function: 0.10868
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.108462
New value of Value function: 0.108462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0730415
New value of Value function: 0.108462
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.108246
New value of Value function: 0.108246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0472524
New value of Value function: 0.108246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0445696
New value of Value function: 0.108246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0384869
New value of Value function: 0.108246
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.108029
New value of Value function: 0.108029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0456228
New value of Value function: 0.108029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0466548
New value of Value function: 0.108029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.107813
New value of Value function: 0.107813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.048248
New value of Value function: 0.107813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0492237
New value of Value function: 0.107813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0501799
New value of Value function: 0.107813
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.107597
New value of Value function: 0.107597
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.107382
New value of Value function: 0.107382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0476546
New value of Value function: 0.107382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.03965
New value of Value function: 0.107382
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.107167
New value of Value function: 0.107167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0511053
New value of Value function: 0.107167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0520122
New value of Value function: 0.107167
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.106953
New value of Value function: 0.106953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0735058
New value of Value function: 0.106953
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.106739
New value of Value function: 0.106739
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0528932
New value of Value function: 0.106739
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.073957
New value of Value function: 0.106739
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.106526
New value of Value function: 0.106526
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.048619
New value of Value function: 0.106526
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.106313
New value of Value function: 0.106313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0495602
New value of Value function: 0.106313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.0743915
New value of Value function: 0.106313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0748173
New value of Value function: 0.106313
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.1061
New value of Value function: 0.1061
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0752307
New value of Value function: 0.1061
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0537452
New value of Value function: 0.1061
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.105888
New value of Value function: 0.105888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0545763
New value of Value function: 0.105888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.050475
New value of Value function: 0.105888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0553907
New value of Value function: 0.105888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.040763
New value of Value function: 0.105888
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.105676
New value of Value function: 0.105676
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.105465
New value of Value function: 0.105465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.0756245
New value of Value function: 0.105465
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.105254
New value of Value function: 0.105254
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.105043
New value of Value function: 0.105043
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0760028
New value of Value function: 0.105043
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0513563
New value of Value function: 0.105043
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.104833
New value of Value function: 0.104833
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.104623
New value of Value function: 0.104623
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.104414
New value of Value function: 0.104414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0522086
New value of Value function: 0.104414
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.104205
New value of Value function: 0.104205
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 0.103997
New value of Value function: 0.103997
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 0.103789
New value of Value function: 0.103789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0418159
New value of Value function: 0.103789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0530327
New value of Value function: 0.103789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 0.103581
New value of Value function: 0.103581
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 0.103374
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0561436
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0428403
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0568815
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0763435
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0538327
New value of Value function: 0.103374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 0.103168
New value of Value function: 0.103168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0546131
New value of Value function: 0.103168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0766736
New value of Value function: 0.103168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0553778
New value of Value function: 0.103168
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 0.102961
New value of Value function: 0.102961
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 0.102755
New value of Value function: 0.102755
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.0769897
New value of Value function: 0.102755
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 0.10255
New value of Value function: 0.10255
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0438294
New value of Value function: 0.10255
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0575898
New value of Value function: 0.10255
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.0772958
New value of Value function: 0.10255
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 0.102345
New value of Value function: 0.102345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.044795
New value of Value function: 0.102345
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 0.10214
New value of Value function: 0.10214
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 0.101936
New value of Value function: 0.101936
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 0.101732
New value of Value function: 0.101732
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 0.101528
New value of Value function: 0.101528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0457267
New value of Value function: 0.101528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0560978
New value of Value function: 0.101528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 0.101325
New value of Value function: 0.101325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.0775738
New value of Value function: 0.101325
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 0.101123
New value of Value function: 0.101123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0567961
New value of Value function: 0.101123
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 0.10092
New value of Value function: 0.10092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0466287
New value of Value function: 0.10092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0475127
New value of Value function: 0.10092
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 92
New value of Q matrix: 0.138902
New value of Value function: 0.138902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 372
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0399743
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 373
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0374998
New value of Value function: 0.0014256
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.0785225
New value of Value function: 0.138902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.0581604
New value of Value function: 0.138902
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 93
New value of Q matrix: 0.176483
New value of Value function: 0.176483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 377
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 0.0203528
New value of Value function: 0.0203528
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 378
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 379
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0753177
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.0801288
New value of Value function: 0.176483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 0.17613
New value of Value function: 0.17613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0601675
New value of Value function: 0.17613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 95
New value of Q matrix: 0.212608
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.109984
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.0503894
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.0823531
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0602649
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.0532085
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.084533
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.0559713
New value of Value function: 0.212608
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 0.212182
New value of Value function: 0.212182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 0.211758
New value of Value function: 0.211758
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 98
New value of Q matrix: 0.247549
New value of Value function: 0.247549
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.56608e-05
New value of Value function: 0.0014256
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 395
----------
State: 129
	Distance: 0
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.0722939
New value of Value function: 0.0014256
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 99
New value of Q matrix: 0.282598
New value of Value function: 0.282598
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 397
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0391749
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 398
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0383914
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 399
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 400
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 401
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 402
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.107785
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 403
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 404
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 405
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 406
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0384944
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 407
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 0.02
New value of Value function: 0.02
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 408
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00036635
New value of Value function: 0.00036635
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 409
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 0.0399457
New value of Value function: 0.0399457
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 410
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.59431e-06
New value of Value function: 6.59431e-06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 411
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.140542
New value of Value function: 0.00036635
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.0879291
New value of Value function: 0.282598
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 0.282032
New value of Value function: 0.282032
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 101
New value of Q matrix: 0.316398
New value of Value function: 0.316398
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 415
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000365618
New value of Value function: 0.000365618
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 416
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0376169
New value of Value function: 0.000365618
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 417
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.036858
New value of Value function: 0.000365618
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 418
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000364886
New value of Value function: 0.000364886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 419
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.56796e-06
New value of Value function: 0.000364886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 420
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: -0.172036
New value of Value function: 0.000364886
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.060547
New value of Value function: 0.316398
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 102
New value of Q matrix: 0.350077
New value of Value function: 0.350077
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 423
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.000364157
New value of Value function: 0.000364157
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 424
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000363428
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 425
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: -0.202294
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0924719
New value of Value function: 0.350077
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 0.349377
New value of Value function: 0.349377
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.0652529
New value of Value function: 0.349377
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0969113
New value of Value function: 0.349377
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 0.348678
New value of Value function: 0.348678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.0656123
New value of Value function: 0.348678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.101249
New value of Value function: 0.348678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.0702241
New value of Value function: 0.348678
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 0.347981
New value of Value function: 0.347981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.0653233
New value of Value function: 0.347981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.0750833
New value of Value function: 0.347981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.105488
New value of Value function: 0.347981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.109642
New value of Value function: 0.347981
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 0.347285
New value of Value function: 0.347285
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 0.34659
New value of Value function: 0.34659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.0705387
New value of Value function: 0.34659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.0702554
New value of Value function: 0.34659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.113688
New value of Value function: 0.34659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.117652
New value of Value function: 0.34659
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 0.345897
New value of Value function: 0.345897
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.075354
New value of Value function: 0.345897
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.0750765
New value of Value function: 0.345897
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 0.345205
New value of Value function: 0.345205
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 110
New value of Q matrix: 0.378308
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 450
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.29783e-05
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 451
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: -0.231439
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.0806565
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.122109
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.0858529
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.126476
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.130756
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.0803911
New value of Value function: 0.378308
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 0.377551
New value of Value function: 0.377551
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.0909318
New value of Value function: 0.377551
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.0855792
New value of Value function: 0.377551
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.095909
New value of Value function: 0.377551
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 0.376796
New value of Value function: 0.376796
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 0.376042
New value of Value function: 0.376042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.0906364
New value of Value function: 0.376042
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 114
New value of Q matrix: 0.408528
New value of Value function: 0.408528
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 466
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0361143
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 467
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.92605e-05
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 468
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: -0.259456
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 115
New value of Q matrix: 0.440364
New value of Value function: 0.440364
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 470
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: -0.286341
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 116
New value of Q matrix: 0.471563
New value of Value function: 0.471563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 472
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0353855
New value of Value function: 0.000363428
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 473
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.000362702
New value of Value function: 0.000362702
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 474
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.000361976
New value of Value function: 0.000361976
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 475
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.000361252
New value of Value function: 0.000361252
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 476
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.50254e-06
New value of Value function: 0.000361252
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 477
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00036053
New value of Value function: 0.00036053
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 478
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.000359809
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 479
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0346713
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 480
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.280607
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 481
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: -0.306507
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.0973118
New value of Value function: 0.471563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.136629
New value of Value function: 0.471563
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 0.47062
New value of Value function: 0.47062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.102462
New value of Value function: 0.47062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.0820461
New value of Value function: 0.47062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 561
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 118
New value of Q matrix: 0.501208
New value of Value function: 0.501208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 488
----------
State: 561
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0309783
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.142918
New value of Value function: 0.501208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.104387
New value of Value function: 0.501208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 0.500205
New value of Value function: 0.500205
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 120
New value of Q matrix: 0.530208
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 493
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.53518e-05
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 494
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.2849e-05
New value of Value function: 0.000359809
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 495
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.000372592
New value of Value function: 0.000372592
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 496
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0373645
New value of Value function: 0.02
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 497
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0744898
New value of Value function: 0.02
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0362572
New value of Value function: 0.02
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 499
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.020319
New value of Value function: 0.020319
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 500
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0388343
New value of Value function: 0.0399457
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 501
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 0.0399193
New value of Value function: 0.0399193
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 502
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00108369
New value of Value function: 0.00108369
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 503
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 0.0591405
New value of Value function: 0.0591405
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 504
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00212654
New value of Value function: 0.00212654
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 505
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00106453
New value of Value function: 0.0591405
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 506
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0586767
New value of Value function: 0.0586767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 507
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0398659
New value of Value function: 0.0398659
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 508
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0397861
New value of Value function: 0.0397861
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 509
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.020277
New value of Value function: 0.0397861
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 510
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0397065
New value of Value function: 0.0397065
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 511
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0205861
New value of Value function: 0.0397065
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 512
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 0.0402127
New value of Value function: 0.0402127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 513
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00314019
New value of Value function: 0.00314019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 514
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0374258
New value of Value function: 0.0586767
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 515
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0585593
New value of Value function: 0.0585593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 516
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.034478
New value of Value function: 0.0585593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 517
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0356232
New value of Value function: 0.0585593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 518
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0327344
New value of Value function: 0.0585593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 519
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0719459
New value of Value function: 0.0585593
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 520
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0584422
New value of Value function: 0.0584422
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 521
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0310277
New value of Value function: 0.0584422
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 522
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0579972
New value of Value function: 0.0579972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 523
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0370136
New value of Value function: 0.0402127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 524
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0338668
New value of Value function: 0.0579972
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 525
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0578812
New value of Value function: 0.0578812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 526
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0694651
New value of Value function: 0.0578812
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 527
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 0.0767801
New value of Value function: 0.0767801
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 528
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.300321
New value of Value function: 0.00314019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 529
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: -0.32477
New value of Value function: 0.00314019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 530
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.0899489
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 531
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.149604
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 532
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.156156
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 533
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.109957
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 534
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.0976937
New value of Value function: 0.530208
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 535
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 0.529147
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 536
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.117282
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 537
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.162557
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 538
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.168831
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 539
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.124461
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 540
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.131496
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 541
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.138391
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 542
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.145148
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 543
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.15177
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 544
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.158259
New value of Value function: 0.529147
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 545
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 0.528089
New value of Value function: 0.528089
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 546
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.17496
New value of Value function: 0.528089
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 547
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.180966
New value of Value function: 0.528089
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 548
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 0.527033
New value of Value function: 0.527033
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 549
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 0.525979
New value of Value function: 0.525979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 550
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.111767
New value of Value function: 0.525979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 551
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.105207
New value of Value function: 0.525979
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 552
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 0.524927
New value of Value function: 0.524927
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 553
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 0.523877
New value of Value function: 0.523877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 554
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.112533
New value of Value function: 0.523877
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 555
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 0.522829
New value of Value function: 0.522829
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 556
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 0.521784
New value of Value function: 0.521784
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 557
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.119674
New value of Value function: 0.521784
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 558
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 129
New value of Q matrix: 0.551404
New value of Value function: 0.551404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 559
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: -0.34835
New value of Value function: 0.00314019
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 560
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.119457
New value of Value function: 0.551404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 561
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.165019
New value of Value function: 0.551404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 562
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 0.187272
New value of Value function: 0.551404
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 563
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 0.550302
New value of Value function: 0.550302
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 564
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 131
New value of Q matrix: 0.579352
New value of Value function: 0.579352
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 565
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00313391
New value of Value function: 0.00313391
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 566
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00307135
New value of Value function: 0.00307135
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 567
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.18698e-07
New value of Value function: 6.59431e-06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 568
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.18698e-07
New value of Value function: 6.59431e-06
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 569
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00138216
New value of Value function: 0.00138216
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 570
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0318074
New value of Value function: 0.0767801
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 571
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: -0.0111713
New value of Value function: 0.0767801
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 572
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 573
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 0.02
New value of Value function: 0.02
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 574
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 575
----------
State: 633
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 576
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 577
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 578
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 579
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 580
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 581
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.48788e-05
New value of Value function: 2.48788e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 582
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.47819e-07
New value of Value function: 0.00138216
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 583
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.92601e-05
New value of Value function: 4.92601e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 584
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00137939
New value of Value function: 0.00137939
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 585
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.000360439
New value of Value function: 0.00137939
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 586
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.01996
New value of Value function: 0.01996
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 587
----------
State: 801
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 0.0200009
New value of Value function: 0.0200009
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 588
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.91616e-05
New value of Value function: 4.91616e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 589
----------
State: 657
	Distance: 4
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.30075e-05
New value of Value function: 7.30075e-05
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 590
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.00138204
New value of Value function: 0.00138204
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 591
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 0.0952694
New value of Value function: 0.0952694
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 592
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.000378107
New value of Value function: 0.00138204
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 593
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00306925
New value of Value function: 0.00306925
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 594
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00275809
New value of Value function: 0.0952694
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 595
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 0.113419
New value of Value function: 0.113419
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 596
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00504941
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 597
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 0.131206
New value of Value function: 0.131206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 598
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00537164
New value of Value function: 0.00537164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 599
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: -0.0479849
New value of Value function: 0.131206
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 600
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.000461434
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 601
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.73518e-05
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 602
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0014427
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 603
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00281392
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 604
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.130944
New value of Value function: 0.130944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 605
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: -0.0103163
New value of Value function: 0.130944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 606
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0023571
New value of Value function: 0.00504941
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 607
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 0.148422
New value of Value function: 0.148422
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 608
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00535509
New value of Value function: 0.00535509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 609
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00503931
New value of Value function: 0.00503931
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 610
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00761011
New value of Value function: 0.00761011
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 611
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.00743838
New value of Value function: 0.148422
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 612
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.146177
New value of Value function: 0.146177
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 613
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0396362
New value of Value function: 0.0402127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 614
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0336422
New value of Value function: 0.0402127
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 615
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.00465842
New value of Value function: 0.146177
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 616
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.143977
New value of Value function: 0.143977
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 617
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0401323
New value of Value function: 0.0401323
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 618
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 0.059426
New value of Value function: 0.059426
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 619
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0338815
New value of Value function: 0.00535509
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 620
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00783958
New value of Value function: 0.00783958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 621
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: -0.0268841
New value of Value function: 0.143977
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 622
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00781977
New value of Value function: 0.00781977
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 623
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00400543
New value of Value function: 0.00761011
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 624
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 19
New value of Q matrix: 0.161238
New value of Value function: 0.161238
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 625
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.000493368
New value of Value function: 0.00781977
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 626
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0105657
New value of Value function: 0.0105657
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 627
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 20
New value of Q matrix: 0.178204
New value of Value function: 0.178204
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 628
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.013562
New value of Value function: 0.013562
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 629
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 21
New value of Q matrix: 0.194884
New value of Value function: 0.194884
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 630
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0134278
New value of Value function: 0.0134278
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 631
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00743323
New value of Value function: 0.00761011
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 632
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 22
New value of Q matrix: 0.211228
New value of Value function: 0.211228
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 633
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.341141
New value of Value function: 0.0134278
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 634
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.000266545
New value of Value function: 0.0134278
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 635
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0169613
New value of Value function: 0.0169613
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 636
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 0.0228399
New value of Value function: 0.211228
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 637
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.01126
New value of Value function: 0.01126
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 638
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.00714572
New value of Value function: 0.211228
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 639
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.0261852
New value of Value function: 0.211228
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 640
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.210805
New value of Value function: 0.210805
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 641
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 0.226895
New value of Value function: 0.226895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 642
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0207062
New value of Value function: 0.0207062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 643
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.00291871
New value of Value function: 0.226895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 644
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0297456
New value of Value function: 0.226895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 645
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.000481152
New value of Value function: 0.226895
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 646
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.226441
New value of Value function: 0.226441
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 647
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0222705
New value of Value function: 0.226441
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 648
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 0.242285
New value of Value function: 0.242285
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 649
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.000856212
New value of Value function: 0.0207062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 650
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0328312
New value of Value function: 0.0207062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 651
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: -0.36389
New value of Value function: 0.0207062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 652
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 132
New value of Q matrix: 0.608138
New value of Value function: 0.608138
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 653
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.000633925
New value of Value function: 0.0207062
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 654
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0204947
New value of Value function: 0.0204947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 655
----------
State: 681
	Distance: 4
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0153959
New value of Value function: 0.0153959
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 656
----------
State: 825
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 0.257808
New value of Value function: 0.257808
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 657
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00190876
New value of Value function: 0.0204947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 658
----------
State: 849
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 0.0786064
New value of Value function: 0.0786064
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 659
----------
State: 705
	Distance: 4
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: -0.385666
New value of Value function: 0.0204947
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 660
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 0.606921
New value of Value function: 0.606921
New value of Policy matrix: 1

