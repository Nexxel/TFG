=======================================
Episode: 1
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 9
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 10
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 11
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 12
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 13
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 14
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 15
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 16
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 17
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 1.38675
New value of Value function: 1.38675
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 18
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 19
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 20
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 21
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 22
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 23
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.10011
New value of Value function: 7.10011
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 24
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -3.10029
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 25
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.38304
New value of Value function: 1.38304
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 26
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.37947
New value of Value function: 1.37947
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 27
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 3.5221
New value of Value function: 3.5221
New value of Policy matrix: 4

=======================================
Episode: 1
Iteration: 28
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 29
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 30
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 31
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 32
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.14315
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 33
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 34
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 35
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 36
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 37
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 38
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 39
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 40
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 41
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 42
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 43
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 44
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 45
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 46
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 47
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 48
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 49
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 50
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 51
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 52
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 53
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 54
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 55
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 56
----------
State: 2737
	Distance: 6
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 57
----------
State: 3137
	Distance: 7
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.9205
New value of Value function: 1.9205
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 58
----------
State: 3497
	Distance: 8
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.6715
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 59
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 60
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 61
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 63
----------
State: 3897
	Distance: 9
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 64
----------
State: 3537
	Distance: 8
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.88761
New value of Value function: 5.88761
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 3
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 4
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 5
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 6
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 7
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 8
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 9
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 10
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 11
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 12
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 13
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 14
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 15
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 16
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 17
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 18
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 19
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 20
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 21
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 22
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 23
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 24
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 25
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 26
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 27
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 28
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 29
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 30
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 31
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 32
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 33
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 2.99
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 34
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 35
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 36
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -3.44243
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 37
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 5.8255
New value of Value function: 5.8255
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 38
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 39
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 40
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 41
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 42
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 43
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.13499
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 44
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 45
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.41518
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 46
----------
State: 3453
	Distance: 8
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.33723
New value of Value function: 9.33723
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 47
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 48
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 49
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 50
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 51
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 52
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 53
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 54
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.28527
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 55
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 56
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 57
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 58
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 59
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 60
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 61
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 62
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.657635
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 63
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 64
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 65
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 66
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 67
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 68
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 69
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 70
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 71
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 72
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 73
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.9205
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 74
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 75
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 76
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.475
New value of Value function: 7.475
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 77
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: -0.376948
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 78
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 5.475
New value of Value function: 5.475
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 79
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.26795
New value of Value function: 4.9205
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 80
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 81
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.42025
New value of Value function: 4.42025
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 82
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.8327
New value of Value function: 5.475
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 83
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 5.475
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 84
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.37605
New value of Value function: 9.37605
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 85
----------
State: 2329
	Distance: 5
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.42025
New value of Value function: 4.42025
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 86
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 6.54666
New value of Value function: 6.54666
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 87
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.19813
New value of Value function: 4.9205
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 88
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 7.08744
New value of Value function: 7.08744
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 89
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.9205
New value of Value function: 4.9205
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 90
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.90456
New value of Value function: 2.90456
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 91
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.12397
New value of Value function: 5.12397
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 92
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 93
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 94
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 95
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 96
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 97
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.12449
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 98
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.98865
New value of Value function: 2.98865
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 99
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.95401
New value of Value function: 5.95401
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 100
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2.57158
New value of Value function: 2.57158
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 101
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.50018
New value of Value function: 4.50018
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 102
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 103
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 104
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 0.95
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 105
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.96565
New value of Value function: 4.96565
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 106
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.9405
New value of Value function: 0.95
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 107
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.925952
New value of Value function: 0.9405
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 108
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.94837
New value of Value function: 4.94837
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 109
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.93385
New value of Value function: 0.93385
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 110
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.928458
New value of Value function: 0.928458
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 111
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.923816
New value of Value function: 0.925952
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 112
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 0.910326
New value of Value function: 0.923816
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 113
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 4.94837
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 114
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.89889
New value of Value function: 5.89889
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 115
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.93326
New value of Value function: 4.93326
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 116
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.919684
New value of Value function: 0.919684
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 117
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0.919684
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 118
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 119
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 0.452267
New value of Value function: 0.452267
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 165
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 166
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.55226
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 0.832061
New value of Value function: 0.832061
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 168
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.17626
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.15171
New value of Value function: 1.15171
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 170
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 171
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 172
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 173
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 174
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 175
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 176
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 177
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.8399
New value of Value function: 2.8399
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 178
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.88831
New value of Value function: 5.88831
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 179
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.93326
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 180
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.88393
New value of Value function: 9.88393
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 181
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 4.92396
New value of Value function: 4.92396
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 182
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.91593
New value of Value function: 0.91593
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 183
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.912468
New value of Value function: 0.912468
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 184
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.909242
New value of Value function: 0.910326
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 185
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.04484
New value of Value function: 0.909242
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 186
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 187
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 188
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 189
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 190
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 191
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 192
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 193
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 194
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 195
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 196
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 197
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 198
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 199
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.19376
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 1.42131
New value of Value function: 1.42131
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 1
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.85788
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 2
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 3
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 4
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 5
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 6
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 7
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 8
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 9
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 10
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -1.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 11
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 12
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 13
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 14
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 15
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.0176777
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 16
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 17
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 18
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 19
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 20
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 21
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 22
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 23
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 25
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 27
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 28
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 29
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 30
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 31
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 32
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 34
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 35
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 36
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 38
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 40
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 42
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 43
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 45
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 46
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 47
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.05
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 48
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.32822
New value of Value function: 6.32822
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 49
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 50
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 51
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 52
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 53
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 54
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 55
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 56
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 57
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 58
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 59
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 60
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 61
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 62
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 63
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 64
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 65
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 66
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 67
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 68
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.42998
New value of Value function: 3.42998
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 69
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.99848
New value of Value function: 6.99848
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 70
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 71
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 72
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.44721
New value of Value function: 4.44721
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 73
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.726935
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 74
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.67289
New value of Value function: 4.67289
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 75
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.523076
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 76
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.31308
New value of Value function: 4.67289
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 77
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.79652
New value of Value function: 4.79652
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 78
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1774
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 1
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 1
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.828734
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 2
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.9188
New value of Value function: 7.9188
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 3
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.87092
New value of Value function: 6.87092
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 4
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 5
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 6
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.9605
New value of Value function: 2.9605
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 7
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.8725
New value of Value function: 4.8725
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 8
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 6.99848
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 9
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 9.19208
New value of Value function: 9.19208
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 10
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.03791
New value of Value function: 8.03791
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 11
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 38.4702
New value of Value function: 38.4702
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 12
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 98.8284
New value of Value function: 98.8284
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.3769
New value of Value function: 10.3769
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 2
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.4066
New value of Value function: 10.4066
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 3
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.18467
New value of Value function: 9.18467
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 4
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.73736
New value of Value function: 9.73736
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 5
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.98802
New value of Value function: 6.98802
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 6
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -7
New value of Value function: 2.9605
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 7
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 8
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 9
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 10
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 11
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 12
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 13
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 14
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 15
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 16
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 17
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.59291
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.41926
New value of Value function: 1.41926
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.41723
New value of Value function: 1.41723
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.230661
New value of Value function: 1.41723
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 1.41522
New value of Value function: 1.41522
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 1.41324
New value of Value function: 1.41324
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 1.41128
New value of Value function: 1.41128
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.250939
New value of Value function: 1.41128
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 1.40934
New value of Value function: 1.40934
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.419582
New value of Value function: 1.40934
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 1.40743
New value of Value function: 1.40743
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 1.40553
New value of Value function: 1.40553
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.452559
New value of Value function: 1.40553
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.575209
New value of Value function: 1.40553
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.40365
New value of Value function: 1.40365
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.245651
New value of Value function: 1.40365
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 1.40179
New value of Value function: 1.40179
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 1.39995
New value of Value function: 1.39995
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.216449
New value of Value function: 1.39995
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 1.39813
New value of Value function: 1.39813
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 1.39632
New value of Value function: 1.39632
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.396353
New value of Value function: 1.39632
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 1.39453
New value of Value function: 1.39453
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 1.39276
New value of Value function: 1.39276
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.702274
New value of Value function: 1.39276
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 1.39101
New value of Value function: 1.39101
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 1.38927
New value of Value function: 1.38927
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 1.38755
New value of Value function: 1.38755
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 1.38584
New value of Value function: 1.38584
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 1.38415
New value of Value function: 1.38415
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.806603
New value of Value function: 1.38415
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 1.38247
New value of Value function: 1.38247
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.441139
New value of Value function: 1.38247
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 1.3808
New value of Value function: 1.3808
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 1.37915
New value of Value function: 1.37915
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 1.37752
New value of Value function: 1.37752
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 1.37589
New value of Value function: 1.37589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.599088
New value of Value function: 1.37589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.543633
New value of Value function: 1.37589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.728067
New value of Value function: 1.37589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.892323
New value of Value function: 1.37589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 1.37428
New value of Value function: 1.37428
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 1.37268
New value of Value function: 1.37268
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 1.3711
New value of Value function: 1.3711
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.666311
New value of Value function: 1.3711
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 1.36953
New value of Value function: 1.36953
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.963008
New value of Value function: 1.36953
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 1.36797
New value of Value function: 1.36797
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 1.36642
New value of Value function: 1.36642
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 1.36488
New value of Value function: 1.36488
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 1.36335
New value of Value function: 1.36335
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 1.36184
New value of Value function: 1.36184
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 1.36034
New value of Value function: 1.36034
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 1.35884
New value of Value function: 1.35884
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 1.35736
New value of Value function: 1.35736
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 1.35589
New value of Value function: 1.35589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.767086
New value of Value function: 1.35589
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 1.35443
New value of Value function: 1.35443
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 1.35297
New value of Value function: 1.35297
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 1.35153
New value of Value function: 1.35153
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.606697
New value of Value function: 1.35153
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 1.3501
New value of Value function: 1.3501
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 1.34868
New value of Value function: 1.34868
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 1.34726
New value of Value function: 1.34726
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 1.34586
New value of Value function: 1.34586
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.850437
New value of Value function: 1.34586
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 1.34446
New value of Value function: 1.34446
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 1.34307
New value of Value function: 1.34307
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 1.3417
New value of Value function: 1.3417
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 1.34033
New value of Value function: 1.34033
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 1.33897
New value of Value function: 1.33897
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 1.33761
New value of Value function: 1.33761
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 1.33627
New value of Value function: 1.33627
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 1.33493
New value of Value function: 1.33493
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 1.3336
New value of Value function: 1.3336
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 1.33228
New value of Value function: 1.33228
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 1.33097
New value of Value function: 1.33097
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 1.32967
New value of Value function: 1.32967
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 1.32837
New value of Value function: 1.32837
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.825903
New value of Value function: 1.32837
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 1.32708
New value of Value function: 1.32708
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 1.3258
New value of Value function: 1.3258
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 1.4869
New value of Value function: 1.4869
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 100
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 101
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 102
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 103
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 104
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.52797
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 109
New value of Q matrix: 1.63183
New value of Value function: 1.63183
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 106
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 107
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.38449
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 110
New value of Q matrix: 1.76228
New value of Value function: 1.76228
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 109
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.95753
New value of Value function: 4.95753
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 110
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 7.99196
New value of Value function: 7.99196
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 111
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.92537
New value of Value function: 4.92537
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 112
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 6.32798
New value of Value function: 6.32798
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 113
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.25535
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 111
New value of Q matrix: 1.87976
New value of Value function: 1.87976
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 115
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 116
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 117
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 118
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 119
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 120
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 121
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 122
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 123
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 124
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 125
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 126
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 127
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 128
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 129
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 130
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 131
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 132
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 133
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 134
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 135
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 136
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 137
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 138
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.70004
New value of Value function: 2.70004
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 139
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 140
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 141
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 142
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 143
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 144
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 145
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 146
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 147
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 148
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.13904
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 112
New value of Q matrix: 1.98561
New value of Value function: 1.98561
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 150
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 151
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 152
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 153
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 154
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 155
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 156
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 157
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 158
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 159
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 160
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 161
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 162
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 0.95
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 163
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 164
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 165
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.673035
New value of Value function: 0.673035
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 166
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 2.70004
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 167
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 168
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.673035
New value of Value function: 0.673035
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 169
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.0106
New value of Value function: 4.0106
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 170
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.50018
New value of Value function: 6.50018
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 171
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 172
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 173
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.0595
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 174
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.48553
New value of Value function: 4.48553
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 175
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: 4.30254
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 176
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 12.2497
New value of Value function: 12.2497
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 177
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.0031
New value of Value function: 11.0031
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 178
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 9.73736
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 179
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 180
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 181
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 182
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 183
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 184
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 185
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 186
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 5.80185
New value of Value function: 5.80185
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 187
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 9.73736
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 188
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 11.64
New value of Value function: 11.64
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 189
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.20154
New value of Value function: 9.73736
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 190
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.84368
New value of Value function: 8.84368
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 191
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 192
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 1.95
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 193
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 194
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 195
----------
State: 2297
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 196
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.499821
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 197
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.21371
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 198
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 199
----------
State: 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 200
----------
State: 1933
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1533
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 1
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.45946
New value of Value function: 7.45946
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 2
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 4.39214
New value of Value function: 4.39214
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 3
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.0686
New value of Value function: 5.0686
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 4
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 17.9517
New value of Value function: 17.9517
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 5
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 59.9268
New value of Value function: 59.9268
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 6
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 99.5048
New value of Value function: 99.5048
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 1
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 4
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 5
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 6
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.0895
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 7
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.9105
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 8
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 9
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 10
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 11
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 12
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.40025
New value of Value function: 5.40025
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 13
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.00424
New value of Value function: 9.00424
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 14
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.60388
New value of Value function: 6.60388
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 15
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.07278
New value of Value function: 2.57158
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 16
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.95992
New value of Value function: 6.95992
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 17
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.51338
New value of Value function: 4.51338
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 18
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 5.29377
New value of Value function: 5.29377
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 19
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.9527
New value of Value function: 4.9527
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 20
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 21
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 22
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 1
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.7793
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.25046
New value of Value function: 9.25046
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.38253
New value of Value function: 8.38253
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 4
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.47077
New value of Value function: 6.47077
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 5
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.2987
New value of Value function: 9.00424
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 6
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.89429
New value of Value function: 9.89429
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 7
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 6.72678
New value of Value function: 6.72678
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 8
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.1825
New value of Value function: 10.1825
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 9
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.84674
New value of Value function: 7.84674
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 10
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 4.51338
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 11
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 12
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 13
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 14
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 15
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 16
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 17
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 18
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 19
----------
State: 2289
	Distance: 5
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.01656
New value of Value function: 2.01656
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 20
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 8.47866
New value of Value function: 8.47866
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 21
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 8.38724
New value of Value function: 8.38724
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 22
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.47649
New value of Value function: 2.47649
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 23
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.95876
New value of Value function: 2.98865
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 24
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.09017
New value of Value function: 4.09017
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 25
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.89383
New value of Value function: 1.89383
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 26
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.04927
New value of Value function: 4.09017
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 27
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 4.99371
New value of Value function: 4.99371
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 28
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 7.909
New value of Value function: 7.909
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 29
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 3.91481
New value of Value function: 3.91481
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 30
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.59847
New value of Value function: 5.59847
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 31
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.71951
New value of Value function: 6.71951
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 32
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 33
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 34
----------
State: 1845
	Distance: 4
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 35
----------
State: 1805
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 99.05
New value of Value function: 99.05
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 36
----------
State: 1405
	Distance: 3
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1806
	Distance: 4
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 2
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 1
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.8734
New value of Value function: 11.8734
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 2
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.4273
New value of Value function: 10.4273
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 3
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.30414
New value of Value function: 8.30414
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 4
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 5.1192
New value of Value function: 5.1192
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 5
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 10.3026
New value of Value function: 10.3026
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 6
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 31.9346
New value of Value function: 31.9346
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 7
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 73.709
New value of Value function: 73.709
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 8
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 98.5098
New value of Value function: 99.5048
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 9
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 99.7524
New value of Value function: 99.7524
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 1
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 7.60151
New value of Value function: 7.60151
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 2
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 18.5952
New value of Value function: 18.5952
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 3
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 31.6152
New value of Value function: 31.9346
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 4
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 45.2244
New value of Value function: 45.2244
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 5
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 52.9864
New value of Value function: 52.9864
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 6
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 71.8303
New value of Value function: 71.8303
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 7
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 99.8631
New value of Value function: 99.8631
New value of Policy matrix: 4

=======================================
Episode: 11
Iteration: 1
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.1347
New value of Value function: 12.1347
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 2
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.6837
New value of Value function: 10.6837
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 3
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 7.40371
New value of Value function: 7.40371
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 4
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.1831
New value of Value function: 11.1831
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 5
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 8.20046
New value of Value function: 8.20046
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 6
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 3.21794
New value of Value function: 3.21794
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 7
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 10.7851
New value of Value function: 10.7851
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 8
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.1344
New value of Value function: 11.1344
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.79634
New value of Value function: 7.79634
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 10
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 11
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 12
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 13
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 14
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 15
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 16
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 17
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 18
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 19
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 20
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 21
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 22
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 23
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 24
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 25
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 26
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 27
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 28
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 29
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 30
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 31
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 32
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 33
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 34
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1366
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 12
Iteration: 1
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.1463
New value of Value function: 13.1463
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 2
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 12.0797
New value of Value function: 12.0797
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 3
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.3557
New value of Value function: 11.3557
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 4
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 8.14947
New value of Value function: 8.14947
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 5
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.8674
New value of Value function: 11.8674
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 6
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 8.19621
New value of Value function: 8.19621
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 7
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 4.65946
New value of Value function: 4.65946
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 8
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 6.99374
New value of Value function: 6.99374
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 9
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.9238
New value of Value function: 7.79634
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 10
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 7.69782
New value of Value function: 7.69782
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 11
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.47739
New value of Value function: 8.47739
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 12
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 45.4166
New value of Value function: 45.4166
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 13
----------
State: 1365
	Distance: 3
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 2
New value of Q matrix: 96.4645
New value of Value function: 96.4645
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 1
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 10.3769
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 2
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 3
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.44068
New value of Value function: 9.44068
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 4
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 2.44429
New value of Value function: 2.44429
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 5
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.00399
New value of Value function: 6.00399
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 6
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 2.19412
New value of Value function: 2.19412
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 7
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.28222
New value of Value function: 8.28222
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 8
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 9
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.0615
New value of Value function: 9.0615
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 10
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 7.83483
New value of Value function: 7.83483
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 11
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.5679
New value of Value function: 11.5679
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 12
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.43478
New value of Value function: 8.30414
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 13
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 17.4004
New value of Value function: 17.4004
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 14
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 28.1112
New value of Value function: 28.1112
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 15
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 48.617
New value of Value function: 48.617
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 16
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 67.6737
New value of Value function: 67.6737
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 17
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 99.919
New value of Value function: 99.919
New value of Policy matrix: 4

=======================================
Episode: 14
Iteration: 1
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 15.6252
New value of Value function: 15.6252
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 2
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 34.8356
New value of Value function: 34.8356
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 3
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 54.8655
New value of Value function: 54.8655
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 4
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 22.0275
New value of Value function: 67.6737
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 5
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 59.2888
New value of Value function: 59.2888
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 6
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 77.7265
New value of Value function: 77.7265
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 7
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 7
New value of Q matrix: 98.0598
New value of Value function: 98.5098
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 1
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 8.80235
New value of Value function: 8.80235
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 2
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.57824
New value of Value function: 9.57824
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 3
----------
State: 2653
	Distance: 6
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.39388
New value of Value function: 5.39388
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 4
----------
State: 2689
	Distance: 6
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 9.41048
New value of Value function: 9.41048
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 5
----------
State: 2649
	Distance: 6
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 8.58912
New value of Value function: 8.58912
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 6
----------
State: 2249
	Distance: 5
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 6.22838
New value of Value function: 6.22838
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 7
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.54995
New value of Value function: 7.69782
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 8
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 11.6604
New value of Value function: 11.6604
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 9
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.4382
New value of Value function: 12.4382
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 10
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 20.9856
New value of Value function: 20.9856
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 11
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 30.1368
New value of Value function: 30.1368
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 12
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -7
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 13
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.90015
New value of Value function: 2.90015
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 14
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.906211
New value of Value function: 0.906211
New value of Policy matrix: 4

=======================================
Episode: 15
Iteration: 15
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.903345
New value of Value function: 0.903345
New value of Policy matrix: 4

=======================================
Episode: 15
Iteration: 16
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 2.43703
New value of Value function: 2.43703
New value of Policy matrix: 4

=======================================
Episode: 15
Iteration: 17
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 18
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 16
Iteration: 1
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.67659
New value of Value function: 8.30414
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 2
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 13.2704
New value of Value function: 13.2704
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 3
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 22.6475
New value of Value function: 22.6475
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 4
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 42.4557
New value of Value function: 42.4557
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 5
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 43.0311
New value of Value function: 59.2888
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 6
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 47.2751
New value of Value function: 47.2751
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 7
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 64.9539
New value of Value function: 64.9539
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 8
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 84.3541
New value of Value function: 84.3541
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 9
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 97.8132
New value of Value function: 98.0598
New value of Policy matrix: 4

=======================================
Episode: 16
Iteration: 10
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1774
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 96
New value of Visit matrix: 8
New value of Q matrix: 97.3316
New value of Value function: 97.8132
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 1
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 14.2644
New value of Value function: 14.2644
New value of Policy matrix: 2

