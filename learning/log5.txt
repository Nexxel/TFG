=======================================
Simulation: 1
Iteration: 1
----------
State: 493
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 493
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 493
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 493
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 493
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 3
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 3
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 3
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 3
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 520
	Distance: 2
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 3
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 516
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
State': 496
	Distance: 2
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 0
Action: 1
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 0
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 636
	Distance: 3
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 636
	Distance: 3
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 2
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
State': 492
	Distance: 2
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 0
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

